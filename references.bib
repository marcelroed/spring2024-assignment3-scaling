@online{240518392ScalingLaws,
  title = {[2405.18392] {{Scaling Laws}} and {{Compute-Optimal Training Beyond Fixed Training Durations}}},
  url = {https://arxiv.org/abs/2405.18392},
  urldate = {2024-12-04},
  file = {/Users/marcel/Zotero/storage/BBR73P4H/2405.html}
}

@article{abramsonAccurateStructurePrediction2024,
  title = {Accurate Structure Prediction of Biomolecular Interactions with {{AlphaFold}} 3},
  author = {Abramson, Josh and Adler, Jonas and Dunger, Jack and Evans, Richard and Green, Tim and Pritzel, Alexander and Ronneberger, Olaf and Willmore, Lindsay and Ballard, Andrew J. and Bambrick, Joshua and Bodenstein, Sebastian W. and Evans, David A. and Hung, Chia-Chun and O’Neill, Michael and Reiman, David and Tunyasuvunakool, Kathryn and Wu, Zachary and Žemgulytė, Akvilė and Arvaniti, Eirini and Beattie, Charles and Bertolli, Ottavia and Bridgland, Alex and Cherepanov, Alexey and Congreve, Miles and Cowen-Rivers, Alexander I. and Cowie, Andrew and Figurnov, Michael and Fuchs, Fabian B. and Gladman, Hannah and Jain, Rishub and Khan, Yousuf A. and Low, Caroline M. R. and Perlin, Kuba and Potapenko, Anna and Savy, Pascal and Singh, Sukhdeep and Stecula, Adrian and Thillaisundaram, Ashok and Tong, Catherine and Yakneen, Sergei and Zhong, Ellen D. and Zielinski, Michal and Žídek, Augustin and Bapst, Victor and Kohli, Pushmeet and Jaderberg, Max and Hassabis, Demis and Jumper, John M.},
  date = {2024-05-08},
  journaltitle = {Nature},
  pages = {1--3},
  publisher = {Nature Publishing Group},
  issn = {1476-4687},
  doi = {10.1038/s41586-024-07487-w},
  url = {https://www.nature.com/articles/s41586-024-07487-w},
  urldate = {2024-05-14},
  abstract = {The introduction of AlphaFold\,21 has spurred a revolution in modelling the structure of proteins and their interactions, enabling a huge range of applications in protein modelling and design2–6. In this paper, we describe our AlphaFold\,3 model with a substantially updated diffusion-based architecture, which is capable of joint structure prediction of complexes including proteins, nucleic acids, small molecules, ions, and modified residues. The new AlphaFold model demonstrates significantly improved accuracy over many previous specialised tools: far greater accuracy on protein-ligand interactions than state of the art docking tools, much higher accuracy on protein-nucleic acid interactions than nucleic-acid-specific predictors, and significantly higher antibody-antigen prediction accuracy than AlphaFold-Multimer v2.37,8. Together these results show that high accuracy modelling across biomolecular space is possible within a single unified deep learning framework.},
  langid = {english},
  keywords = {Drug discovery,Machine learning,Protein structure predictions,Structural biology},
  file = {/Users/marcel/Zotero/storage/NDRX8N5I/Abramson et al. - 2024 - Accurate structure prediction of biomolecular interactions with AlphaFold 3.pdf}
}

@software{AbstractTrees2023,
  title = {{{AbstractTrees}}},
  date = {2023-05-08T18:30:04Z},
  origdate = {2015-07-22T17:32:10Z},
  url = {https://github.com/JuliaCollections/AbstractTrees.jl},
  urldate = {2023-05-15},
  abstract = {Abstract julia interfaces for working with trees},
  organization = {JuliaCollections}
}

@online{AkerScholarship,
  title = {Aker {{Scholarship}}},
  url = {https://www.akerscholarship.org},
  urldate = {2022-12-09},
  abstract = {Aker Scholarship er et stipend for deg som ønsker å ta en Mastergrad eller PhD ved et av verdens ledende universiteter. Stipendet kan søkes av studenter fra alle fagområder.},
  langid = {american},
  organization = {Aker Scholarship - EN},
  file = {/Users/marcel/Zotero/storage/477KGZUY/home.html}
}

@article{alarieTwoDecadesBlackbox2021,
  title = {Two Decades of Blackbox Optimization Applications},
  author = {Alarie, Stéphane and Audet, Charles and Gheribi, Aïmen E. and Kokkolaras, Michael and Le Digabel, Sébastien},
  date = {2021-01-01},
  journaltitle = {EURO Journal on Computational Optimization},
  shortjournal = {EURO Journal on Computational Optimization},
  volume = {9},
  pages = {100011},
  issn = {2192-4406},
  doi = {10.1016/j.ejco.2021.100011},
  url = {https://www.sciencedirect.com/science/article/pii/S2192440621001386},
  urldate = {2023-12-16},
  abstract = {This article reviews blackbox optimization applications of direct search optimization methods over the past twenty years. Emphasis is placed on the Mesh Adaptive Direct Search (Mads) derivative-free optimization algorithm. The main focus is on applications in three specific fields: energy, materials science, and computational engineering design. Nevertheless, other applications in science and engineering, including patents, are also considered. The breadth of applications demonstrates the versatility of Mads and highlights the evolution of its accompanying software NOMAD as a standard tool for blackbox optimization.},
  keywords = {Applications,Blackbox optimization,Derivative-free optimization,Mesh adaptive direct search},
  file = {/Users/marcel/Zotero/storage/EG2H5768/Alarie et al. - 2021 - Two decades of blackbox optimization applications.pdf}
}

@video{alexanderaminiMITS19120192019,
  entrysubtype = {video},
  title = {{{MIT}} 6.{{S191}} (2019): {{Biologically Inspired Neural Networks}} ({{IBM}})},
  shorttitle = {{{MIT}} 6.{{S191}} (2019)},
  editor = {{Alexander Amini}},
  editortype = {director},
  date = {2019-02-19},
  url = {https://www.youtube.com/watch?v=4lY-oAY0aQU},
  urldate = {2022-04-19},
  abstract = {MIT Introduction to Deep Learning 6.S191: Lecture 8 A Biologically Plausible Learning Algorithm for Neural Networks Lecturer: Dmitry Krotov MIT/IBM Watson AI Lab Guest Lecture January 2019 For all lectures, slides and lab materials: http://introtodeeplearning.com}
}

@book{alligoodChaosIntroductionDynamical1996,
  title = {Chaos: {{An Introduction}} to {{Dynamical Systems}}},
  shorttitle = {Chaos},
  author = {Alligood, Kathleen T. and Sauer, Tim D. and Yorke, James A.},
  editor = {Banchoff, Thomas F. and Devlin, Keith and Gonnet, Gaston and Marsden, Jerrold and Wagon, Stan},
  editortype = {redactor},
  date = {1996},
  series = {Textbooks in {{Mathematical Sciences}}},
  publisher = {Springer},
  location = {New York, NY},
  doi = {10.1007/b97589},
  url = {http://link.springer.com/10.1007/b97589},
  urldate = {2023-10-27},
  isbn = {978-0-387-94677-1 978-0-387-22492-3},
  langid = {english},
  keywords = {calculus,chaos,computer simulation,differential equation,nonlinear dynamics,simulation},
  file = {/Users/marcel/Zotero/storage/A2AZFT6M/Alligood et al. - 1996 - Chaos An Introduction to Dynamical Systems.pdf}
}

@online{alonBottleneckGraphNeural2021,
  title = {On the {{Bottleneck}} of {{Graph Neural Networks}} and Its {{Practical Implications}}},
  author = {Alon, Uri and Yahav, Eran},
  date = {2021-03-09},
  eprint = {2006.05205},
  eprinttype = {arXiv},
  eprintclass = {cs, stat},
  doi = {10.48550/arXiv.2006.05205},
  url = {http://arxiv.org/abs/2006.05205},
  urldate = {2022-09-22},
  abstract = {Since the proposal of the graph neural network (GNN) by Gori et al. (2005) and Scarselli et al. (2008), one of the major problems in training GNNs was their struggle to propagate information between distant nodes in the graph. We propose a new explanation for this problem: GNNs are susceptible to a bottleneck when aggregating messages across a long path. This bottleneck causes the over-squashing of exponentially growing information into fixed-size vectors. As a result, GNNs fail to propagate messages originating from distant nodes and perform poorly when the prediction task depends on long-range interaction. In this paper, we highlight the inherent problem of over-squashing in GNNs: we demonstrate that the bottleneck hinders popular GNNs from fitting long-range signals in the training data; we further show that GNNs that absorb incoming edges equally, such as GCN and GIN, are more susceptible to over-squashing than GAT and GGNN; finally, we show that prior work, which extensively tuned GNN models of long-range problems, suffers from over-squashing, and that breaking the bottleneck improves their state-of-the-art results without any tuning or additional weights. Our code is available at https://github.com/tech-srl/bottleneck/ .},
  pubstate = {prepublished},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/marcel/Zotero/storage/4MX436YY/Alon and Yahav - 2021 - On the Bottleneck of Graph Neural Networks and its.pdf;/Users/marcel/Zotero/storage/QJ4HKJ5P/2006.html}
}

@article{amirsoleimaniInMemoryVectorMatrixMultiplication2020,
  title = {In-{{Memory Vector-Matrix Multiplication}} in {{Monolithic Complementary Metal}}–{{Oxide}}–{{Semiconductor-Memristor Integrated Circuits}}: {{Design Choices}}, {{Challenges}}, and {{Perspectives}}},
  shorttitle = {In-{{Memory Vector-Matrix Multiplication}} in {{Monolithic Complementary Metal}}–{{Oxide}}–{{Semiconductor-Memristor Integrated Circuits}}},
  author = {Amirsoleimani, Amirali and Alibart, Fabien and Yon, Victor and Xu, Jianxiong and Pazhouhandeh, M. Reza and Ecoffey, Serge and Beilliard, Yann and Genov, Roman and Drouin, Dominique},
  date = {2020},
  journaltitle = {Advanced Intelligent Systems},
  volume = {2},
  number = {11},
  pages = {2000115},
  issn = {2640-4567},
  doi = {10.1002/aisy.202000115},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/aisy.202000115},
  urldate = {2023-12-15},
  abstract = {The low communication bandwidth between memory and processing units in conventional von Neumann machines does not support the requirements of emerging applications that rely extensively on large sets of data. More recent computing paradigms, such as high parallelization and near-memory computing, help alleviate the data communication bottleneck to some extent, but paradigm-shifting concepts are required. In-memory computing has emerged as a prime candidate to eliminate this bottleneck by colocating memory and processing. In this context, resistive switching (RS) memory devices is a key promising choice, due to their unique intrinsic device-level properties, enabling both storing and computing with a small, massively-parallel footprint at low power. Theoretically, this directly translates to a major boost in energy efficiency and computational throughput, but various practical challenges remain. A qualitative and quantitative analysis of several key existing challenges in implementing high-capacity, high-volume RS memories for accelerating the most computationally demanding computation in machine learning (ML) inference, that of vector-matrix multiplication (VMM), is presented. The monolithic integration of RS memories with complementary metal–oxide–semiconductor (CMOS) integrated circuits is presented as the core underlying technology. The key existing design choices in terms of device-level physical implementation, circuit-level design, and system-level considerations is reviewed and an outlook for future directions is provided.},
  langid = {english},
  keywords = {complementary metal–oxide–semiconductor,in-memory computing,inference,memristors,redox-based random access memories,resistive switching memories,vector-matrix multiplications},
  file = {/Users/marcel/Zotero/storage/RWDVRJTZ/Amirsoleimani et al. - 2020 - In-Memory Vector-Matrix Multiplication in Monolithic Complementary Metal–Oxide–Semiconductor-Memrist.pdf;/Users/marcel/Zotero/storage/28PBD7AI/aisy.html}
}

@online{anUltrafastPhotorealisticStyle2020,
  title = {Ultrafast {{Photorealistic Style Transfer}} via {{Neural Architecture Search}}},
  author = {An, Jie and Xiong, Haoyi and Huan, Jun and Luo, Jiebo},
  date = {2020-06-22},
  eprint = {1912.02398},
  eprinttype = {arXiv},
  eprintclass = {cs, eess},
  doi = {10.48550/arXiv.1912.02398},
  url = {http://arxiv.org/abs/1912.02398},
  urldate = {2022-12-18},
  abstract = {The key challenge in photorealistic style transfer is that an algorithm should faithfully transfer the style of a reference photo to a content photo while the generated image should look like one captured by a camera. Although several photorealistic style transfer algorithms have been proposed, they need to rely on post- and/or pre-processing to make the generated images look photorealistic. If we disable the additional processing, these algorithms would fail to produce plausible photorealistic stylization in terms of detail preservation and photorealism. In this work, we propose an effective solution to these issues. Our method consists of a construction step (C-step) to build a photorealistic stylization network and a pruning step (P-step) for acceleration. In the C-step, we propose a dense auto-encoder named PhotoNet based on a carefully designed pre-analysis. PhotoNet integrates a feature aggregation module (BFA) and instance normalized skip links (INSL). To generate faithful stylization, we introduce multiple style transfer modules in the decoder and INSLs. PhotoNet significantly outperforms existing algorithms in terms of both efficiency and effectiveness. In the P-step, we adopt a neural architecture search method to accelerate PhotoNet. We propose an automatic network pruning framework in the manner of teacher-student learning for photorealistic stylization. The network architecture named PhotoNAS resulted from the search achieves significant acceleration over PhotoNet while keeping the stylization effects almost intact. We conduct extensive experiments on both image and video transfer. The results show that our method can produce favorable results while achieving 20-30 times acceleration in comparison with the existing state-of-the-art approaches. It is worth noting that the proposed algorithm accomplishes better performance without any pre- or post-processing.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Electrical Engineering and Systems Science - Image and Video Processing},
  file = {/Users/marcel/Zotero/storage/L86MVZ8L/An et al. - 2020 - Ultrafast Photorealistic Style Transfer via Neural.pdf;/Users/marcel/Zotero/storage/9JFD2VZA/1912.html}
}

@inproceedings{arvanitis3DMeshInpainting2018a,
  title = {{{3D Mesh Inpainting Using Matrix Completion}} via {{Augmented Lagrange Multiplier Method}}},
  booktitle = {2018 {{IEEE}} 13th {{Image}}, {{Video}}, and {{Multidimensional Signal Processing Workshop}} ({{IVMSP}})},
  author = {Arvanitis, Gerasimos and Moustakas, Konstantinos and Fakotakis, Nikos and Lalos, Aris S.},
  date = {2018-06},
  pages = {1--5},
  doi = {10.1109/IVMSPW.2018.8448546},
  abstract = {Recently, 3D objects have started to attract a lot of attention, due to their increased usage in a large variety of different fields (e.g., archeology, gaming, topography, medicine etc.), Despite the technological improvement that has been occurred, there are still limitations that can cause noisy or incomplete data. In this paper, we focus on the problems of partial-deformed or partial-observed 3D meshes, presenting a very fast and efficient method for surface inpainting of dense 3D meshes. In order to achieve this, we use a matrix completion approach taking advantage of the low-rank property attributed to spatial coherence. Two different scenarios are studied and presented: (i) the repairing of partial-observed 3D meshes consisting of incomplete surfaces, (ii) the recovery of 3D objects with holes which are created by the intentional removal of deformed areas. We demonstrate the performance of our approach providing experimental results for both cases highlighting the effectiveness of our method.},
  eventtitle = {2018 {{IEEE}} 13th {{Image}}, {{Video}}, and {{Multidimensional Signal Processing Workshop}} ({{IVMSP}})},
  keywords = {inpainting of 3D meshes,low-rank matrix completion,Minimization,Missing geometry of 3D meshes,Solid modeling,Spatial coherence,Surface topography,Three-dimensional displays,Videos},
  file = {/Users/marcel/Zotero/storage/NXLKIGUL/Arvanitis et al. - 2018 - 3D Mesh Inpainting Using Matrix Completion via Aug.pdf;/Users/marcel/Zotero/storage/7HNQI6KY/8448546.html}
}

@misc{ASPLOS24_Summer_ARKPdf,
  title = {{{ASPLOS24}}\_{{Summer}}\_{{ARK}} (2).Pdf},
  file = {/Users/marcel/Zotero/storage/URR8EUCC/ASPLOS24_Summer_ARK (2).pdf}
}

@article{aycockBriefHistoryJustintime2003,
  title = {A Brief History of Just-in-Time},
  author = {Aycock, John},
  date = {2003-06-01},
  journaltitle = {ACM Computing Surveys},
  shortjournal = {ACM Comput. Surv.},
  volume = {35},
  number = {2},
  pages = {97--113},
  issn = {0360-0300},
  doi = {10.1145/857076.857077},
  url = {https://dl.acm.org/doi/10.1145/857076.857077},
  urldate = {2023-05-14},
  abstract = {Software systems have been using "just-in-time" compilation (JIT) techniques since the 1960s. Broadly, JIT compilation includes any translation performed dynamically, after a program has started execution. We examine the motivation behind JIT compilation and constraints imposed on JIT compilation systems, and present a classification scheme for such systems. This classification emerges as we survey forty years of JIT work, from 1960--2000.},
  keywords = {dynamic compilation,Just-in-time compilation},
  file = {/Users/marcel/Zotero/storage/CWVF8HAM/Aycock - 2003 - A brief history of just-in-time.pdf}
}

@online{baLayerNormalization2016,
  title = {Layer {{Normalization}}},
  author = {Ba, Jimmy Lei and Kiros, Jamie Ryan and Hinton, Geoffrey E.},
  date = {2016-07-21},
  eprint = {1607.06450},
  eprinttype = {arXiv},
  eprintclass = {cs, stat},
  doi = {10.48550/arXiv.1607.06450},
  url = {http://arxiv.org/abs/1607.06450},
  urldate = {2024-02-29},
  abstract = {Training state-of-the-art, deep neural networks is computationally expensive. One way to reduce the training time is to normalize the activities of the neurons. A recently introduced technique called batch normalization uses the distribution of the summed input to a neuron over a mini-batch of training cases to compute a mean and variance which are then used to normalize the summed input to that neuron on each training case. This significantly reduces the training time in feed-forward neural networks. However, the effect of batch normalization is dependent on the mini-batch size and it is not obvious how to apply it to recurrent neural networks. In this paper, we transpose batch normalization into layer normalization by computing the mean and variance used for normalization from all of the summed inputs to the neurons in a layer on a single training case. Like batch normalization, we also give each neuron its own adaptive bias and gain which are applied after the normalization but before the non-linearity. Unlike batch normalization, layer normalization performs exactly the same computation at training and test times. It is also straightforward to apply to recurrent neural networks by computing the normalization statistics separately at each time step. Layer normalization is very effective at stabilizing the hidden state dynamics in recurrent networks. Empirically, we show that layer normalization can substantially reduce the training time compared with previously published techniques.},
  pubstate = {prepublished},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/marcel/Zotero/storage/NIA7APT7/Ba et al. - 2016 - Layer Normalization.pdf;/Users/marcel/Zotero/storage/N37MGNIJ/1607.html}
}

@article{baldiTheoryLocalLearning2016,
  title = {A Theory of Local Learning, the Learning Channel, and the Optimality of Backpropagation},
  author = {Baldi, Pierre and Sadowski, Peter},
  date = {2016-11},
  journaltitle = {Neural Networks: The Official Journal of the International Neural Network Society},
  shortjournal = {Neural Netw},
  volume = {83},
  eprint = {27584574},
  eprinttype = {pmid},
  pages = {51--74},
  issn = {1879-2782},
  doi = {10.1016/j.neunet.2016.07.006},
  abstract = {In a physical neural system, where storage and processing are intimately intertwined, the rules for adjusting the synaptic weights can only depend on variables that are available locally, such as the activity of the pre- and post-synaptic neurons, resulting in local learning rules. A systematic framework for studying the space of local learning rules is obtained by first specifying the nature of the local variables, and then the functional form that ties them together into each learning rule. Such a framework enables also the systematic discovery of new learning rules and exploration of relationships between learning rules and group symmetries. We study polynomial local learning rules stratified by their degree and analyze their behavior and capabilities in both linear and non-linear units and networks. Stacking local learning rules in deep feedforward networks leads to deep local learning. While deep local learning can learn interesting representations, it cannot learn complex input-output functions, even when targets are available for the top layer. Learning complex input-output functions requires local deep learning where target information is communicated to the deep layers through a backward learning channel. The nature of the communicated information about the targets and the structure of the learning channel partition the space of learning algorithms. For any learning algorithm, the capacity of the learning channel can be defined as the number of bits provided about the error gradient per weight, divided by the number of required operations per weight. We estimate the capacity associated with several learning algorithms and show that backpropagation outperforms them by simultaneously maximizing the information rate and minimizing the computational cost. This result is also shown to be true for recurrent networks, by unfolding them in time. The theory clarifies the concept of Hebbian learning, establishes the power and limitations of local learning rules, introduces the learning channel which enables a formal analysis of the optimality of backpropagation, and explains the sparsity of the space of learning rules discovered so far.},
  langid = {english},
  keywords = {Algorithms,Backpropagation,Deep learning,Feedback,Hebbian learning,Learning channel,Machine Learning,Neural Networks Computer,Supervised learning,Unsupervised learning},
  file = {/Users/marcel/Zotero/storage/EW4Y3XDC/Baldi and Sadowski - 2016 - A theory of local learning, the learning channel, .pdf}
}

@book{banerjeePLLPerformanceSimulation2017,
  title = {{{PLL Performance}}, {{Simulation}}, and {{Design}} 5th {{Edition}}},
  author = {Banerjee, Dean},
  date = {2017},
  langid = {english},
  file = {/Users/marcel/Zotero/storage/K8MJ3RCL/Banerjee - 2017 - PLL Performance, Simulation, and Design 5th Edition.pdf}
}

@article{barabasiNetworkScience2013,
  title = {Network Science},
  author = {Barabási, Albert-László},
  date = {2013-03-28},
  journaltitle = {Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences},
  volume = {371},
  number = {1987},
  pages = {20120375},
  publisher = {Royal Society},
  doi = {10.1098/rsta.2012.0375},
  url = {https://royalsocietypublishing.org/doi/full/10.1098/rsta.2012.0375},
  urldate = {2024-03-15},
  abstract = {Professor Barabási's talk described how the tools of network science can help understand the Web's structure, development and weaknesses. The Web is an information network, in which the nodes are documents (at the time of writing over one trillion of them), connected by links. Other well-known network structures include the Internet, a physical network where the nodes are routers and the links are physical connections, and organizations, where the nodes are people and the links represent communications.},
  keywords = {complex systems,networks,web infrastructure},
  file = {/Users/marcel/Zotero/storage/DK5PFWLU/Barabási - 2013 - Network science.pdf}
}

@article{barariAnalogCircuitDesign2014,
  title = {Analog {{Circuit Design Optimization Based}} on {{Evolutionary Algorithms}}},
  author = {Barari, Mansour and Karimi, Hamid Reza and Razaghian, Farhad},
  date = {2014-04-07},
  journaltitle = {Mathematical Problems in Engineering},
  volume = {2014},
  pages = {e593684},
  publisher = {Hindawi},
  issn = {1024-123X},
  doi = {10.1155/2014/593684},
  url = {https://www.hindawi.com/journals/mpe/2014/593684/},
  urldate = {2023-12-16},
  abstract = {This paper investigates an evolutionary-based designing system for automated sizing of analog integrated circuits (ICs). Two evolutionary algorithms, genetic algorithm and PSO (Parswal particle swarm optimization) algorithm, are proposed to design analog ICs with practical user-defined specifications. On the basis of the combination of HSPICE and MATLAB, the system links circuit performances, evaluated through specific electrical simulation, to the optimization system in the MATLAB environment, for the selected topology. The system has been tested by typical and hard-to-design cases, such as complex analog blocks with stringent design requirements. The results show that the design specifications are closely met. Comparisons with available methods like genetic algorithms show that the proposed algorithm offers important advantages in terms of optimization quality and robustness. Moreover, the algorithm is shown to be efficient.},
  langid = {english},
  file = {/Users/marcel/Zotero/storage/Y8DZNU2L/Barari et al. - 2014 - Analog Circuit Design Optimization Based on Evolutionary Algorithms.pdf}
}

@article{batznerEquivariantGraphNeural2022,
  title = {E(3)-Equivariant Graph Neural Networks for Data-Efficient and Accurate Interatomic Potentials},
  author = {Batzner, Simon and Musaelian, Albert and Sun, Lixin and Geiger, Mario and Mailoa, Jonathan P. and Kornbluth, Mordechai and Molinari, Nicola and Smidt, Tess E. and Kozinsky, Boris},
  date = {2022-05-04},
  journaltitle = {Nature Communications},
  shortjournal = {Nat Commun},
  volume = {13},
  number = {1},
  pages = {2453},
  publisher = {Nature Publishing Group},
  issn = {2041-1723},
  doi = {10.1038/s41467-022-29939-5},
  url = {https://www.nature.com/articles/s41467-022-29939-5},
  urldate = {2023-01-10},
  abstract = {This work presents Neural Equivariant Interatomic Potentials (NequIP), an E(3)-equivariant neural network approach for learning interatomic potentials from ab-initio calculations for molecular dynamics simulations. While most contemporary symmetry-aware models use invariant convolutions and only act on scalars, NequIP employs E(3)-equivariant convolutions for interactions of geometric tensors, resulting in a more information-rich and faithful representation of atomic environments. The method achieves state-of-the-art accuracy on a challenging and diverse set of molecules and materials while exhibiting remarkable data efficiency. NequIP outperforms existing models with up to three orders of magnitude fewer training data, challenging the widely held belief that deep neural networks require massive training sets. The high data efficiency of the method allows for the construction of accurate potentials using high-order quantum chemical level of theory as reference and enables high-fidelity molecular dynamics simulations over long time scales.},
  issue = {1},
  langid = {english},
  keywords = {Atomistic models,Computational chemistry,Computational methods,Computer science,Molecular dynamics},
  file = {/Users/marcel/Zotero/storage/QYHS9YAT/Batzner et al. - 2022 - E(3)-equivariant graph neural networks for data-ef.pdf}
}

@misc{behnelLxmlXMLHTML2005,
  title = {Lxml: {{XML}} and {{HTML}} with {{Python}}},
  author = {Behnel, Stefan and Faassen, Martijn and Bicking, Ian},
  date = {2005},
  organization = {Lxml}
}

@online{behrouzTitansLearningMemorize2024,
  title = {Titans: {{Learning}} to {{Memorize}} at {{Test Time}}},
  shorttitle = {Titans},
  author = {Behrouz, Ali and Zhong, Peilin and Mirrokni, Vahab},
  date = {2024-12-31},
  eprint = {2501.00663},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2501.00663},
  url = {http://arxiv.org/abs/2501.00663},
  urldate = {2025-02-10},
  abstract = {Over more than a decade there has been an extensive research effort on how to effectively utilize recurrent models and attention. While recurrent models aim to compress the data into a fixed-size memory (called hidden state), attention allows attending to the entire context window, capturing the direct dependencies of all tokens. This more accurate modeling of dependencies, however, comes with a quadratic cost, limiting the model to a fixed-length context. We present a new neural long-term memory module that learns to memorize historical context and helps attention to attend to the current context while utilizing long past information. We show that this neural memory has the advantage of fast parallelizable training while maintaining a fast inference. From a memory perspective, we argue that attention due to its limited context but accurate dependency modeling performs as a short-term memory, while neural memory due to its ability to memorize the data, acts as a long-term, more persistent, memory. Based on these two modules, we introduce a new family of architectures, called Titans, and present three variants to address how one can effectively incorporate memory into this architecture. Our experimental results on language modeling, common-sense reasoning, genomics, and time series tasks show that Titans are more effective than Transformers and recent modern linear recurrent models. They further can effectively scale to larger than 2M context window size with higher accuracy in needle-in-haystack tasks compared to baselines.},
  pubstate = {prepublished},
  version = {1},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Machine Learning},
  file = {/Users/marcel/Zotero/storage/72676ANC/Behrouz et al. - 2024 - Titans Learning to Memorize at Test Time.pdf;/Users/marcel/Zotero/storage/T6KWXL6E/2501.html}
}

@unpublished{bekkersBSplineCNNsLie2021,
  title = {B-{{Spline CNNs}} on {{Lie Groups}}},
  author = {Bekkers, Erik J.},
  date = {2021-03-22},
  eprint = {1909.12057},
  eprinttype = {arXiv},
  eprintclass = {cs, stat},
  url = {http://arxiv.org/abs/1909.12057},
  urldate = {2021-07-27},
  abstract = {Group convolutional neural networks (G-CNNs) can be used to improve classical CNNs by equipping them with the geometric structure of groups. Central in the success of G-CNNs is the lifting of feature maps to higher dimensional disentangled representations, in which data characteristics are effectively learned, geometric data-augmentations are made obsolete, and predictable behavior under geometric transformations (equivariance) is guaranteed via group theory. Currently, however, the practical implementations of G-CNNs are limited to either discrete groups (that leave the grid intact) or continuous compact groups such as rotations (that enable the use of Fourier theory). In this paper we lift these limitations and propose a modular framework for the design and implementation of G-CNNs for arbitrary Lie groups. In our approach the differential structure of Lie groups is used to expand convolution kernels in a generic basis of B-splines that is defined on the Lie algebra. This leads to a flexible framework that enables localized, atrous, and deformable convolutions in G-CNNs by means of respectively localized, sparse and non-uniform B-spline expansions. The impact and potential of our approach is studied on two benchmark datasets: cancer detection in histopathology slides in which rotation equivariance plays a key role and facial landmark localization in which scale equivariance is important. In both cases, G-CNN architectures outperform their classical 2D counterparts and the added value of atrous and localized group convolutions is studied in detail.},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/marcel/Zotero/storage/S8N43RV5/Bekkers_2021_B-Spline CNNs on Lie Groups.pdf;/Users/marcel/Zotero/storage/T67R44TL/1909.html}
}

@unpublished{bengioBiologicallyPlausibleDeep2016,
  title = {Towards {{Biologically Plausible Deep Learning}}},
  author = {Bengio, Yoshua and Lee, Dong-Hyun and Bornschein, Jorg and Mesnard, Thomas and Lin, Zhouhan},
  date = {2016-08-08},
  eprint = {1502.04156},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/1502.04156},
  urldate = {2022-04-19},
  abstract = {Neuroscientists have long criticised deep learning algorithms as incompatible with current knowledge of neurobiology. We explore more biologically plausible versions of deep representation learning, focusing here mostly on unsupervised learning but developing a learning mechanism that could account for supervised, unsupervised and reinforcement learning. The starting point is that the basic learning rule believed to govern synaptic weight updates (Spike-Timing-Dependent Plasticity) arises out of a simple update rule that makes a lot of sense from a machine learning point of view and can be interpreted as gradient descent on some objective function so long as the neuronal dynamics push firing rates towards better values of the objective function (be it supervised, unsupervised, or reward-driven). The second main idea is that this corresponds to a form of the variational EM algorithm, i.e., with approximate rather than exact posteriors, implemented by neural dynamics. Another contribution of this paper is that the gradients required for updating the hidden states in the above variational interpretation can be estimated using an approximation that only requires propagating activations forward and backward, with pairs of layers learning to form a denoising auto-encoder. Finally, we extend the theory about the probabilistic interpretation of auto-encoders to justify improved sampling schemes based on the generative interpretation of denoising auto-encoders, and we validate all these ideas on generative learning tasks.},
  keywords = {Computer Science - Machine Learning},
  file = {/Users/marcel/Zotero/storage/P55GBFZP/Bengio et al. - 2016 - Towards Biologically Plausible Deep Learning.pdf;/Users/marcel/Zotero/storage/3YUEVRNL/1502.html}
}

@article{benraComparisonOneWayTwoWay2011,
  title = {A {{Comparison}} of {{One-Way}} and {{Two-Way Coupling Methods}} for {{Numerical Analysis}} of {{Fluid-Structure Interactions}}},
  author = {Benra, Friedrich-Karl and Dohmen, Hans Josef and Pei, Ji and Schuster, Sebastian and Wan, Bo},
  date = {2011-11-03},
  journaltitle = {Journal of Applied Mathematics},
  volume = {2011},
  pages = {e853560},
  publisher = {Hindawi},
  issn = {1110-757X},
  doi = {10.1155/2011/853560},
  url = {https://www.hindawi.com/journals/jam/2011/853560/},
  urldate = {2022-12-15},
  abstract = {The interaction between fluid and structure occurs in a wide range of engineering problems. The solution for such problems is based on the relations of continuum mechanics and is mostly solved with numerical methods. It is a computational challenge to solve such problems because of the complex geometries, intricate physics of fluids, and complicated fluid-structure interactions. The way in which the interaction between fluid and solid is described gives the largest opportunity for reducing the computational effort. One possibility for reducing the computational effort of fluid-structure simulations is the use of one-way coupled simulations. In this paper, different problems are investigated with one-way and two-way coupled methods. After an explanation of the solution strategy for both models, a closer look at the differences between these methods will be provided, and it will be shown under what conditions a one-way coupling solution gives plausible results.},
  langid = {english},
  file = {/Users/marcel/Zotero/storage/8GLN4VM6/Benra et al. - 2011 - A Comparison of One-Way and Two-Way Coupling Metho.pdf}
}

@article{bezansonJuliaFreshApproach2017,
  title = {Julia: {{A Fresh Approach}} to {{Numerical Computing}}},
  shorttitle = {Julia},
  author = {Bezanson, Jeff and Edelman, Alan and Karpinski, Stefan and Shah, Viral B.},
  date = {2017-01},
  journaltitle = {SIAM Review},
  shortjournal = {SIAM Rev.},
  volume = {59},
  number = {1},
  pages = {65--98},
  publisher = {{Society for Industrial and Applied Mathematics}},
  issn = {0036-1445},
  doi = {10.1137/141000671},
  url = {https://epubs.siam.org/doi/10.1137/141000671},
  urldate = {2023-05-12},
  abstract = {JuMP is an open-source modeling language that allows users to express a wide range of optimization problems (linear, mixed-integer, quadratic, conic-quadratic, semidefinite, and nonlinear) in a high-level, algebraic syntax. JuMP takes advantage of advanced features of the Julia programming language to offer unique functionality while achieving performance on par with commercial modeling tools for standard tasks. In this work we will provide benchmarks, present the novel aspects of the implementation, and discuss how JuMP can be extended to new problem classes and composed with state-of-the-art tools for visualization and interactivity.},
  file = {/Users/marcel/Zotero/storage/LBXS53PK/Bezanson et al. - 2017 - Julia A Fresh Approach to Numerical Computing.pdf}
}

@inproceedings{binkleyTradeoffsOptimizationAnalog2007,
  title = {Tradeoffs and {{Optimization}} in {{Analog CMOS Design}}},
  booktitle = {2007 14th {{International Conference}} on {{Mixed Design}} of {{Integrated Circuits}} and {{Systems}}},
  author = {Binkley, D. M.},
  date = {2007-06},
  pages = {47--60},
  doi = {10.1109/MIXDES.2007.4286119},
  url = {https://ieeexplore.ieee.org/document/4286119},
  urldate = {2023-12-16},
  abstract = {The selection of drain current, inversion coefficient, and channel length for each MOS device in an analog circuit results in significant tradeoffs in performance. The selection of inversion coefficient, which is a numerical measure of MOS inversion, enables design freely in weak, moderate, and strong inversion and facilitates optimum design. Here, channel width required for layout is easily found and implicitly considered in performance expressions. This paper gives hand expressions motivated by the EKV MOS model and measured data for MOS device performance, inclusive of velocity saturation and other small-geometry effects. A simple spreadsheet tool is then used to predict MOS device performance and map this into complete circuit performance. Tradeoffs and optimization of performance are illustrated by the design of three, 0.18-μm CMOS operational transconductance amplifiers optimized for DC, balanced, and AC performance. Measured performance shows significant tradeoffs in voltage gain, output resistance, transconductance bandwidth, input-referred flicker noise and offset voltage, and layout area.},
  eventtitle = {2007 14th {{International Conference}} on {{Mixed Design}} of {{Integrated Circuits}} and {{Systems}}}
}

@article{blinnFloatingpointTricks1997,
  title = {Floating-Point Tricks},
  author = {Blinn, J.F.},
  date = {1997-07},
  journaltitle = {IEEE Computer Graphics and Applications},
  volume = {17},
  number = {4},
  pages = {80--84},
  issn = {1558-1756},
  doi = {10.1109/38.595279},
  url = {https://ieeexplore.ieee.org/document/595279},
  urldate = {2023-11-10},
  abstract = {The author discusses IEEE floating point representation that stores numbers in what amounts to scientific notation. He considers the sign bit, the logarithm function, function approximations, errors and refinements.},
  eventtitle = {{{IEEE Computer Graphics}} and {{Applications}}},
  file = {/Users/marcel/Zotero/storage/UWSGF4I2/Blinn - 1997 - Floating-point tricks.pdf;/Users/marcel/Zotero/storage/2EWTQXGD/595279.html}
}

@unpublished{bodnarNeuralSheafDiffusion2022,
  title = {Neural {{Sheaf Diffusion}}: {{A Topological Perspective}} on {{Heterophily}} and {{Oversmoothing}} in {{GNNs}}},
  shorttitle = {Neural {{Sheaf Diffusion}}},
  author = {Bodnar, Cristian and Di Giovanni, Francesco and Chamberlain, Benjamin Paul and Liò, Pietro and Bronstein, Michael M.},
  date = {2022-02-09},
  eprint = {2202.04579},
  eprinttype = {arXiv},
  eprintclass = {cs, math},
  url = {http://arxiv.org/abs/2202.04579},
  urldate = {2022-03-17},
  abstract = {Cellular sheaves equip graphs with "geometrical" structure by assigning vector spaces and linear maps to nodes and edges. Graph Neural Networks (GNNs) implicitly assume a graph with a trivial underlying sheaf. This choice is reflected in the structure of the graph Laplacian operator, the properties of the associated diffusion equation, and the characteristics of the convolutional models that discretise this equation. In this paper, we use cellular sheaf theory to show that the underlying geometry of the graph is deeply linked with the performance of GNNs in heterophilic settings and their oversmoothing behaviour. By considering a hierarchy of increasingly general sheaves, we study how the ability of the sheaf diffusion process to achieve linear separation of the classes in the infinite time limit expands. At the same time, we prove that when the sheaf is non-trivial, discretised parametric diffusion processes have greater control than GNNs over their asymptotic behaviour. On the practical side, we study how sheaves can be learned from data. The resulting sheaf diffusion models have many desirable properties that address the limitations of classical graph diffusion equations (and corresponding GNN models) and obtain state-of-the-art results in heterophilic settings. Overall, our work provides new connections between GNNs and algebraic topology and would be of interest to both fields.},
  keywords = {Computer Science - Machine Learning,Mathematics - Algebraic Topology},
  file = {/Users/marcel/Zotero/storage/246E963V/Bodnar et al. - 2022 - Neural Sheaf Diffusion A Topological Perspective .pdf;/Users/marcel/Zotero/storage/YA2S6Y9W/2202.html}
}

@online{bodnarWeisfeilerLehmanGo2021,
  title = {Weisfeiler and {{Lehman Go Topological}}: {{Message Passing Simplicial Networks}}},
  shorttitle = {Weisfeiler and {{Lehman Go Topological}}},
  author = {Bodnar, Cristian and Frasca, Fabrizio and Wang, Yu Guang and Otter, Nina and Montúfar, Guido and Liò, Pietro and Bronstein, Michael},
  date = {2021-06-14},
  eprint = {2103.03212},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2103.03212},
  url = {http://arxiv.org/abs/2103.03212},
  urldate = {2022-12-01},
  abstract = {The pairwise interaction paradigm of graph machine learning has predominantly governed the modelling of relational systems. However, graphs alone cannot capture the multi-level interactions present in many complex systems and the expressive power of such schemes was proven to be limited. To overcome these limitations, we propose Message Passing Simplicial Networks (MPSNs), a class of models that perform message passing on simplicial complexes (SCs). To theoretically analyse the expressivity of our model we introduce a Simplicial Weisfeiler-Lehman (SWL) colouring procedure for distinguishing non-isomorphic SCs. We relate the power of SWL to the problem of distinguishing non-isomorphic graphs and show that SWL and MPSNs are strictly more powerful than the WL test and not less powerful than the 3-WL test. We deepen the analysis by comparing our model with traditional graph neural networks (GNNs) with ReLU activations in terms of the number of linear regions of the functions they can represent. We empirically support our theoretical claims by showing that MPSNs can distinguish challenging strongly regular graphs for which GNNs fail and, when equipped with orientation equivariant layers, they can improve classification accuracy in oriented SCs compared to a GNN baseline.},
  pubstate = {prepublished},
  keywords = {Computer Science - Machine Learning,Computer Science - Social and Information Networks},
  file = {/Users/marcel/Zotero/storage/62LFG727/Bodnar et al. - 2021 - Weisfeiler and Lehman Go Topological Message Pass.pdf;/Users/marcel/Zotero/storage/FIA7A46B/2103.html}
}

@online{BrainPerformanceFLOPS2015,
  title = {Brain Performance in {{FLOPS}}},
  date = {2015-07-26T12:33:41-07:00},
  url = {https://aiimpacts.org/brain-performance-in-flops/},
  urldate = {2022-12-01},
  abstract = {The computing power needed to replicate the human brain's relevant activities has been estimated by various authors, with answers ranging from~1012~to 1028 FLOPS. Details Notes We have not investigated the brain's performance in FLOPS in detail, nor substantially reviewed the literature since 2015. This page summarizes others' estimates that we are aware of, as well...},
  langid = {american},
  organization = {AI Impacts},
  file = {/Users/marcel/Zotero/storage/ARLNG952/brain-performance-in-flops.html}
}

@book{briggsDFTOwnerManual1995,
  title = {The {{DFT}}: An Owner's Manual for the Discrete {{Fourier}} Transform},
  shorttitle = {The {{DFT}}},
  author = {Briggs, William L. and Henson, Van Emden},
  date = {1995},
  publisher = {{Society for Industrial and Applied Mathematics}},
  location = {Philadelphia},
  isbn = {978-0-89871-342-8},
  pagetotal = {434},
  keywords = {Fourier transformations}
}

@online{bronsteinGeometricDeepLearning2021,
  title = {Geometric {{Deep Learning}}: {{Grids}}, {{Groups}}, {{Graphs}}, {{Geodesics}}, and {{Gauges}}},
  shorttitle = {Geometric {{Deep Learning}}},
  author = {Bronstein, Michael M. and Bruna, Joan and Cohen, Taco and Veličković, Petar},
  date = {2021-05-02},
  eprint = {2104.13478},
  eprinttype = {arXiv},
  eprintclass = {cs, stat},
  doi = {10.48550/arXiv.2104.13478},
  url = {http://arxiv.org/abs/2104.13478},
  urldate = {2022-09-22},
  abstract = {The last decade has witnessed an experimental revolution in data science and machine learning, epitomised by deep learning methods. Indeed, many high-dimensional learning tasks previously thought to be beyond reach -- such as computer vision, playing Go, or protein folding -- are in fact feasible with appropriate computational scale. Remarkably, the essence of deep learning is built from two simple algorithmic principles: first, the notion of representation or feature learning, whereby adapted, often hierarchical, features capture the appropriate notion of regularity for each task, and second, learning by local gradient-descent type methods, typically implemented as backpropagation. While learning generic functions in high dimensions is a cursed estimation problem, most tasks of interest are not generic, and come with essential pre-defined regularities arising from the underlying low-dimensionality and structure of the physical world. This text is concerned with exposing these regularities through unified geometric principles that can be applied throughout a wide spectrum of applications. Such a 'geometric unification' endeavour, in the spirit of Felix Klein's Erlangen Program, serves a dual purpose: on one hand, it provides a common mathematical framework to study the most successful neural network architectures, such as CNNs, RNNs, GNNs, and Transformers. On the other hand, it gives a constructive procedure to incorporate prior physical knowledge into neural architectures and provide principled way to build future architectures yet to be invented.},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computational Geometry,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/marcel/Zotero/storage/HKQ8WGWC/Bronstein et al. - 2021 - Geometric Deep Learning Grids, Groups, Graphs, Ge.pdf;/Users/marcel/Zotero/storage/GI3THZXN/2104.html}
}

@online{bronsteinOversquashingBottlenecksGraph2021,
  title = {Over-Squashing, {{Bottlenecks}}, and {{Graph Ricci}} Curvature},
  author = {Bronstein, Michael},
  date = {2021-11-30T16:32:40},
  url = {https://towardsdatascience.com/over-squashing-bottlenecks-and-graph-ricci-curvature-c238b7169e16},
  urldate = {2022-05-13},
  abstract = {A concept from differential geometry called Ricci curvature allows to understand the phenomena of over-squashing and bottlenecks in GNNs},
  langid = {english},
  organization = {Medium}
}

@online{brownLanguageModelsAre2020,
  title = {Language {{Models}} Are {{Few-Shot Learners}}},
  author = {Brown, Tom B. and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and Agarwal, Sandhini and Herbert-Voss, Ariel and Krueger, Gretchen and Henighan, Tom and Child, Rewon and Ramesh, Aditya and Ziegler, Daniel M. and Wu, Jeffrey and Winter, Clemens and Hesse, Christopher and Chen, Mark and Sigler, Eric and Litwin, Mateusz and Gray, Scott and Chess, Benjamin and Clark, Jack and Berner, Christopher and McCandlish, Sam and Radford, Alec and Sutskever, Ilya and Amodei, Dario},
  date = {2020-07-22},
  eprint = {2005.14165},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2005.14165},
  url = {http://arxiv.org/abs/2005.14165},
  urldate = {2022-09-22},
  abstract = {Recent work has demonstrated substantial gains on many NLP tasks and benchmarks by pre-training on a large corpus of text followed by fine-tuning on a specific task. While typically task-agnostic in architecture, this method still requires task-specific fine-tuning datasets of thousands or tens of thousands of examples. By contrast, humans can generally perform a new language task from only a few examples or from simple instructions - something which current NLP systems still largely struggle to do. Here we show that scaling up language models greatly improves task-agnostic, few-shot performance, sometimes even reaching competitiveness with prior state-of-the-art fine-tuning approaches. Specifically, we train GPT-3, an autoregressive language model with 175 billion parameters, 10x more than any previous non-sparse language model, and test its performance in the few-shot setting. For all tasks, GPT-3 is applied without any gradient updates or fine-tuning, with tasks and few-shot demonstrations specified purely via text interaction with the model. GPT-3 achieves strong performance on many NLP datasets, including translation, question-answering, and cloze tasks, as well as several tasks that require on-the-fly reasoning or domain adaptation, such as unscrambling words, using a novel word in a sentence, or performing 3-digit arithmetic. At the same time, we also identify some datasets where GPT-3's few-shot learning still struggles, as well as some datasets where GPT-3 faces methodological issues related to training on large web corpora. Finally, we find that GPT-3 can generate samples of news articles which human evaluators have difficulty distinguishing from articles written by humans. We discuss broader societal impacts of this finding and of GPT-3 in general.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computation and Language},
  file = {/Users/marcel/Zotero/storage/A3S76FE7/Brown et al. - 2020 - Language Models are Few-Shot Learners.pdf;/Users/marcel/Zotero/storage/GTIWYHFS/2005.html}
}

@inproceedings{buchelGradientDescentbasedProgramming2022,
  title = {Gradient Descent-Based Programming of Analog in-Memory Computing Cores},
  booktitle = {2022 {{International Electron Devices Meeting}} ({{IEDM}})},
  author = {Büchel, J. and Vasilopoulos, A. and Kersting, B. and Odermatt, F. and Brew, K. and Ok, I. and Choi, S. and Saraf, I. and Chan, V. and Philip, T. and Saulnier, N. and Narayanan, V. and Gallo, M. Le and Sebastian, A.},
  date = {2022-12},
  pages = {33.1.1-33.1.4},
  issn = {2156-017X},
  doi = {10.1109/IEDM45625.2022.10019486},
  url = {https://ieeexplore.ieee.org/document/10019486},
  urldate = {2023-10-20},
  abstract = {The precise programming of crossbar arrays of unit-cells is crucial for obtaining high matrix-vector-multiplication (MVM) accuracy in analog in-memory computing (AIMC) cores. We propose a radically different approach based on directly minimizing the MVM error using gradient descent with synthetic random input data. Our method significantly reduces the MVM error compared with conventional unit-cell by unit-cell iterative programming. It also eliminates the need for high-resolution analog-to-digital converters (ADCs) to read the small unit-cell conductance during programming. Our method improves the experimental inference accuracy of ResNet-9 implemented on two phase-change memory (PCM)-based AIMC cores by 1.26\%.},
  eventtitle = {2022 {{International Electron Devices Meeting}} ({{IEDM}})},
  file = {/Users/marcel/Zotero/storage/Y4Y4TZ4U/Büchel et al. - 2022 - Gradient descent-based programming of analog in-memory computing cores.pdf;/Users/marcel/Zotero/storage/DLLXXC9D/10019486.html}
}

@article{buckleyPhotonicOnlineLearning2023,
  title = {Photonic Online Learning: A Perspective},
  shorttitle = {Photonic Online Learning},
  author = {Buckley, Sonia Mary and Tait, Alexander N. and McCaughan, Adam N. and Shastri, Bhavin J.},
  date = {2023-03-01},
  journaltitle = {Nanophotonics},
  volume = {12},
  number = {5},
  pages = {833--845},
  publisher = {De Gruyter},
  issn = {2192-8614},
  doi = {10.1515/nanoph-2022-0553},
  url = {https://www.degruyter.com/document/doi/10.1515/nanoph-2022-0553/html},
  urldate = {2023-11-10},
  abstract = {Emerging neuromorphic hardware promises to solve certain problems faster and with higher energy efficiency than traditional computing by using physical processes that take place at the device level as the computational primitives in neural networks. While initial results in photonic neuromorphic hardware are very promising, such hardware requires programming or “training” that is often power-hungry and time-consuming. In this article, we examine the online learning paradigm, where the machinery for training is built deeply into the hardware itself. We argue that some form of online learning will be necessary if photonic neuromorphic hardware is to achieve its true potential.},
  langid = {english},
  keywords = {integrated photonics,neural networks,neuromorphic photonics},
  file = {/Users/marcel/Zotero/storage/EE7LSAYQ/Buckley et al. - 2023 - Photonic online learning a perspective.pdf}
}

@online{burnsDiscoveringLatentKnowledge2024,
  title = {Discovering {{Latent Knowledge}} in {{Language Models Without Supervision}}},
  author = {Burns, Collin and Ye, Haotian and Klein, Dan and Steinhardt, Jacob},
  date = {2024-03-02},
  eprint = {2212.03827},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2212.03827},
  url = {http://arxiv.org/abs/2212.03827},
  urldate = {2024-03-15},
  abstract = {Existing techniques for training language models can be misaligned with the truth: if we train models with imitation learning, they may reproduce errors that humans make; if we train them to generate text that humans rate highly, they may output errors that human evaluators can't detect. We propose circumventing this issue by directly finding latent knowledge inside the internal activations of a language model in a purely unsupervised way. Specifically, we introduce a method for accurately answering yes-no questions given only unlabeled model activations. It works by finding a direction in activation space that satisfies logical consistency properties, such as that a statement and its negation have opposite truth values. We show that despite using no supervision and no model outputs, our method can recover diverse knowledge represented in large language models: across 6 models and 10 question-answering datasets, it outperforms zero-shot accuracy by 4\textbackslash\% on average. We also find that it cuts prompt sensitivity in half and continues to maintain high accuracy even when models are prompted to generate incorrect answers. Our results provide an initial step toward discovering what language models know, distinct from what they say, even when we don't have access to explicit ground truth labels.},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Machine Learning},
  file = {/Users/marcel/Zotero/storage/9T3L9XZ9/Burns et al. - 2024 - Discovering Latent Knowledge in Language Models Without Supervision.pdf;/Users/marcel/Zotero/storage/79TM6TJW/2212.html}
}

@article{buscarinoRobustnessNoiseSynchronization2013,
  title = {Robustness to Noise in Synchronization of Complex Networks},
  author = {Buscarino, Arturo and Gambuzza, Lucia Valentina and Porfiri, Maurizio and Fortuna, Luigi and Frasca, Mattia},
  date = {2013-06-19},
  journaltitle = {Scientific Reports},
  shortjournal = {Sci Rep},
  volume = {3},
  number = {1},
  pages = {2026},
  publisher = {Nature Publishing Group},
  issn = {2045-2322},
  doi = {10.1038/srep02026},
  url = {https://www.nature.com/articles/srep02026},
  urldate = {2023-11-17},
  abstract = {In this report, we investigate dynamical robustness of a complex network to noise injected through one of its nodes. We focus on synchronization of coupled nonlinear systems and, as a special instance, we address the classical consensus protocol for linear integrators. We establish an exact closed-form expression of the synchronization error for the consensus protocol and an approximate result for chaotic units. While structural robustness is known to be significantly affected by attacks targeted to network hubs, our results posit that dynamical robustness is controlled by both the topology of the network and the dynamics of the units. We provide examples where hubs perform better or worse than isolated nodes.},
  issue = {1},
  langid = {english},
  keywords = {Complex networks,Electrical and electronic engineering,Nonlinear phenomena,Statistical physics},
  file = {/Users/marcel/Zotero/storage/ZMMSEZVD/Buscarino et al. - 2013 - Robustness to noise in synchronization of complex networks.pdf}
}

@article{buttsSynchronizationCommunicationMassively2007,
  title = {Synchronization through {{Communication}} in a {{Massively Parallel Processor Array}}},
  author = {Butts, Mike},
  date = {2007-09},
  journaltitle = {IEEE Micro},
  volume = {27},
  number = {5},
  pages = {32--40},
  issn = {1937-4143},
  doi = {10.1109/MM.2007.4378781},
  abstract = {Programming MPPAs for complex real-time embedded applications is difficult with conventional multiprogramming models, which usually treat communication and synchronization separately. Based on a programming model for massively parallel embedded computing that is reasonable and productive for software developers, we developed a scalable MPPA chip architecture that delivers tera-ops performance with very good energy efficiency in an ordinary 130-nm ASIC. This MPPA's architecture is based on the structural object programming model, which composes strictly encapsulated processing and memory objects in a structure of self-synchronizing channels. Small RISC CPUs and memories execute the objects.},
  eventtitle = {{{IEEE Micro}}},
  keywords = {Application software,Application specific integrated circuits,Computer architecture,High definition video,Integrated circuit interconnections,multicore architectures,multiple data stream processors,multiprocessors,Packet switching,parallel architectures,Parallel programming,Reduced instruction set computing,Registers,Sensor arrays,synchronization},
  file = {/Users/marcel/Zotero/storage/IBRLPCWW/4378781.html}
}

@article{buzsakiLogdynamicBrainHow2014,
  title = {The Log-Dynamic Brain: How Skewed Distributions Affect Network Operations},
  shorttitle = {The Log-Dynamic Brain},
  author = {Buzsáki, György and Mizuseki, Kenji},
  date = {2014-04},
  journaltitle = {Nature Reviews Neuroscience},
  shortjournal = {Nat Rev Neurosci},
  volume = {15},
  number = {4},
  pages = {264--278},
  publisher = {Nature Publishing Group},
  issn = {1471-0048},
  doi = {10.1038/nrn3687},
  url = {https://www.nature.com/articles/nrn3687},
  urldate = {2022-05-02},
  abstract = {At many physiological and anatomical levels in the brain, the distribution of numerous parameters is strongly skewed with a heavy tail and typically follows a lognormal distribution.The power and frequency relationship of brain oscillations is typically expressed in a log scale.Network synchrony, measured as a fraction of spiking neurons in a given time window, shows lognormal distribution in all brain states.Firing rates, spike bursts and synaptic weights follow a lognormal distribution. Importantly, these parameters remain correlated across brain states, environments and situations.The log-dynamic patterns of networks may be supported by the lognormal distribution of corticocortical connections strengths and axon diameters.A preconfigured, strongly connected minority of fast-firing neurons form the backbone of brain connectivity and serve as an ever-ready, fast-acting system. However, full performance of the brain also depends on the activity of very large numbers of weakly connected and slow-firing majority of neurons.},
  issue = {4},
  langid = {english},
  keywords = {Cellular neuroscience,Spine regulation and structure,Synaptic transmission},
  file = {/Users/marcel/Zotero/storage/IVNQQPKR/Buzsáki and Mizuseki - 2014 - The log-dynamic brain how skewed distributions af.pdf;/Users/marcel/Zotero/storage/BGXXSWFN/nrn3687.html}
}

@article{bystromCIDERExpressiveNonlocal2022,
  title = {{{CIDER}}: {{An Expressive}}, {{Nonlocal Feature Set}} for {{Machine Learning Density Functionals}} with {{Exact Constraints}}},
  shorttitle = {{{CIDER}}},
  author = {Bystrom, Kyle and Kozinsky, Boris},
  date = {2022-04-12},
  journaltitle = {Journal of Chemical Theory and Computation},
  shortjournal = {J. Chem. Theory Comput.},
  volume = {18},
  number = {4},
  eprint = {2109.02788},
  eprinttype = {arXiv},
  eprintclass = {physics},
  pages = {2180--2192},
  issn = {1549-9618, 1549-9626},
  doi = {10.1021/acs.jctc.1c00904},
  url = {http://arxiv.org/abs/2109.02788},
  urldate = {2023-01-10},
  abstract = {Machine learning (ML) has recently gained attention as a means to develop more accurate exchange-correlation (XC) functionals for density functional theory, but functionals developed thus far need to be improved on several metrics, including accuracy, numerical stability, and transferability across chemical space. In this work, we introduce a set of nonlocal features of the density called the CIDER formalism, which we use to train a Gaussian process model for the exchange energy that obeys the critical uniform scaling rule for exchange. The resulting CIDER exchange functional is significantly more accurate than any semi-local functional tested here, and it has good transferability across main-group molecules. This work therefore serves as an initial step toward more accurate exchange functionals, and it also introduces useful techniques for developing robust, physics-informed XC models via ML.},
  keywords = {Physics - Chemical Physics,Physics - Computational Physics},
  file = {/Users/marcel/Zotero/storage/MJNJBZES/Bystrom and Kozinsky - 2022 - CIDER An Expressive, Nonlocal Feature Set for Mac.pdf;/Users/marcel/Zotero/storage/UDVWK45R/2109.html}
}

@incollection{carterPositiveNegativeLiberty2022,
  title = {Positive and {{Negative Liberty}}},
  booktitle = {The {{Stanford Encyclopedia}} of {{Philosophy}}},
  author = {Carter, Ian},
  editor = {Zalta, Edward N.},
  date = {2022},
  edition = {Spring 2022},
  publisher = {Metaphysics Research Lab, Stanford University},
  url = {https://plato.stanford.edu/archives/spr2022/entries/liberty-positive-negative/},
  urldate = {2022-04-10},
  abstract = {Negative liberty is the absence of obstacles, barriers or constraints.One has negative liberty to the extent that actions are available toone in this negative sense. Positive liberty is the possibility ofacting — or the fact of acting — in such a way as to takecontrol of one’s life and realize one’s fundamentalpurposes. While negative liberty is usually attributed to individualagents, positive liberty is sometimes attributed to collectivities, orto individuals considered primarily as members of givencollectivities., The idea of distinguishing between a negative and a positive sense ofthe term ‘liberty’ goes back at least to Kant, and wasexamined and defended in depth by Isaiah Berlin in the 1950s and’60s. Discussions about positive and negative liberty normallytake place within the context of political and social philosophy. Theyare distinct from, though sometimes related to, philosophicaldiscussions about free will. Work on the nature of positive liberty often overlaps, however, withwork on the nature of autonomy., As Berlin showed, negative and positive liberty are not merely twodistinct kinds of liberty; they can be seen as rival, incompatibleinterpretations of a single political ideal. Since few people claim tobe against liberty, the way this term is interpreted and defined canhave important political implications. Political liberalism tends to presuppose a negative definition of liberty: liberalsgenerally claim that if one favors individual liberty one should placestrong limitations on the activities of the state. Critics ofliberalism often contest this implication by contesting the negativedefinition of liberty: they argue that the pursuit of libertyunderstood as self-realization or as self-determination (whether ofthe individual or of the collectivity) can require state interventionof a kind not normally allowed by liberals., Many authors prefer to talk of positive and negative freedom.This is only a difference of style, and the terms‘liberty’ and ‘freedom’ are normally usedinterchangeably by political and social philosophers. Although someattempts have been made to distinguish between liberty and freedom(Pitkin 1988; Williams 2001; Dworkin 2011), generally speaking thesehave not caught on. Neither can they be translated into other Europeanlanguages, which contain only the one term, of either Latin orGermanic origin (e.g. liberté, Freiheit), where Englishcontains both.},
  keywords = {abilities,action,autonomy: in moral and political philosophy,autonomy: personal,Berlin Isaiah,civil rights,coercion,free will,freedom: of speech,legal rights,liberalism,libertarianism,limits of law,paternalism,republicanism,rights,rights: human},
  file = {/Users/marcel/Zotero/storage/23WIHMMC/liberty-positive-negative.html}
}

@article{chabassierModelingSimulationGrand2013,
  title = {Modeling and Simulation of a Grand Piano},
  author = {Chabassier, Juliette and Chaigne, Antoine and Joly, Patrick},
  date = {2013-07-01},
  journaltitle = {The Journal of the Acoustical Society of America},
  volume = {134},
  number = {1},
  pages = {648--665},
  issn = {0001-4966, 1520-8524},
  doi = {10.1121/1.4809649},
  url = {https://pubs.aip.org/jasa/article/134/1/648/614365/Modeling-and-simulation-of-a-grand-piano},
  urldate = {2024-01-27},
  abstract = {A time-domain global modeling of a grand piano is presented. The string model includes internal losses, stiffness, and geometrical nonlinearity. The hammer-string interaction is governed by a nonlinear dissipative compression force. The soundboard is modeled as a dissipative bidimensional orthotropic Reissner–Mindlin plate where the presence of ribs and bridges is treated as local heterogeneities. The coupling between strings and soundboard at the bridge allows the transmission of both transverse and longitudinal waves to the soundboard. The soundboard is coupled to the acoustic field, whereas all other parts of the structure are supposed to be perfectly rigid. The acoustic field is bounded artificially using perfectly matched layers. The discrete form of the equations is based on original energy preserving schemes. Artificial decoupling is achieved, through the use of Schur complements and Lagrange multipliers, so that each variable of the problem can be updated separately at each time step. The capability of the model is highlighted by series of simulations in the low, medium, and high register, and through comparisons with waveforms recorded on a Steinway D piano. Its ability to account for phantom partials and precursors, consecutive to string nonlinearity and inharmonicity, is particularly emphasized.},
  langid = {english},
  file = {/Users/marcel/Zotero/storage/I96VD5UZ/Chabassier et al. - 2013 - Modeling and simulation of a grand piano.pdf}
}

@online{chamberlainBeltramiFlowNeural2021a,
  title = {Beltrami {{Flow}} and {{Neural Diffusion}} on {{Graphs}}},
  author = {Chamberlain, Benjamin Paul and Rowbottom, James and Eynard, Davide and Di Giovanni, Francesco and Dong, Xiaowen and Bronstein, Michael M.},
  date = {2021-10-18},
  eprint = {2110.09443},
  eprinttype = {arXiv},
  eprintclass = {cs, stat},
  doi = {10.48550/arXiv.2110.09443},
  url = {http://arxiv.org/abs/2110.09443},
  urldate = {2022-07-04},
  abstract = {We propose a novel class of graph neural networks based on the discretised Beltrami flow, a non-Euclidean diffusion PDE. In our model, node features are supplemented with positional encodings derived from the graph topology and jointly evolved by the Beltrami flow, producing simultaneously continuous feature learning and topology evolution. The resulting model generalises many popular graph neural networks and achieves state-of-the-art results on several benchmarks.},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/marcel/Zotero/storage/SYW7Q4MD/Chamberlain et al. - 2021 - Beltrami Flow and Neural Diffusion on Graphs.pdf;/Users/marcel/Zotero/storage/QGQP35M9/2110.html}
}

@unpublished{chamberlainGRANDGraphNeural2021,
  title = {{{GRAND}}: {{Graph Neural Diffusion}}},
  shorttitle = {{{GRAND}}},
  author = {Chamberlain, Benjamin Paul and Rowbottom, James and Gorinova, Maria and Webb, Stefan and Rossi, Emanuele and Bronstein, Michael M.},
  date = {2021-09-22},
  eprint = {2106.10934},
  eprinttype = {arXiv},
  eprintclass = {cs, stat},
  url = {http://arxiv.org/abs/2106.10934},
  urldate = {2022-04-24},
  abstract = {We present Graph Neural Diffusion (GRAND) that approaches deep learning on graphs as a continuous diffusion process and treats Graph Neural Networks (GNNs) as discretisations of an underlying PDE. In our model, the layer structure and topology correspond to the discretisation choices of temporal and spatial operators. Our approach allows a principled development of a broad new class of GNNs that are able to address the common plights of graph learning models such as depth, oversmoothing, and bottlenecks. Key to the success of our models are stability with respect to perturbations in the data and this is addressed for both implicit and explicit discretisation schemes. We develop linear and nonlinear versions of GRAND, which achieve competitive results on many standard graph benchmarks.},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/marcel/Zotero/storage/GMWRQIGK/Chamberlain et al. - 2021 - GRAND Graph Neural Diffusion.pdf;/Users/marcel/Zotero/storage/84TLAZQ9/2106.html}
}

@article{chenDeepLabSemanticImage2016,
  title = {{{DeepLab}}: {{Semantic Image Segmentation}} with {{Deep Convolutional Nets}}, {{Atrous Convolution}}, and {{Fully Connected CRFs}}},
  shorttitle = {{{DeepLab}}},
  author = {Chen, Liang-Chieh and Papandreou, George and Kokkinos, Iasonas and Murphy, Kevin and Yuille, Alan L.},
  date = {2016-06-02},
  doi = {10.48550/arXiv.1606.00915},
  url = {https://arxiv.org/abs/1606.00915v2},
  urldate = {2022-12-18},
  abstract = {In this work we address the task of semantic image segmentation with Deep Learning and make three main contributions that are experimentally shown to have substantial practical merit. First, we highlight convolution with upsampled filters, or 'atrous convolution', as a powerful tool in dense prediction tasks. Atrous convolution allows us to explicitly control the resolution at which feature responses are computed within Deep Convolutional Neural Networks. It also allows us to effectively enlarge the field of view of filters to incorporate larger context without increasing the number of parameters or the amount of computation. Second, we propose atrous spatial pyramid pooling (ASPP) to robustly segment objects at multiple scales. ASPP probes an incoming convolutional feature layer with filters at multiple sampling rates and effective fields-of-views, thus capturing objects as well as image context at multiple scales. Third, we improve the localization of object boundaries by combining methods from DCNNs and probabilistic graphical models. The commonly deployed combination of max-pooling and downsampling in DCNNs achieves invariance but has a toll on localization accuracy. We overcome this by combining the responses at the final DCNN layer with a fully connected Conditional Random Field (CRF), which is shown both qualitatively and quantitatively to improve localization performance. Our proposed "DeepLab" system sets the new state-of-art at the PASCAL VOC-2012 semantic image segmentation task, reaching 79.7\% mIOU in the test set, and advances the results on three other datasets: PASCAL-Context, PASCAL-Person-Part, and Cityscapes. All of our code is made publicly available online.},
  langid = {english},
  file = {/Users/marcel/Zotero/storage/4SKZUYUW/Chen et al. - 2016 - DeepLab Semantic Image Segmentation with Deep Con.pdf}
}

@unpublished{chenEquivariantPointNetwork2021,
  title = {Equivariant {{Point Network}} for {{3D Point Cloud Analysis}}},
  author = {Chen, Haiwei and Liu, Shichen and Chen, Weikai and Li, Hao},
  date = {2021-04-02},
  eprint = {2103.14147},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2103.14147},
  urldate = {2021-07-27},
  abstract = {Features that are equivariant to a larger group of symmetries have been shown to be more discriminative and powerful in recent studies. However, higher-order equivariant features often come with an exponentially-growing computational cost. Furthermore, it remains relatively less explored how rotation-equivariant features can be leveraged to tackle 3D shape alignment tasks. While many past approaches have been based on either non-equivariant or invariant descriptors to align 3D shapes, we argue that such tasks may benefit greatly from an equivariant framework. In this paper, we propose an effective and practical SE(3) (3D translation and rotation) equivariant network for point cloud analysis that addresses both problems. First, we present SE(3) separable point convolution, a novel framework that breaks down the 6D convolution into two separable convolutional operators alternatively performed in the 3D Euclidean and SO(3) spaces. This significantly reduces the computational cost without compromising the performance. Second, we introduce an attention layer to effectively harness the expressiveness of the equivariant features. While jointly trained with the network, the attention layer implicitly derives the intrinsic local frame in the feature space and generates attention vectors that can be integrated into different alignment tasks. We evaluate our approach through extensive studies and visual interpretations. The empirical results demonstrate that our proposed model outperforms strong baselines in a variety of benchmarks},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {/Users/marcel/Zotero/storage/7A7Q65WK/Chen et al_2021_Equivariant Point Network for 3D Point Cloud Analysis.pdf;/Users/marcel/Zotero/storage/AK39UPC4/2103.html}
}

@online{chenMeasuringRelievingOversmoothing2019,
  title = {Measuring and {{Relieving}} the {{Over-smoothing Problem}} for {{Graph Neural Networks}} from the {{Topological View}}},
  author = {Chen, Deli and Lin, Yankai and Li, Wei and Li, Peng and Zhou, Jie and Sun, Xu},
  date = {2019-11-18},
  eprint = {1909.03211},
  eprinttype = {arXiv},
  eprintclass = {cs, stat},
  url = {http://arxiv.org/abs/1909.03211},
  urldate = {2022-09-22},
  abstract = {Graph Neural Networks (GNNs) have achieved promising performance on a wide range of graph-based tasks. Despite their success, one severe limitation of GNNs is the over-smoothing issue (indistinguishable representations of nodes in different classes). In this work, we present a systematic and quantitative study on the over-smoothing issue of GNNs. First, we introduce two quantitative metrics, MAD and MADGap, to measure the smoothness and over-smoothness of the graph nodes representations, respectively. Then, we verify that smoothing is the nature of GNNs and the critical factor leading to over-smoothness is the low information-to-noise ratio of the message received by the nodes, which is partially determined by the graph topology. Finally, we propose two methods to alleviate the over-smoothing issue from the topological view: (1) MADReg which adds a MADGap-based regularizer to the training objective;(2) AdaGraph which optimizes the graph topology based on the model predictions. Extensive experiments on 7 widely-used graph datasets with 10 typical GNN models show that the two proposed methods are effective for relieving the over-smoothing issue, thus improving the performance of various GNN models.},
  pubstate = {prepublished},
  keywords = {Computer Science - Machine Learning,Computer Science - Social and Information Networks,Statistics - Machine Learning},
  file = {/Users/marcel/Zotero/storage/TSMR7SDY/Chen et al. - 2019 - Measuring and Relieving the Over-smoothing Problem.pdf;/Users/marcel/Zotero/storage/C9U58B4K/1909.html}
}

@inproceedings{chenNeuralOrdinaryDifferential2018,
  title = {Neural {{Ordinary Differential Equations}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Chen, Ricky T. Q. and Rubanova, Yulia and Bettencourt, Jesse and Duvenaud, David K},
  date = {2018},
  volume = {31},
  publisher = {Curran Associates, Inc.},
  url = {https://papers.nips.cc/paper/2018/hash/69386f6bb1dfed68692a24c8686939b9-Abstract.html},
  urldate = {2022-09-12},
  abstract = {We introduce a new family of deep neural network models. Instead of specifying a discrete sequence of hidden layers, we parameterize the derivative of the hidden state using a neural network. The output of the network is computed using a blackbox differential equation solver. These continuous-depth models have constant memory cost, adapt their evaluation strategy to each input, and can explicitly trade numerical precision for speed. We demonstrate these properties in continuous-depth residual networks and continuous-time latent variable models. We also construct continuous normalizing flows, a generative model that can train by maximum likelihood, without partitioning or ordering the data dimensions. For training, we show how to scalably backpropagate through any ODE solver, without access to its internal operations. This allows end-to-end training of ODEs within larger models.},
  file = {/Users/marcel/Zotero/storage/AX2QCDBI/Chen et al. - 2018 - Neural Ordinary Differential Equations.pdf}
}

@inproceedings{chentanezLiquidSimulationLatticebased2007,
  title = {Liquid Simulation on Lattice-Based Tetrahedral Meshes},
  author = {Chentanez, Nuttapong and Feldman, Bryan and Labelle, François and O'Brien, James and Shewchuk, Jonathan},
  date = {2007-08-05},
  pages = {219--228},
  doi = {10.1145/1281740.1281819},
  abstract = {We describe a method for animating incompressible liquids with detailed free surfaces. For each time step, semi-Lagrangian contouring computes a new fluid boundary (represented as a fine surface triangulation) from the previous time step's fluid boundary and velocity field. Then a mesh generation algorithm called isosurface stuffing discretizes the region enclosed by the new fluid boundary, creating a tetrahedral mesh that grades from a fine resolution at the surface to a coarser resolution in the interior. The mesh has a structure, based on the body centered cubic lattice, that accommodates graded tetrahedron sizes but is regular enough to aid efficient point location and to save memory used to store geometric properties of identical tetrahedra. Although the mesh is warped to conform to the liquid boundary, it has a mathematical guarantee on tetrahedron quality, and is generated very rapidly. Each successive time step entails creating a new triangulated liquid surface and a new tetrahedral mesh. Semi-Lagrangian advection computes velocities at the current time step on the new mesh. We use a finite volume discretization to perform pressure projection required to enforce the fluid's incompressibility, and we solve the linear system with algebraic multigrid. A novel thickening scheme prevents thin sheets and droplets of liquid from vanishing when their thicknesses drop below the mesh resolution. Examples demonstrate that the method captures complex liquid motions and fine details on the free surfaces without suffering from excessive volume loss or artificial damping.},
  file = {/Users/marcel/Zotero/storage/U4Y6UBVJ/Chentanez et al. - 2007 - Liquid simulation on lattice-based tetrahedral mes.pdf}
}

@unpublished{cmscollaborationDeepNeuralNetwork2020,
  title = {A Deep Neural Network for Simultaneous Estimation of b Jet Energy and Resolution},
  author = {CMS Collaboration},
  date = {2020-11-05},
  eprint = {1912.06046},
  eprinttype = {arXiv},
  eprintclass = {hep-ex, physics:physics},
  doi = {10.1007/s41781-020-00041-z},
  url = {http://arxiv.org/abs/1912.06046},
  urldate = {2021-09-27},
  abstract = {We describe a method to obtain point and dispersion estimates for the energies of jets arising from b quarks produced in proton-proton collisions at an energy of \$\textbackslash sqrt\{s\} =\$ 13 TeV at the CERN LHC. The algorithm is trained on a large simulated sample of b jets and validated on data recorded by the CMS detector in 2017 corresponding to an integrated luminosity of 41 fb\$\textasciicircum\{-1\}\$. A multivariate regression algorithm based on a deep feed-forward neural network employs jet composition and shape information, and the properties of reconstructed secondary vertices associated with the jet. The results of the algorithm are used to improve the sensitivity of analyses that make use of b jets in the final state, such as the observation of Higgs boson decay to \$\textbackslash mathrm\{b\textbackslash bar\{b\}\}\$.},
  keywords = {High Energy Physics - Experiment,Physics - Data Analysis Statistics and Probability},
  file = {/Users/marcel/Zotero/storage/77R3WMC5/CMS Collaboration_2020_A deep neural network for simultaneous estimation of b jet energy and resolution.pdf;/Users/marcel/Zotero/storage/TF3QH7CG/1912.html}
}

@article{cmscollaborationMissingTransverseEnergy2011,
  title = {Missing Transverse Energy Performance of the {{CMS}} Detector},
  author = {CMS Collaboration},
  date = {2011-09-09},
  journaltitle = {Journal of Instrumentation},
  shortjournal = {J. Inst.},
  volume = {6},
  number = {09},
  eprint = {1106.5048},
  eprinttype = {arXiv},
  pages = {P09001-P09001},
  issn = {1748-0221},
  doi = {10.1088/1748-0221/6/09/P09001},
  url = {http://arxiv.org/abs/1106.5048},
  urldate = {2021-07-27},
  abstract = {During 2010 the LHC delivered pp collisions with a centre-of-mass energy of 7 TeV. In this paper, the results of comprehensive studies of missing transverse energy as measured by the CMS detector are presented. The results cover the measurements of the scale and resolution for missing transverse energy, and the effects of multiple pp interactions within the same bunch crossings on the scale and resolution. Anomalous measurements of missing transverse energy are studied, and algorithms for their identification are described. The performances of several reconstruction algorithms for calculating missing transverse energy are compared. An algorithm, called missing-transverse-energy significance, which estimates the compatibility of the reconstructed missing transverse energy with zero, is described, and its performance is demonstrated.},
  keywords = {Physics - Instrumentation and Detectors},
  file = {/Users/marcel/Zotero/storage/LAFE6MHY/CMS Collaboration_2011_Missing transverse energy performance of the CMS detector.pdf;/Users/marcel/Zotero/storage/GK7BEWQV/1106.html}
}

@online{CMSMachineLearning,
  title = {{{CMS}} and the Machine Learning at the Forefront of Data Management | {{CMS Experiment}}},
  url = {https://cms.cern/news/cms-and-machine-learning-forefront-data-management},
  urldate = {2022-12-01},
  file = {/Users/marcel/Zotero/storage/8YHFR6ZZ/cms-and-machine-learning-forefront-data-management.html}
}

@online{cohenGroupEquivariantConvolutional2016,
  title = {Group {{Equivariant Convolutional Networks}}},
  author = {Cohen, Taco S. and Welling, Max},
  date = {2016-06-03},
  eprint = {1602.07576},
  eprinttype = {arXiv},
  eprintclass = {cs, stat},
  url = {http://arxiv.org/abs/1602.07576},
  urldate = {2022-12-01},
  abstract = {We introduce Group equivariant Convolutional Neural Networks (G-CNNs), a natural generalization of convolutional neural networks that reduces sample complexity by exploiting symmetries. G-CNNs use G-convolutions, a new type of layer that enjoys a substantially higher degree of weight sharing than regular convolution layers. G-convolutions increase the expressive capacity of the network without increasing the number of parameters. Group convolution layers are easy to use and can be implemented with negligible computational overhead for discrete groups generated by translations, reflections and rotations. G-CNNs achieve state of the art results on CIFAR10 and rotated MNIST.},
  pubstate = {prepublished},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/marcel/Zotero/storage/7KDP3EV8/Cohen and Welling - 2016 - Group Equivariant Convolutional Networks.pdf;/Users/marcel/Zotero/storage/MDKJACER/1602.html}
}

@unpublished{cohenIntertwinersInducedRepresentations2018,
  title = {Intertwiners between {{Induced Representations}} (with {{Applications}} to the {{Theory}} of {{Equivariant Neural Networks}})},
  author = {Cohen, Taco S. and Geiger, Mario and Weiler, Maurice},
  date = {2018-03-30},
  eprint = {1803.10743},
  eprinttype = {arXiv},
  eprintclass = {cs, stat},
  url = {http://arxiv.org/abs/1803.10743},
  urldate = {2021-07-27},
  abstract = {Group equivariant and steerable convolutional neural networks (regular and steerable G-CNNs) have recently emerged as a very effective model class for learning from signal data such as 2D and 3D images, video, and other data where symmetries are present. In geometrical terms, regular G-CNNs represent data in terms of scalar fields ("feature channels"), whereas the steerable G-CNN can also use vector or tensor fields ("capsules") to represent data. In algebraic terms, the feature spaces in regular G-CNNs transform according to a regular representation of the group G, whereas the feature spaces in Steerable G-CNNs transform according to the more general induced representations of G. In order to make the network equivariant, each layer in a G-CNN is required to intertwine between the induced representations associated with its input and output space. In this paper we present a general mathematical framework for G-CNNs on homogeneous spaces like Euclidean space or the sphere. We show, using elementary methods, that the layers of an equivariant network are convolutional if and only if the input and output feature spaces transform according to an induced representation. This result, which follows from G.W. Mackey's abstract theory on induced representations, establishes G-CNNs as a universal class of equivariant network architectures, and generalizes the important recent work of Kondor \& Trivedi on the intertwiners between regular representations.},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/marcel/Zotero/storage/83LSNKQD/Cohen et al_2018_Intertwiners between Induced Representations (with Applications to the Theory.pdf;/Users/marcel/Zotero/storage/3SNH6WY9/1803.html}
}

@unpublished{cohenSteerableCNNs2016,
  title = {Steerable {{CNNs}}},
  author = {Cohen, Taco S. and Welling, Max},
  date = {2016-12-26},
  eprint = {1612.08498},
  eprinttype = {arXiv},
  eprintclass = {cs, stat},
  url = {http://arxiv.org/abs/1612.08498},
  urldate = {2021-08-13},
  abstract = {It has long been recognized that the invariance and equivariance properties of a representation are critically important for success in many vision tasks. In this paper we present Steerable Convolutional Neural Networks, an efficient and flexible class of equivariant convolutional networks. We show that steerable CNNs achieve state of the art results on the CIFAR image classification benchmark. The mathematical theory of steerable representations reveals a type system in which any steerable representation is a composition of elementary feature types, each one associated with a particular kind of symmetry. We show how the parameter cost of a steerable filter bank depends on the types of the input and output features, and show how to use this knowledge to construct CNNs that utilize parameters effectively.},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/marcel/Zotero/storage/WYH9D7P6/Cohen_Welling_2016_Steerable CNNs.pdf;/Users/marcel/Zotero/storage/745Z5NL7/1612.html}
}

@inproceedings{cordonnierExtrapolatingPathsGraph2019,
  title = {Extrapolating Paths with Graph Neural Networks},
  booktitle = {International {{Joint Conference}} on {{Artificial Intelligence}}},
  author = {Cordonnier, Jean-Baptiste and Loukas, Andreas},
  date = {2019},
  url = {https://api.semanticscholar.org/CorpusID:81978533}
}

@article{corronChaosLinearWave2019,
  title = {Chaos in a Linear Wave Equation},
  author = {Corron, Ned J.},
  date = {2019-06-01},
  journaltitle = {Chaos, Solitons \& Fractals: X},
  shortjournal = {Chaos, Solitons \& Fractals: X},
  volume = {2},
  pages = {100014},
  issn = {2590-0544},
  doi = {10.1016/j.csfx.2019.100014},
  url = {https://www.sciencedirect.com/science/article/pii/S2590054419300120},
  urldate = {2023-11-06},
  abstract = {A linear partial differential equation is shown to exhibit three properties often used to define chaotic dynamics. The system comprises a one-dimensional wave equation with gain that operates on a semi-infinite line. A boundary condition enforces that the waves remain finite. It is shown that the resulting solution set is dense with periodic orbits, contains transitive orbits, and exhibits extreme sensitivity to initial conditions. Definitions of chaos are considered in light of such linear chaos.},
  keywords = {Backward shift,Chaos,Definition of chaos,Linear chaos,Wave equation},
  file = {/Users/marcel/Zotero/storage/4VZNYB87/Corron - 2019 - Chaos in a linear wave equation.pdf}
}

@article{cragoExposingMemoryAccess2018,
  title = {Exposing {{Memory Access Patterns}} to {{Improve Instruction}} and {{Memory Efficiency}} in {{GPUs}}},
  author = {Crago, Neal C. and Stephenson, Mark and Keckler, Stephen W.},
  date = {2018-10-29},
  journaltitle = {ACM Transactions on Architecture and Code Optimization},
  shortjournal = {ACM Trans. Archit. Code Optim.},
  volume = {15},
  number = {4},
  pages = {45:1--45:23},
  issn = {1544-3566},
  doi = {10.1145/3280851},
  url = {https://doi.org/10.1145/3280851},
  urldate = {2022-09-24},
  abstract = {Modern computing workloads often have high memory intensity, requiring high bandwidth access to memory. The memory request patterns of these workloads vary and include regular strided accesses and indirect (pointer-based) accesses. Such applications require a large number of address generation instructions and a high degree of memory-level parallelism. This article proposes new memory instructions that exploit strided and indirect memory request patterns and improve efficiency in GPU architectures. The new instructions reduce address calculation instructions by offloading addressing to dedicated hardware, and reduce destructive memory request interference by grouping related requests together. Our results show that we can eliminate 33\% of dynamic instructions across 16 GPU benchmarks. These improvements result in an overall runtime improvement of 26\%, an energy reduction of 18\%, and a reduction in energy-delay product of 32\%.},
  keywords = {GPU architecture,vector instruction sets,vector memory instructions},
  file = {/Users/marcel/Zotero/storage/GWFZS5P2/Crago et al. - 2018 - Exposing Memory Access Patterns to Improve Instruc.pdf}
}

@article{cramerSurrogateGradientsAnalog2022,
  title = {Surrogate Gradients for Analog Neuromorphic Computing},
  author = {Cramer, Benjamin and Billaudelle, Sebastian and Kanya, Simeon and Leibfried, Aron and Grübl, Andreas and Karasenko, Vitali and Pehle, Christian and Schreiber, Korbinian and Stradmann, Yannik and Weis, Johannes and Schemmel, Johannes and Zenke, Friedemann},
  date = {2022-01-25},
  journaltitle = {Proceedings of the National Academy of Sciences of the United States of America},
  shortjournal = {Proc Natl Acad Sci U S A},
  volume = {119},
  number = {4},
  eprint = {35042792},
  eprinttype = {pmid},
  pages = {e2109194119},
  issn = {0027-8424},
  doi = {10.1073/pnas.2109194119},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8794842/},
  urldate = {2023-10-20},
  abstract = {Neuromorphic systems aim to accomplish efficient computation in electronics by mirroring neurobiological principles. Taking advantage of neuromorphic technologies requires effective learning algorithms capable of instantiating high-performing neural networks, while also dealing with inevitable manufacturing variations of individual components, such as memristors or analog neurons. We present a learning framework resulting in bioinspired spiking neural networks with high performance, low inference latency, and sparse spike-coding schemes, which also self-corrects for device mismatch. We validate our approach on the BrainScaleS-2 analog spiking neuromorphic system, demonstrating state-of-the-art accuracy, low latency, and energy efficiency. Our work sketches a path for building powerful neuromorphic processors that take advantage of emerging analog technologies., To rapidly process temporal information at a low metabolic cost, biological neurons integrate inputs as an analog sum, but communicate with spikes, binary events in time. Analog neuromorphic hardware uses the same principles to emulate spiking neural networks with exceptional energy efficiency. However, instantiating high-performing spiking networks on such hardware remains a significant challenge due to device mismatch and the lack of efficient training algorithms. Surrogate gradient learning has emerged as a promising training strategy for spiking networks, but its applicability for analog neuromorphic systems has not been demonstrated. Here, we demonstrate surrogate gradient learning on the BrainScaleS-2 analog neuromorphic system using an in-the-loop approach. We show that learning self-corrects for device mismatch, resulting in competitive spiking network performance on both vision and speech benchmarks. Our networks display sparse spiking activity with, on average, less than one spike per hidden neuron and input, perform inference at rates of up to 85,000 frames per second, and consume less than 200 mW. In summary, our work sets several benchmarks for low-energy spiking network processing on analog neuromorphic hardware and paves the way for future on-chip learning algorithms.},
  pmcid = {PMC8794842},
  file = {/Users/marcel/Zotero/storage/Q7FTET4C/Cramer et al. - 2022 - Surrogate gradients for analog neuromorphic computing.pdf}
}

@article{crickRecentExcitementNeural1989,
  title = {The Recent Excitement about Neural Networks},
  author = {Crick, Francis},
  date = {1989-01},
  journaltitle = {Nature},
  volume = {337},
  number = {6203},
  pages = {129--132},
  publisher = {Nature Publishing Group},
  issn = {1476-4687},
  doi = {10.1038/337129a0},
  url = {https://www.nature.com/articles/337129a0},
  urldate = {2022-05-01},
  abstract = {The remarkable properties of some recent computer algorithms for neural networks seemed to promise a fresh approach to understanding the computational properties of the brain. Unfortunately most of these neural nets are unrealistic in important respects.},
  issue = {6203},
  langid = {english},
  keywords = {Humanities and Social Sciences,multidisciplinary,Science},
  file = {/Users/marcel/Zotero/storage/EJS4WCCJ/Crick - 1989 - The recent excitement about neural networks.pdf;/Users/marcel/Zotero/storage/N82DTA9X/337129a0.html}
}

@article{dalgatyBioInspiredArchitecturesSubstantially2021,
  title = {Bio-{{Inspired Architectures Substantially Reduce}} the {{Memory Requirements}} of {{Neural Network Models}}},
  author = {Dalgaty, Thomas and Miller, John P. and Vianello, Elisa and Casas, Jérôme},
  date = {2021},
  journaltitle = {Frontiers in Neuroscience},
  volume = {15},
  issn = {1662-453X},
  url = {https://www.frontiersin.org/article/10.3389/fnins.2021.612359},
  urldate = {2022-05-02},
  abstract = {We propose a neural network model for the jumping escape response behavior observed in the cricket cercal sensory system. This sensory system processes low-intensity air currents in the animal's immediate environment generated by predators, competitors, and mates. Our model is inspired by decades of physiological and anatomical studies. We compare the performance of our model with a model derived through a universal approximation, or a generic deep learning, approach, and demonstrate that, to achieve the same performance, these models required between one and two orders of magnitude more parameters. Furthermore, since the architecture of the bio-inspired model is defined by a set of logical relations between neurons, we find that the model is open to interpretation and can be understood. This work demonstrates the potential of incorporating bio-inspired architectural motifs, which have evolved in animal nervous systems, into memory efficient neural network models.},
  file = {/Users/marcel/Zotero/storage/KWWTKY23/Dalgaty et al. - 2021 - Bio-Inspired Architectures Substantially Reduce th.pdf}
}

@online{daoFlashAttention2FasterAttention2023,
  title = {{{FlashAttention-2}}: {{Faster Attention}} with {{Better Parallelism}} and {{Work Partitioning}}},
  shorttitle = {{{FlashAttention-2}}},
  author = {Dao, Tri},
  date = {2023-07-17},
  eprint = {2307.08691},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2307.08691},
  url = {http://arxiv.org/abs/2307.08691},
  urldate = {2024-03-16},
  abstract = {Scaling Transformers to longer sequence lengths has been a major problem in the last several years, promising to improve performance in language modeling and high-resolution image understanding, as well as to unlock new applications in code, audio, and video generation. The attention layer is the main bottleneck in scaling to longer sequences, as its runtime and memory increase quadratically in the sequence length. FlashAttention exploits the asymmetric GPU memory hierarchy to bring significant memory saving (linear instead of quadratic) and runtime speedup (2-4\$\textbackslash times\$ compared to optimized baselines), with no approximation. However, FlashAttention is still not nearly as fast as optimized matrix-multiply (GEMM) operations, reaching only 25-40\textbackslash\% of the theoretical maximum FLOPs/s. We observe that the inefficiency is due to suboptimal work partitioning between different thread blocks and warps on the GPU, causing either low-occupancy or unnecessary shared memory reads/writes. We propose FlashAttention-2, with better work partitioning to address these issues. In particular, we (1) tweak the algorithm to reduce the number of non-matmul FLOPs (2) parallelize the attention computation, even for a single head, across different thread blocks to increase occupancy, and (3) within each thread block, distribute the work between warps to reduce communication through shared memory. These yield around 2\$\textbackslash times\$ speedup compared to FlashAttention, reaching 50-73\textbackslash\% of the theoretical maximum FLOPs/s on A100 and getting close to the efficiency of GEMM operations. We empirically validate that when used end-to-end to train GPT-style models, FlashAttention-2 reaches training speed of up to 225 TFLOPs/s per A100 GPU (72\textbackslash\% model FLOPs utilization).},
  pubstate = {prepublished},
  keywords = {Computer Science - Machine Learning},
  file = {/Users/marcel/Zotero/storage/VEVBM6LN/Dao - 2023 - FlashAttention-2 Faster Attention with Better Parallelism and Work Partitioning.pdf;/Users/marcel/Zotero/storage/BDFUTXNN/2307.html}
}

@online{daoFlashAttentionFastMemoryEfficient2022,
  title = {{{FlashAttention}}: {{Fast}} and {{Memory-Efficient Exact Attention}} with {{IO-Awareness}}},
  shorttitle = {{{FlashAttention}}},
  author = {Dao, Tri and Fu, Daniel Y. and Ermon, Stefano and Rudra, Atri and Ré, Christopher},
  date = {2022-06-23},
  eprint = {2205.14135},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2205.14135},
  url = {http://arxiv.org/abs/2205.14135},
  urldate = {2025-03-04},
  abstract = {Transformers are slow and memory-hungry on long sequences, since the time and memory complexity of self-attention are quadratic in sequence length. Approximate attention methods have attempted to address this problem by trading off model quality to reduce the compute complexity, but often do not achieve wall-clock speedup. We argue that a missing principle is making attention algorithms IO-aware -- accounting for reads and writes between levels of GPU memory. We propose FlashAttention, an IO-aware exact attention algorithm that uses tiling to reduce the number of memory reads/writes between GPU high bandwidth memory (HBM) and GPU on-chip SRAM. We analyze the IO complexity of FlashAttention, showing that it requires fewer HBM accesses than standard attention, and is optimal for a range of SRAM sizes. We also extend FlashAttention to block-sparse attention, yielding an approximate attention algorithm that is faster than any existing approximate attention method. FlashAttention trains Transformers faster than existing baselines: 15\% end-to-end wall-clock speedup on BERT-large (seq. length 512) compared to the MLPerf 1.1 training speed record, 3\$\textbackslash times\$ speedup on GPT-2 (seq. length 1K), and 2.4\$\textbackslash times\$ speedup on long-range arena (seq. length 1K-4K). FlashAttention and block-sparse FlashAttention enable longer context in Transformers, yielding higher quality models (0.7 better perplexity on GPT-2 and 6.4 points of lift on long-document classification) and entirely new capabilities: the first Transformers to achieve better-than-chance performance on the Path-X challenge (seq. length 16K, 61.4\% accuracy) and Path-256 (seq. length 64K, 63.1\% accuracy).},
  pubstate = {prepublished},
  keywords = {Computer Science - Machine Learning},
  file = {/Users/marcel/Zotero/storage/SCKHEYNT/Dao et al. - 2022 - FlashAttention Fast and Memory-Efficient Exact Attention with IO-Awareness.pdf;/Users/marcel/Zotero/storage/AL6EYWWA/2205.html}
}

@online{daoTransformersAreSSMs2024,
  title = {Transformers Are {{SSMs}}: {{Generalized Models}} and {{Efficient Algorithms Through Structured State Space Duality}}},
  shorttitle = {Transformers Are {{SSMs}}},
  author = {Dao, Tri and Gu, Albert},
  date = {2024-05-31},
  eprint = {2405.21060},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2405.21060},
  url = {http://arxiv.org/abs/2405.21060},
  urldate = {2025-01-30},
  abstract = {While Transformers have been the main architecture behind deep learning's success in language modeling, state-space models (SSMs) such as Mamba have recently been shown to match or outperform Transformers at small to medium scale. We show that these families of models are actually quite closely related, and develop a rich framework of theoretical connections between SSMs and variants of attention, connected through various decompositions of a well-studied class of structured semiseparable matrices. Our state space duality (SSD) framework allows us to design a new architecture (Mamba-2) whose core layer is an a refinement of Mamba's selective SSM that is 2-8X faster, while continuing to be competitive with Transformers on language modeling.},
  pubstate = {prepublished},
  keywords = {Computer Science - Machine Learning},
  file = {/Users/marcel/Zotero/storage/DL6W7JMG/Dao and Gu - 2024 - Transformers are SSMs Generalized Models and Efficient Algorithms Through Structured State Space Du.pdf;/Users/marcel/Zotero/storage/NRSJXEM7/2405.html}
}

@article{dealmeidaMemoryRetrievalTime2007,
  title = {Memory Retrieval Time and Memory Capacity of the {{CA3}} Network: {{Role}} of Gamma Frequency Oscillations},
  shorttitle = {Memory Retrieval Time and Memory Capacity of the {{CA3}} Network},
  author = {family=Almeida, given=Licurgo, prefix=de, useprefix=true and Idiart, Marco and Lisman, John E.},
  date = {2007-11},
  journaltitle = {Learning \& Memory},
  shortjournal = {Learn Mem},
  volume = {14},
  number = {11},
  eprint = {18007022},
  eprinttype = {pmid},
  pages = {795--806},
  issn = {1072-0502},
  doi = {10.1101/lm.730207},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2080581/},
  urldate = {2022-05-02},
  abstract = {The existence of recurrent synaptic connections in CA3 led to the hypothesis that CA3 is an autoassociative network similar to the Hopfield networks studied by theorists. CA3 undergoes gamma frequency periodic inhibition that prevents a persistent attractor state. This argues against the analogy to Hopfield nets, in which an attractor state can be used for working memory. However, we show that such periodic inhibition allows one cycle of recurrent excitatory activity and that this is sufficient for memory retrieval (within milliseconds). Thus, gamma oscillations are compatible with a long-term autoassociative memory function for CA3. A second goal of our work was to evaluate previous methods for estimating the memory capacity (P) of CA3. We confirm the equation, P = c/a2, where c is the probability that any two cells are recurrently connected and a is the fraction of cells representing a memory item. In applying this to CA3, we focus on CA3a, the subregion where recurrent connections are most numerous (c = 0.2) and approximate randomness. We estimate that a memory item is represented by ∼225 of the 70,000 neurons in CA3a (a = 0.003) and that ∼20,000 memory items can be stored. Our general conclusion is that the physiological and anatomical findings of CA3a are consistent with an autoassociative function. The nature of the information that is associated in CA3a is discussed. We also discuss how the autoassociative properties of CA3 and the heteroassociative properties of dentate synapses (linking sequential memories) form an integrated system for the storage and recall of item sequences. The recall process generates the phase precession in dentate, CA3, and entorhinal cortex.},
  pmcid = {PMC2080581},
  file = {/Users/marcel/Zotero/storage/6AES4753/de Almeida et al. - 2007 - Memory retrieval time and memory capacity of the C.pdf}
}

@unpublished{dehaanGaugeEquivariantMesh2020,
  title = {Gauge {{Equivariant Mesh CNNs}}: {{Anisotropic}} Convolutions on Geometric Graphs},
  shorttitle = {Gauge {{Equivariant Mesh CNNs}}},
  author = {family=Haan, given=Pim, prefix=de, useprefix=true and Weiler, Maurice and Cohen, Taco and Welling, Max},
  date = {2020-03-11},
  eprint = {2003.05425},
  eprinttype = {arXiv},
  eprintclass = {cs, stat},
  url = {http://arxiv.org/abs/2003.05425},
  urldate = {2021-07-27},
  abstract = {A common approach to define convolutions on meshes is to interpret them as a graph and apply graph convolutional networks (GCNs). Such GCNs utilize isotropic kernels and are therefore insensitive to the relative orientation of vertices and thus to the geometry of the mesh as a whole. We propose Gauge Equivariant Mesh CNNs which generalize GCNs to apply anisotropic gauge equivariant kernels. Since the resulting features carry orientation information, we introduce a geometric message passing scheme defined by parallel transporting features over mesh edges. Our experiments validate the significantly improved expressivity of the proposed model over conventional GCNs and other methods.},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/marcel/Zotero/storage/G2B3JR9H/de Haan et al_2020_Gauge Equivariant Mesh CNNs.pdf;/Users/marcel/Zotero/storage/XE4AK58X/2003.html}
}

@online{deletangLanguageModelingCompression2023,
  title = {Language {{Modeling Is Compression}}},
  author = {Delétang, Grégoire and Ruoss, Anian and Duquenne, Paul-Ambroise and Catt, Elliot and Genewein, Tim and Mattern, Christopher and Grau-Moya, Jordi and Wenliang, Li Kevin and Aitchison, Matthew and Orseau, Laurent and Hutter, Marcus and Veness, Joel},
  date = {2023-09-19},
  eprint = {2309.10668},
  eprinttype = {arXiv},
  eprintclass = {cs, math},
  doi = {10.48550/arXiv.2309.10668},
  url = {http://arxiv.org/abs/2309.10668},
  urldate = {2024-03-16},
  abstract = {It has long been established that predictive models can be transformed into lossless compressors and vice versa. Incidentally, in recent years, the machine learning community has focused on training increasingly large and powerful self-supervised (language) models. Since these large language models exhibit impressive predictive capabilities, they are well-positioned to be strong compressors. In this work, we advocate for viewing the prediction problem through the lens of compression and evaluate the compression capabilities of large (foundation) models. We show that large language models are powerful general-purpose predictors and that the compression viewpoint provides novel insights into scaling laws, tokenization, and in-context learning. For example, Chinchilla 70B, while trained primarily on text, compresses ImageNet patches to 43.4\% and LibriSpeech samples to 16.4\% of their raw size, beating domain-specific compressors like PNG (58.5\%) or FLAC (30.3\%), respectively. Finally, we show that the prediction-compression equivalence allows us to use any compressor (like gzip) to build a conditional generative model.},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Information Theory,Computer Science - Machine Learning},
  file = {/Users/marcel/Zotero/storage/SPYBKSRQ/Delétang et al. - 2023 - Language Modeling Is Compression.pdf;/Users/marcel/Zotero/storage/WR6MN37B/2309.html}
}

@unpublished{dengVectorNeuronsGeneral2021,
  title = {Vector {{Neurons}}: {{A General Framework}} for {{SO}}(3)-{{Equivariant Networks}}},
  shorttitle = {Vector {{Neurons}}},
  author = {Deng, Congyue and Litany, Or and Duan, Yueqi and Poulenard, Adrien and Tagliasacchi, Andrea and Guibas, Leonidas},
  date = {2021-04-25},
  eprint = {2104.12229},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2104.12229},
  urldate = {2021-07-30},
  abstract = {Invariance and equivariance to the rotation group have been widely discussed in the 3D deep learning community for pointclouds. Yet most proposed methods either use complex mathematical tools that may limit their accessibility, or are tied to specific input data types and network architectures. In this paper, we introduce a general framework built on top of what we call Vector Neuron representations for creating SO(3)-equivariant neural networks for pointcloud processing. Extending neurons from 1D scalars to 3D vectors, our vector neurons enable a simple mapping of SO(3) actions to latent spaces thereby providing a framework for building equivariance in common neural operations -- including linear layers, non-linearities, pooling, and normalizations. Due to their simplicity, vector neurons are versatile and, as we demonstrate, can be incorporated into diverse network architecture backbones, allowing them to process geometry inputs in arbitrary poses. Despite its simplicity, our method performs comparably well in accuracy and generalization with other more complex and specialized state-of-the-art methods on classification and segmentation tasks. We also show for the first time a rotation equivariant reconstruction network.},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {/Users/marcel/Zotero/storage/P3P967GI/Deng et al_2021_Vector Neurons.pdf;/Users/marcel/Zotero/storage/5BRHQZ3G/2104.html}
}

@online{DetectiveWhoToo,
  title = {Detective Who’s Too Literal \#shorts - {{YouTube}}},
  url = {https://www.youtube.com/shorts/GffrPTbklpM},
  urldate = {2023-02-10},
  file = {/Users/marcel/Zotero/storage/BJWPEW84/GffrPTbklpM.html}
}

@online{dettmersLLMInt88bit2022,
  title = {{{LLM}}.Int8(): 8-Bit {{Matrix Multiplication}} for {{Transformers}} at {{Scale}}},
  shorttitle = {{{LLM}}.Int8()},
  author = {Dettmers, Tim and Lewis, Mike and Belkada, Younes and Zettlemoyer, Luke},
  date = {2022-11-10},
  eprint = {2208.07339},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2208.07339},
  url = {http://arxiv.org/abs/2208.07339},
  urldate = {2024-03-16},
  abstract = {Large language models have been widely adopted but require significant GPU memory for inference. We develop a procedure for Int8 matrix multiplication for feed-forward and attention projection layers in transformers, which cut the memory needed for inference by half while retaining full precision performance. With our method, a 175B parameter 16/32-bit checkpoint can be loaded, converted to Int8, and used immediately without performance degradation. This is made possible by understanding and working around properties of highly systematic emergent features in transformer language models that dominate attention and transformer predictive performance. To cope with these features, we develop a two-part quantization procedure, LLM.int8(). We first use vector-wise quantization with separate normalization constants for each inner product in the matrix multiplication, to quantize most of the features. However, for the emergent outliers, we also include a new mixed-precision decomposition scheme, which isolates the outlier feature dimensions into a 16-bit matrix multiplication while still more than 99.9\% of values are multiplied in 8-bit. Using LLM.int8(), we show empirically it is possible to perform inference in LLMs with up to 175B parameters without any performance degradation. This result makes such models much more accessible, for example making it possible to use OPT-175B/BLOOM on a single server with consumer GPUs. We open-source our software.},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning},
  file = {/Users/marcel/Zotero/storage/QCJZX2AM/Dettmers et al. - 2022 - LLM.int8() 8-bit Matrix Multiplication for Transformers at Scale.pdf;/Users/marcel/Zotero/storage/9WJQMUNF/2208.html}
}

@inproceedings{devlinBERTPretrainingDeep2019,
  title = {{{BERT}}: {{Pre-training}} of {{Deep Bidirectional Transformers}} for {{Language Understanding}}},
  shorttitle = {{{BERT}}},
  booktitle = {Proceedings of the 2019 {{Conference}} of the {{North American Chapter}} of the {{Association}} for {{Computational Linguistics}}: {{Human Language Technologies}}, {{Volume}} 1 ({{Long}} and {{Short Papers}})},
  author = {Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  editor = {Burstein, Jill and Doran, Christy and Solorio, Thamar},
  date = {2019-06},
  pages = {4171--4186},
  publisher = {Association for Computational Linguistics},
  location = {Minneapolis, Minnesota},
  doi = {10.18653/v1/N19-1423},
  url = {https://aclanthology.org/N19-1423},
  urldate = {2024-02-14},
  abstract = {We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models (Peters et al., 2018a; Radford et al., 2018), BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5 (7.7 point absolute improvement), MultiNLI accuracy to 86.7\% (4.6\% absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement).},
  eventtitle = {{{NAACL-HLT}} 2019},
  file = {/Users/marcel/Zotero/storage/GU8LKT6X/Devlin et al. - 2019 - BERT Pre-training of Deep Bidirectional Transformers for Language Understanding.pdf}
}

@online{dhariwalDiffusionModelsBeat2021,
  title = {Diffusion {{Models Beat GANs}} on {{Image Synthesis}}},
  author = {Dhariwal, Prafulla and Nichol, Alex},
  date = {2021-06-01},
  eprint = {2105.05233},
  eprinttype = {arXiv},
  eprintclass = {cs, stat},
  doi = {10.48550/arXiv.2105.05233},
  url = {http://arxiv.org/abs/2105.05233},
  urldate = {2022-07-11},
  abstract = {We show that diffusion models can achieve image sample quality superior to the current state-of-the-art generative models. We achieve this on unconditional image synthesis by finding a better architecture through a series of ablations. For conditional image synthesis, we further improve sample quality with classifier guidance: a simple, compute-efficient method for trading off diversity for fidelity using gradients from a classifier. We achieve an FID of 2.97 on ImageNet 128\$\textbackslash times\$128, 4.59 on ImageNet 256\$\textbackslash times\$256, and 7.72 on ImageNet 512\$\textbackslash times\$512, and we match BigGAN-deep even with as few as 25 forward passes per sample, all while maintaining better coverage of the distribution. Finally, we find that classifier guidance combines well with upsampling diffusion models, further improving FID to 3.94 on ImageNet 256\$\textbackslash times\$256 and 3.85 on ImageNet 512\$\textbackslash times\$512. We release our code at https://github.com/openai/guided-diffusion},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/marcel/Zotero/storage/YL7TB8WE/Dhariwal and Nichol - 2021 - Diffusion Models Beat GANs on Image Synthesis.pdf;/Users/marcel/Zotero/storage/ZD4BNQJX/2105.html}
}

@online{dietrichStructuredDynamicSparse2021,
  title = {Towards {{Structured Dynamic Sparse Pre-Training}} of {{BERT}}},
  author = {Dietrich, Anastasia and Gressmann, Frithjof and Orr, Douglas and Chelombiev, Ivan and Justus, Daniel and Luschi, Carlo},
  date = {2021-08-13},
  eprint = {2108.06277},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2108.06277},
  url = {http://arxiv.org/abs/2108.06277},
  urldate = {2022-09-23},
  abstract = {Identifying algorithms for computational efficient unsupervised training of large language models is an important and active area of research. In this work, we develop and study a straightforward, dynamic always-sparse pre-training approach for BERT language modeling task, which leverages periodic compression steps based on magnitude pruning followed by random parameter re-allocation. This approach enables us to achieve Pareto improvements in terms of the number of floating-point operations (FLOPs) over statically sparse and dense models across a broad spectrum of network sizes. Furthermore, we demonstrate that training remains FLOP-efficient when using coarse-grained block sparsity, making it particularly promising for efficient execution on modern hardware accelerators.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computation and Language,Computer Science - Machine Learning},
  file = {/Users/marcel/Zotero/storage/6DLDSHU8/Dietrich et al. - 2021 - Towards Structured Dynamic Sparse Pre-Training of .pdf;/Users/marcel/Zotero/storage/XG7XCCZT/2108.html}
}

@online{digiovanniGraphNeuralNetworks2022a,
  title = {Graph {{Neural Networks}} as {{Gradient Flows}}: Understanding Graph Convolutions via Energy},
  shorttitle = {Graph {{Neural Networks}} as {{Gradient Flows}}},
  author = {Di Giovanni, Francesco and Rowbottom, James and Chamberlain, Benjamin P. and Markovich, Thomas and Bronstein, Michael M.},
  date = {2022-10-08},
  eprint = {2206.10991},
  eprinttype = {arXiv},
  eprintclass = {cs, stat},
  doi = {10.48550/arXiv.2206.10991},
  url = {http://arxiv.org/abs/2206.10991},
  urldate = {2023-01-22},
  abstract = {Gradient flows are differential equations that minimize an energy functional and constitute the main descriptors of physical systems. We apply this formalism to Graph Neural Networks (GNNs) to develop new frameworks for learning on graphs as well as provide a better theoretical understanding of existing ones. We derive GNNs as a gradient flow equation of a parametric energy that provides a physics-inspired interpretation of GNNs as learning particle dynamics in the feature space. In particular, we show that in graph convolutional models (GCN), the positive/negative eigenvalues of the channel mixing matrix correspond to attractive/repulsive forces between adjacent features. We rigorously prove how the channel-mixing can learn to steer the dynamics towards low or high frequencies, which allows to deal with heterophilic graphs. We show that the same class of energies is decreasing along a larger family of GNNs; albeit not gradient flows, they retain their inductive bias. We experimentally evaluate an instance of the gradient flow framework that is principled, more efficient than GCN, and achieves competitive performance on graph datasets of varying homophily often outperforming recent baselines specifically designed to target heterophily.},
  pubstate = {prepublished},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/marcel/Zotero/storage/3GR9X79M/Di Giovanni et al. - 2022 - Graph Neural Networks as Gradient Flows understan.pdf;/Users/marcel/Zotero/storage/N8BUFUH6/2206.html}
}

@online{dingCognitiveGraphMultiHop2019,
  title = {Cognitive {{Graph}} for {{Multi-Hop Reading Comprehension}} at {{Scale}}},
  author = {Ding, Ming and Zhou, Chang and Chen, Qibin and Yang, Hongxia and Tang, Jie},
  date = {2019-06-04},
  eprint = {1905.05460},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.1905.05460},
  url = {http://arxiv.org/abs/1905.05460},
  urldate = {2024-02-13},
  abstract = {We propose a new CogQA framework for multi-hop question answering in web-scale documents. Inspired by the dual process theory in cognitive science, the framework gradually builds a \textbackslash textit\{cognitive graph\} in an iterative process by coordinating an implicit extraction module (System 1) and an explicit reasoning module (System 2). While giving accurate answers, our framework further provides explainable reasoning paths. Specifically, our implementation based on BERT and graph neural network efficiently handles millions of documents for multi-hop reasoning questions in the HotpotQA fullwiki dataset, achieving a winning joint \$F\_1\$ score of 34.9 on the leaderboard, compared to 23.6 of the best competitor.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computation and Language},
  file = {/Users/marcel/Zotero/storage/H5FUVX9S/Ding et al. - 2019 - Cognitive Graph for Multi-Hop Reading Comprehension at Scale.pdf;/Users/marcel/Zotero/storage/4F3EQPJ4/1905.html}
}

@online{dongSurveyIncontextLearning2023,
  title = {A {{Survey}} on {{In-context Learning}}},
  author = {Dong, Qingxiu and Li, Lei and Dai, Damai and Zheng, Ce and Wu, Zhiyong and Chang, Baobao and Sun, Xu and Xu, Jingjing and Li, Lei and Sui, Zhifang},
  date = {2023-06-01},
  eprint = {2301.00234},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2301.00234},
  url = {http://arxiv.org/abs/2301.00234},
  urldate = {2024-03-15},
  abstract = {With the increasing ability of large language models (LLMs), in-context learning (ICL) has become a new paradigm for natural language processing (NLP), where LLMs make predictions only based on contexts augmented with a few examples. It has been a new trend to explore ICL to evaluate and extrapolate the ability of LLMs. In this paper, we aim to survey and summarize the progress and challenges of ICL. We first present a formal definition of ICL and clarify its correlation to related studies. Then, we organize and discuss advanced techniques, including training strategies, demonstration designing strategies, as well as related analysis. Finally, we discuss the challenges of ICL and provide potential directions for further research. We hope that our work can encourage more research on uncovering how ICL works and improving ICL.},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
  file = {/Users/marcel/Zotero/storage/A8AQX4XV/Dong et al. - 2023 - A Survey on In-context Learning.pdf;/Users/marcel/Zotero/storage/CEJXRDKE/2301.html}
}

@article{dormandFamilyEmbeddedRungeKutta1980,
  title = {A Family of Embedded {{Runge-Kutta}} Formulae},
  author = {Dormand, J. R. and Prince, P. J.},
  date = {1980-03-01},
  journaltitle = {Journal of Computational and Applied Mathematics},
  shortjournal = {Journal of Computational and Applied Mathematics},
  volume = {6},
  number = {1},
  pages = {19--26},
  issn = {0377-0427},
  doi = {10.1016/0771-050X(80)90013-3},
  url = {https://www.sciencedirect.com/science/article/pii/0771050X80900133},
  urldate = {2022-09-11},
  abstract = {A family of embedded Runge-Kutta formulae RK5 (4) are derived. From these are presented formulae which have (a) ‘small’ principal truncation terms in the fifth order and (b) extended regions of absolute stability.},
  langid = {english},
  file = {/Users/marcel/Zotero/storage/X8IK5MTD/Dormand and Prince - 1980 - A family of embedded Runge-Kutta formulae.pdf;/Users/marcel/Zotero/storage/TPY7XPIA/0771050X80900133.html}
}

@online{dosovitskiyImageWorth16x162021,
  title = {An {{Image}} Is {{Worth}} 16x16 {{Words}}: {{Transformers}} for {{Image Recognition}} at {{Scale}}},
  shorttitle = {An {{Image}} Is {{Worth}} 16x16 {{Words}}},
  author = {Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and Uszkoreit, Jakob and Houlsby, Neil},
  date = {2021-06-03},
  eprint = {2010.11929},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2010.11929},
  url = {http://arxiv.org/abs/2010.11929},
  urldate = {2022-09-22},
  abstract = {While the Transformer architecture has become the de-facto standard for natural language processing tasks, its applications to computer vision remain limited. In vision, attention is either applied in conjunction with convolutional networks, or used to replace certain components of convolutional networks while keeping their overall structure in place. We show that this reliance on CNNs is not necessary and a pure transformer applied directly to sequences of image patches can perform very well on image classification tasks. When pre-trained on large amounts of data and transferred to multiple mid-sized or small image recognition benchmarks (ImageNet, CIFAR-100, VTAB, etc.), Vision Transformer (ViT) attains excellent results compared to state-of-the-art convolutional networks while requiring substantially fewer computational resources to train.},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning},
  file = {/Users/marcel/Zotero/storage/SVQGXN9Z/Dosovitskiy et al. - 2021 - An Image is Worth 16x16 Words Transformers for Im.pdf;/Users/marcel/Zotero/storage/D4EHHIRJ/2010.html}
}

@article{downingGradientExpectationsStructure,
  title = {Gradient {{Expectations}}: {{Structure}}, {{Origins}} and {{Synthesis}} of {{Predictive Neural Networks}}},
  author = {Downing, Keith L},
  langid = {english},
  file = {/Users/marcel/Zotero/storage/3ZJB7D3V/Downing - Gradient Expectations Structure, Origins and Synt.pdf}
}

@article{duanMemristorBasedCellularNonlinear2015,
  title = {Memristor-{{Based Cellular Nonlinear}}/{{Neural Network}}: {{Design}}, {{Analysis}}, and {{Applications}}},
  shorttitle = {Memristor-{{Based Cellular Nonlinear}}/{{Neural Network}}},
  author = {Duan, Shukai and Hu, Xiaofang and Dong, Zhekang and Wang, Lidan and Mazumder, Pinaki},
  date = {2015-06},
  journaltitle = {IEEE Transactions on Neural Networks and Learning Systems},
  shortjournal = {IEEE Trans. Neural Netw. Learning Syst.},
  volume = {26},
  number = {6},
  pages = {1202--1213},
  issn = {2162-237X, 2162-2388},
  doi = {10.1109/TNNLS.2014.2334701},
  url = {http://ieeexplore.ieee.org/document/6861426/},
  urldate = {2023-10-21},
  abstract = {Cellular nonlinear/neural network (CNN) has been recognized as a powerful massively parallel architecture capable of solving complex engineering problems by performing trillions of analog operations per second. The memristor was theoretically predicted in the late seventies, but it garnered nascent research interest due to the recent much-acclaimed discovery of nanocrossbar memories by engineers at the Hewlett-Packard Laboratory. The memristor is expected to be co-integrated with nanoscale CMOS technology to revolutionize conventional von Neumann as well as neuromorphic computing. In this paper, a compact CNN model based on memristors is presented along with its performance analysis and applications. In the new CNN design, the memristor bridge circuit acts as the synaptic circuit element and substitutes the complex multiplication circuit used in traditional CNN architectures. In addition, the negative differential resistance and nonlinear current–voltage characteristics of the memristor have been leveraged to replace the linear resistor in conventional CNNs. The proposed CNN design has several merits, for example, high density, nonvolatility, and programmability of synaptic weights. The proposed memristor-based CNN design operations for implementing several image processing functions are illustrated through simulation and contrasted with conventional CNNs. Monte-Carlo simulation has been used to demonstrate the behavior of the proposed CNN due to the variations in memristor synaptic weights.},
  langid = {english},
  file = {/Users/marcel/Zotero/storage/2X2ENNYY/Duan et al. - 2015 - Memristor-Based Cellular NonlinearNeural Network Design, Analysis, and Applications.pdf}
}

@article{duDiffPDDifferentiableProjective2022,
  title = {{{DiffPD}}: {{Differentiable Projective Dynamics}}},
  shorttitle = {{{DiffPD}}},
  author = {Du, Tao and Wu, Kui and Ma, Pingchuan and Wah, Sebastien and Spielberg, Andrew and Rus, Daniela and Matusik, Wojciech},
  date = {2022-04-30},
  journaltitle = {ACM Transactions on Graphics},
  shortjournal = {ACM Trans. Graph.},
  volume = {41},
  number = {2},
  pages = {1--21},
  issn = {0730-0301, 1557-7368},
  doi = {10.1145/3490168},
  url = {https://dl.acm.org/doi/10.1145/3490168},
  urldate = {2023-06-29},
  abstract = {We present a novel, fast differentiable simulator for soft-body learning and control applications. Existing differentiable soft-body simulators can be classified into two categories based on their time integration methods: Simulators using explicit timestepping schemes require tiny timesteps to avoid numerical instabilities in gradient computation, and simulators using implicit time integration typically compute gradients by employing the adjoint method and solving the expensive linearized dynamics. Inspired by               Projective Dynamics               (               PD               ), we present               Differentiable Projective Dynamics               (               DiffPD               ), an efficient differentiable soft-body simulator based on PD with implicit time integration. The key idea in DiffPD is to speed up backpropagation by exploiting the prefactorized Cholesky decomposition in forward PD simulation. In terms of contact handling, DiffPD supports two types of contacts: a penalty-based model describing contact and friction forces and a complementarity-based model enforcing non-penetration conditions and static friction. We evaluate the performance of DiffPD and observe it is 4–19 times faster compared with the standard Newton’s method in various applications including system identification, inverse design problems, trajectory optimization, and closed-loop control. We also apply DiffPD in a               reality-to-simulation               (               real-to-sim               ) example with contact and collisions and show its capability of reconstructing a digital twin of real-world scenes.},
  langid = {english},
  file = {/Users/marcel/Zotero/storage/2TZKKKXB/Du et al. - 2022 - DiffPD Differentiable Projective Dynamics.pdf}
}

@online{duGLMGeneralLanguage2022,
  title = {{{GLM}}: {{General Language Model Pretraining}} with {{Autoregressive Blank Infilling}}},
  shorttitle = {{{GLM}}},
  author = {Du, Zhengxiao and Qian, Yujie and Liu, Xiao and Ding, Ming and Qiu, Jiezhong and Yang, Zhilin and Tang, Jie},
  date = {2022-03-17},
  eprint = {2103.10360},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2103.10360},
  url = {http://arxiv.org/abs/2103.10360},
  urldate = {2024-05-23},
  abstract = {There have been various types of pretraining architectures including autoencoding models (e.g., BERT), autoregressive models (e.g., GPT), and encoder-decoder models (e.g., T5). However, none of the pretraining frameworks performs the best for all tasks of three main categories including natural language understanding (NLU), unconditional generation, and conditional generation. We propose a General Language Model (GLM) based on autoregressive blank infilling to address this challenge. GLM improves blank filling pretraining by adding 2D positional encodings and allowing an arbitrary order to predict spans, which results in performance gains over BERT and T5 on NLU tasks. Meanwhile, GLM can be pretrained for different types of tasks by varying the number and lengths of blanks. On a wide range of tasks across NLU, conditional and unconditional generation, GLM outperforms BERT, T5, and GPT given the same model sizes and data, and achieves the best performance from a single pretrained model with 1.25x parameters of BERT Large , demonstrating its generalizability to different downstream tasks.},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Machine Learning},
  file = {/Users/marcel/Zotero/storage/N8FMK9YD/Du et al. - 2022 - GLM General Language Model Pretraining with Autoregressive Blank Infilling.pdf;/Users/marcel/Zotero/storage/WMEQDR48/2103.html}
}

@unpublished{dupontGenerativeModelsDistributions2021,
  title = {Generative {{Models}} as {{Distributions}} of {{Functions}}},
  author = {Dupont, Emilien and Teh, Yee Whye and Doucet, Arnaud},
  date = {2021-05-30},
  eprint = {2102.04776},
  eprinttype = {arXiv},
  eprintclass = {cs, stat},
  url = {http://arxiv.org/abs/2102.04776},
  urldate = {2021-07-27},
  abstract = {Generative models are typically trained on grid-like data such as images. As a result, the size of these models usually scales directly with the underlying grid resolution. In this paper, we abandon discretized grids and instead parameterize individual data points by continuous functions. We then build generative models by learning distributions over such functions. By treating data points as functions, we can abstract away from the specific type of data we train on and construct models that scale independently of signal resolution. To train our model, we use an adversarial approach with a discriminator that acts on continuous signals. Through experiments on both images and 3D shapes, we demonstrate that our model can learn rich distributions of functions independently of data type and resolution.},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/marcel/Zotero/storage/ARW3UVTR/Dupont et al_2021_Generative Models as Distributions of Functions.pdf;/Users/marcel/Zotero/storage/8LFKZE3I/2102.html}
}

@online{duTOFLOWEfficientContinuous2022,
  title = {{{TO-FLOW}}: {{Efficient Continuous Normalizing Flows}} with {{Temporal Optimization}} Adjoint with {{Moving Speed}}},
  shorttitle = {{{TO-FLOW}}},
  author = {Du, Shian and Luo, Yihong and Chen, Wei and Xu, Jian and Zeng, Delu},
  date = {2022-03-27},
  eprint = {2203.10335},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2203.10335},
  url = {http://arxiv.org/abs/2203.10335},
  urldate = {2022-11-10},
  abstract = {Continuous normalizing flows (CNFs) construct invertible mappings between an arbitrary complex distribution and an isotropic Gaussian distribution using Neural Ordinary Differential Equations (neural ODEs). It has not been tractable on large datasets due to the incremental complexity of the neural ODE training. Optimal Transport theory has been applied to regularize the dynamics of the ODE to speed up training in recent works. In this paper, a temporal optimization is proposed by optimizing the evolutionary time for forward propagation of the neural ODE training. In this appoach, we optimize the network weights of the CNF alternately with evolutionary time by coordinate descent. Further with temporal regularization, stability of the evolution is ensured. This approach can be used in conjunction with the original regularization approach. We have experimentally demonstrated that the proposed approach can significantly accelerate training without sacrifying performance over baseline models.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {/Users/marcel/Zotero/storage/IGNCQU9D/Du et al. - 2022 - TO-FLOW Efficient Continuous Normalizing Flows wi.pdf;/Users/marcel/Zotero/storage/HJZ68ZBG/2203.html}
}

@article{duUnderwaterSoftRobot2021,
  title = {Underwater {{Soft Robot Modeling}} and {{Control With Differentiable Simulation}}},
  author = {Du, Tao and Hughes, Josie and Wah, Sebastien and Matusik, Wojciech and Rus, Daniela},
  date = {2021-07},
  journaltitle = {IEEE Robotics and Automation Letters},
  volume = {6},
  number = {3},
  pages = {4994--5001},
  issn = {2377-3766},
  doi = {10.1109/LRA.2021.3070305},
  abstract = {Underwater soft robots are challenging to model and control because of their high degrees of freedom and their intricate coupling with water. In this letter, we present a method that leverages the recent development in differentiable simulation coupled with a differentiable, analytical hydrodynamic model to assist with the modeling and control of an underwater soft robot. We apply this method to Starfish, a customized soft robot design that is easy to fabricate and intuitive to manipulate. Our method starts with data obtained from the real robot and alternates between simulation and experiments. Specifically, the simulation step uses gradients from a differentiable simulator to run system identification and trajectory optimization, and the experiment step executes the optimized trajectory on the robot to collect new data to be fed into simulation. Our demonstration on Starfish shows that proper usage of gradients from a differentiable simulator not only narrows down its simulation-to-reality gap but also improves the performance of an open-loop controller in real experiments.},
  eventtitle = {{{IEEE Robotics}} and {{Automation Letters}}},
  keywords = {Analytical models,calibration and identification,Computational modeling,control,Data models,Learning for soft robots,learning from experience,Mathematical model,model learning for control,modeling,Pipelines,Robots,Soft robotics},
  file = {/Users/marcel/Zotero/storage/6UBH9RYX/Du et al. - 2021 - Underwater Soft Robot Modeling and Control With Di.pdf}
}

@online{earwigEarwigMwparserfromhellPython2013,
  title = {Earwig/Mwparserfromhell: {{A Python}} Parser for {{MediaWiki}} Wikicode},
  author = {Earwig},
  date = {2013-07-03},
  url = {https://github.com/earwig/mwparserfromhell},
  urldate = {2024-03-14},
  file = {/Users/marcel/Zotero/storage/9K372PEM/mwparserfromhell.html}
}

@online{elfwingSigmoidWeightedLinearUnits2017,
  title = {Sigmoid-{{Weighted Linear Units}} for {{Neural Network Function Approximation}} in {{Reinforcement Learning}}},
  author = {Elfwing, Stefan and Uchibe, Eiji and Doya, Kenji},
  date = {2017-11-01},
  eprint = {1702.03118},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.1702.03118},
  url = {http://arxiv.org/abs/1702.03118},
  urldate = {2024-03-16},
  abstract = {In recent years, neural networks have enjoyed a renaissance as function approximators in reinforcement learning. Two decades after Tesauro's TD-Gammon achieved near top-level human performance in backgammon, the deep reinforcement learning algorithm DQN achieved human-level performance in many Atari 2600 games. The purpose of this study is twofold. First, we propose two activation functions for neural network function approximation in reinforcement learning: the sigmoid-weighted linear unit (SiLU) and its derivative function (dSiLU). The activation of the SiLU is computed by the sigmoid function multiplied by its input. Second, we suggest that the more traditional approach of using on-policy learning with eligibility traces, instead of experience replay, and softmax action selection with simple annealing can be competitive with DQN, without the need for a separate target network. We validate our proposed approach by, first, achieving new state-of-the-art results in both stochastic SZ-Tetris and Tetris with a small 10\$\textbackslash times\$10 board, using TD(\$\textbackslash lambda\$) learning and shallow dSiLU network agents, and, then, by outperforming DQN in the Atari 2600 domain by using a deep Sarsa(\$\textbackslash lambda\$) agent with SiLU and dSiLU hidden units.},
  pubstate = {prepublished},
  version = {3},
  keywords = {Computer Science - Machine Learning},
  file = {/Users/marcel/Zotero/storage/84YVR687/Elfwing et al. - 2017 - Sigmoid-Weighted Linear Units for Neural Network Function Approximation in Reinforcement Learning.pdf;/Users/marcel/Zotero/storage/R2JEVW3P/1702.html}
}

@article{EquivariantGraphNeural,
  title = {Equivariant {{Graph Neural Operator}} for {{Modeling 3D Dynamics}}},
  file = {/Users/marcel/Zotero/storage/4BEG2CJI/Equivariant Graph Neural Operator for Modeling 3D Dynamics.pdf}
}

@online{ErrorAnalysisEuler,
  title = {Error Analysis Euler's Method - {{Google Search}}},
  url = {https://www.google.com/search?q=error+analysis+euler%27s+method&oq=error+analysis+euler%27s+method&aqs=chrome..69i57l2j69i59.3574j0j7&sourceid=chrome&ie=UTF-8},
  urldate = {2023-02-28},
  file = {/Users/marcel/Zotero/storage/73YU32GR/search.html}
}

@online{fahimHls4mlOpenSourceCodesign2021,
  title = {Hls4ml: {{An Open-Source Codesign Workflow}} to {{Empower Scientific Low-Power Machine Learning Devices}}},
  shorttitle = {Hls4ml},
  author = {Fahim, Farah and Hawks, Benjamin and Herwig, Christian and Hirschauer, James and Jindariani, Sergo and Tran, Nhan and Carloni, Luca P. and Di Guglielmo, Giuseppe and Harris, Philip and Krupa, Jeffrey and Rankin, Dylan and Valentin, Manuel Blanco and Hester, Josiah and Luo, Yingyi and Mamish, John and Orgrenci-Memik, Seda and Aarrestad, Thea and Javed, Hamza and Loncar, Vladimir and Pierini, Maurizio and Pol, Adrian Alan and Summers, Sioni and Duarte, Javier and Hauck, Scott and Hsu, Shih-Chieh and Ngadiuba, Jennifer and Liu, Mia and Hoang, Duc and Kreinar, Edward and Wu, Zhenbin},
  date = {2021-03-23},
  eprint = {2103.05579},
  eprinttype = {arXiv},
  eprintclass = {physics},
  doi = {10.48550/arXiv.2103.05579},
  url = {http://arxiv.org/abs/2103.05579},
  urldate = {2022-12-07},
  abstract = {Accessible machine learning algorithms, software, and diagnostic tools for energy-efficient devices and systems are extremely valuable across a broad range of application domains. In scientific domains, real-time near-sensor processing can drastically improve experimental design and accelerate scientific discoveries. To support domain scientists, we have developed hls4ml, an open-source software-hardware codesign workflow to interpret and translate machine learning algorithms for implementation with both FPGA and ASIC technologies. We expand on previous hls4ml work by extending capabilities and techniques towards low-power implementations and increased usability: new Python APIs, quantization-aware pruning, end-to-end FPGA workflows, long pipeline kernels for low power, and new device backends include an ASIC workflow. Taken together, these and continued efforts in hls4ml will arm a new generation of domain scientists with accessible, efficient, and powerful tools for machine-learning-accelerated discovery.},
  pubstate = {prepublished},
  keywords = {Computer Science - Hardware Architecture,Computer Science - Machine Learning,Physics - Instrumentation and Detectors},
  file = {/Users/marcel/Zotero/storage/I4SI3VKU/Fahim et al. - 2021 - hls4ml An Open-Source Codesign Workflow to Empowe.pdf;/Users/marcel/Zotero/storage/H8YHUTC3/2103.html}
}

@article{feydyGeometricDataAnalysise,
  title = {Geometric Data Analysis, beyond Convolutions},
  author = {Feydy, Jean},
  pages = {259},
  langid = {english},
  file = {/Users/marcel/Zotero/storage/UEFEMTHH/Feydy - Geometric data analysis, beyond convolutions.pdf}
}

@online{finlayHowTrainYour2020,
  title = {How to Train Your Neural {{ODE}}: The World of {{Jacobian}} and Kinetic Regularization},
  shorttitle = {How to Train Your Neural {{ODE}}},
  author = {Finlay, Chris and Jacobsen, Jörn-Henrik and Nurbekyan, Levon and Oberman, Adam M.},
  date = {2020-06-23},
  eprint = {2002.02798},
  eprinttype = {arXiv},
  eprintclass = {cs, stat},
  doi = {10.48550/arXiv.2002.02798},
  url = {http://arxiv.org/abs/2002.02798},
  urldate = {2022-11-10},
  abstract = {Training neural ODEs on large datasets has not been tractable due to the necessity of allowing the adaptive numerical ODE solver to refine its step size to very small values. In practice this leads to dynamics equivalent to many hundreds or even thousands of layers. In this paper, we overcome this apparent difficulty by introducing a theoretically-grounded combination of both optimal transport and stability regularizations which encourage neural ODEs to prefer simpler dynamics out of all the dynamics that solve a problem well. Simpler dynamics lead to faster convergence and to fewer discretizations of the solver, considerably decreasing wall-clock time without loss in performance. Our approach allows us to train neural ODE-based generative models to the same performance as the unregularized dynamics, with significant reductions in training time. This brings neural ODEs closer to practical relevance in large-scale applications.},
  pubstate = {prepublished},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/marcel/Zotero/storage/5KZLJ5A7/Finlay et al. - 2020 - How to train your neural ODE the world of Jacobia.pdf;/Users/marcel/Zotero/storage/Q9VLRVR3/2002.html}
}

@unpublished{finziGeneralizingConvolutionalNeural2020,
  title = {Generalizing {{Convolutional Neural Networks}} for {{Equivariance}} to {{Lie Groups}} on {{Arbitrary Continuous Data}}},
  author = {Finzi, Marc and Stanton, Samuel and Izmailov, Pavel and Wilson, Andrew Gordon},
  date = {2020-09-24},
  eprint = {2002.12880},
  eprinttype = {arXiv},
  eprintclass = {cs, stat},
  url = {http://arxiv.org/abs/2002.12880},
  urldate = {2021-07-27},
  abstract = {The translation equivariance of convolutional layers enables convolutional neural networks to generalize well on image problems. While translation equivariance provides a powerful inductive bias for images, we often additionally desire equivariance to other transformations, such as rotations, especially for non-image data. We propose a general method to construct a convolutional layer that is equivariant to transformations from any specified Lie group with a surjective exponential map. Incorporating equivariance to a new group requires implementing only the group exponential and logarithm maps, enabling rapid prototyping. Showcasing the simplicity and generality of our method, we apply the same model architecture to images, ball-and-stick molecular data, and Hamiltonian dynamical systems. For Hamiltonian systems, the equivariance of our models is especially impactful, leading to exact conservation of linear and angular momentum.},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/marcel/Zotero/storage/X4XII54R/Finzi et al_2020_Generalizing Convolutional Neural Networks for Equivariance to Lie Groups on.pdf;/Users/marcel/Zotero/storage/RK6IYEJR/2002.html}
}

@unpublished{finziPracticalMethodConstructing2021,
  title = {A {{Practical Method}} for {{Constructing Equivariant Multilayer Perceptrons}} for {{Arbitrary Matrix Groups}}},
  author = {Finzi, Marc and Welling, Max and Wilson, Andrew Gordon},
  date = {2021-04-19},
  eprint = {2104.09459},
  eprinttype = {arXiv},
  eprintclass = {cs, math, stat},
  url = {http://arxiv.org/abs/2104.09459},
  urldate = {2021-07-27},
  abstract = {Symmetries and equivariance are fundamental to the generalization of neural networks on domains such as images, graphs, and point clouds. Existing work has primarily focused on a small number of groups, such as the translation, rotation, and permutation groups. In this work we provide a completely general algorithm for solving for the equivariant layers of matrix groups. In addition to recovering solutions from other works as special cases, we construct multilayer perceptrons equivariant to multiple groups that have never been tackled before, including \$\textbackslash mathrm\{O\}(1,3)\$, \$\textbackslash mathrm\{O\}(5)\$, \$\textbackslash mathrm\{Sp\}(n)\$, and the Rubik's cube group. Our approach outperforms non-equivariant baselines, with applications to particle physics and dynamical systems. We release our software library to enable researchers to construct equivariant layers for arbitrary matrix groups.},
  keywords = {Computer Science - Machine Learning,Mathematics - Dynamical Systems,Statistics - Machine Learning},
  file = {/Users/marcel/Zotero/storage/Y6SQAPRT/Finzi et al_2021_A Practical Method for Constructing Equivariant Multilayer Perceptrons for.pdf;/Users/marcel/Zotero/storage/BJLY5LS4/2104.html}
}

@inproceedings{finziResidualPathwayPriors2021,
  title = {Residual {{Pathway Priors}} for {{Soft Equivariance Constraints}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Finzi, Marc and Benton, Gregory and Wilson, Andrew G},
  date = {2021},
  volume = {34},
  pages = {30037--30049},
  publisher = {Curran Associates, Inc.},
  url = {https://proceedings.neurips.cc/paper/2021/hash/fc394e9935fbd62c8aedc372464e1965-Abstract.html},
  urldate = {2022-12-15},
  abstract = {Models such as convolutional neural networks restrict the hypothesis space to a set of functions satisfying equivariance constraints, and improve generalization in problems by capturing relevant symmetries. However, symmetries are often only partially respected, preventing models with restriction biases from fitting the data. We introduce Residual Pathway Priors (RPPs) as a method for converting hard architectural constraints into soft priors, guiding models towards structured solutions while retaining the ability to capture additional complexity. RPPs are resilient to approximate or misspecified symmetries, and are as effective as fully constrained models even when symmetries are exact. We show that RPPs provide compelling performance on both model-free and model-based reinforcement learning problems, where contact forces and directional rewards violate the assumptions of equivariant networks. Finally, we demonstrate that RPPs have broad applicability, including dynamical systems, regression, and classification.},
  file = {/Users/marcel/Zotero/storage/GSNP6AM2/Finzi et al. - 2021 - Residual Pathway Priors for Soft Equivariance Cons.pdf}
}

@software{flax2020github,
  title = {Flax: {{A}} Neural Network Library and Ecosystem for {{JAX}}},
  author = {Heek, Jonathan and Levskaya, Anselm and Oliver, Avital and Ritter, Marvin and Rondepierre, Bertrand and Steiner, Andreas and family=Zee, given=Marc, prefix=van, useprefix=true},
  date = {2023},
  url = {http://github.com/google/flax},
  version = {0.6.5}
}

@article{Flux.jl-2018,
  title = {Fashionable Modelling with Flux},
  author = {Innes, Michael and Saba, Elliot and Fischer, Keno and Gandhi, Dhairya and Rudilosso, Marco Concetto and Joy, Neethu Mariya and Karmali, Tejan and Pal, Avik and Shah, Viral},
  date = {2018},
  journaltitle = {CoRR},
  volume = {abs/1811.01457},
  eprint = {1811.01457},
  eprinttype = {arXiv},
  url = {https://arxiv.org/abs/1811.01457},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  biburl = {https://dblp.org/rec/bib/journals/corr/abs-1811-01457},
  timestamp = {Thu, 22 Nov 2018 17:58:30 +0100}
}

@inproceedings{folkOverviewHDF5Technology2011,
  title = {An Overview of the {{HDF5}} Technology Suite and Its Applications},
  booktitle = {Proceedings of the {{EDBT}}/{{ICDT}} 2011 {{Workshop}} on {{Array Databases}}},
  author = {Folk, Mike and Heber, Gerd and Koziol, Quincey and Pourmal, Elena and Robinson, Dana},
  date = {2011-03-25},
  series = {{{AD}} '11},
  pages = {36--47},
  publisher = {Association for Computing Machinery},
  location = {New York, NY, USA},
  doi = {10.1145/1966895.1966900},
  url = {https://dl.acm.org/doi/10.1145/1966895.1966900},
  urldate = {2024-02-28},
  abstract = {In this paper, we give an overview of the HDF5 technology suite and some of its applications. We discuss the HDF5 data model, the HDF5 software architecture and some of its performance enhancing capabilities.},
  isbn = {978-1-4503-0614-0},
  keywords = {data management,data models,databases,HDF5},
  file = {/Users/marcel/Zotero/storage/EACTDWR8/Folk et al. - 2011 - An overview of the HDF5 technology suite and its applications.pdf}
}

@online{fournierProteinLanguageModels2024,
  title = {Protein {{Language Models}}: {{Is Scaling Necessary}}?},
  shorttitle = {Protein {{Language Models}}},
  author = {Fournier, Quentin and Vernon, Robert M. and family=Sloot, given=Almer, prefix=van der, useprefix=false and Schulz, Benjamin and Chandar, Sarath and Langmead, Christopher James},
  date = {2024-09-23},
  eprinttype = {bioRxiv},
  eprintclass = {New Results},
  pages = {2024.09.23.614603},
  doi = {10.1101/2024.09.23.614603},
  url = {https://www.biorxiv.org/content/10.1101/2024.09.23.614603v1},
  urldate = {2024-09-30},
  abstract = {Public protein sequence databases contain samples from the fitness landscape explored by nature. Protein language models (pLMs) pre-trained on these sequences aim to capture this landscape for tasks like property prediction and protein design. Following the same trend as in natural language processing, pLMs have continuously been scaled up. However, the premise that scale leads to better performance assumes that source databases provide accurate representation of the underlying fitness landscape, which is likely false. By developing an efficient codebase, designing a modern architecture, and addressing data quality concerns such as sample bias, we introduce AMPLIFY, a best-in-class pLM that is orders of magnitude less expensive to train and deploy than previous models. Furthermore, to support the scientific community and democratize the training of pLMs, we have open-sourced AMPLIFY’s pre-training codebase, data, and model checkpoints.},
  langid = {english},
  pubstate = {prepublished},
  file = {/Users/marcel/Zotero/storage/DVIXFXKX/Fournier et al. - 2024 - Protein Language Models Is Scaling Necessary.pdf}
}

@inproceedings{franzenGeneralNonlinearitiesEquivariant2021,
  title = {General {{Nonlinearities}} in {{SO}}(2)-{{Equivariant CNNs}}},
  author = {Franzen, Daniel and Wand, Michael},
  date = {2021-05-21},
  url = {https://openreview.net/forum?id=PFBHMlpaWY},
  urldate = {2022-05-08},
  abstract = {We improve the ability of using (more) general nonlinerities in SO(2)-equivariant steerable networks.},
  eventtitle = {Advances in {{Neural Information Processing Systems}}},
  langid = {english},
  file = {/Users/marcel/Zotero/storage/SCXMJVJM/Franzen and Wand - 2021 - General Nonlinearities in SO(2)-Equivariant CNNs.pdf;/Users/marcel/Zotero/storage/SX6VGLXZ/forum.html}
}

@unpublished{fuchsSETransformers3D2020,
  title = {{{SE}}(3)-{{Transformers}}: {{3D Roto-Translation Equivariant Attention Networks}}},
  shorttitle = {{{SE}}(3)-{{Transformers}}},
  author = {Fuchs, Fabian B. and Worrall, Daniel E. and Fischer, Volker and Welling, Max},
  date = {2020-11-24},
  eprint = {2006.10503},
  eprinttype = {arXiv},
  eprintclass = {cs, stat},
  url = {http://arxiv.org/abs/2006.10503},
  urldate = {2021-07-27},
  abstract = {We introduce the SE(3)-Transformer, a variant of the self-attention module for 3D point clouds and graphs, which is equivariant under continuous 3D roto-translations. Equivariance is important to ensure stable and predictable performance in the presence of nuisance transformations of the data input. A positive corollary of equivariance is increased weight-tying within the model. The SE(3)-Transformer leverages the benefits of self-attention to operate on large point clouds and graphs with varying number of points, while guaranteeing SE(3)-equivariance for robustness. We evaluate our model on a toy N-body particle simulation dataset, showcasing the robustness of the predictions under rotations of the input. We further achieve competitive performance on two real-world datasets, ScanObjectNN and QM9. In all cases, our model outperforms a strong, non-equivariant attention baseline and an equivariant model without attention.},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/marcel/Zotero/storage/C6WXLBFZ/Fuchs et al_2020_SE(3)-Transformers.pdf;/Users/marcel/Zotero/storage/TH5IPHLX/2006.html}
}

@article{fuDynamicPointCloud2021,
  title = {Dynamic {{Point Cloud Inpainting}} via {{Spatial-Temporal Graph Learning}}},
  author = {Fu, Zeqing and Hu, Wei},
  date = {2021},
  journaltitle = {IEEE Transactions on Multimedia},
  volume = {23},
  pages = {3022--3034},
  issn = {1941-0077},
  doi = {10.1109/TMM.2021.3068606},
  abstract = {The maturity of depth sensors and laser scanning techniques has enabled the convenient acquisition of 3D dynamic point clouds—one natural representation of 3D objects/scenes in motion, leading to a wide range of applications such as immersive tele-presence, autonomous driving, augmented and virtual reality. Nevertheless, dynamic point clouds usually exhibit holes of missing data, thus inpainting is crucial to the subsequent rendering or downstream understanding tasks. Dynamic point cloud inpainting has been largely overlooked so far, which is also quite challenging due to the irregular sampling patterns both in the spatial domain and temporal domain. To this end, we propose an efficient dynamic point cloud inpainting method based on a learnable spatial-temporal graph representation, exploiting both the second-order inter-frame coherence and the intra-frame self-similarity. The key is the second-order inter-frame coherence that enforces the consistent flow in 3D motion over time, for which we search the temporal correspondence in consecutive frames for the same underlying surface by the point-to-plane distance and represent the correlation between them via temporal edge weights in the graph. Based on the second-order inter-frame coherence and intra-frame self-similarity, we formulate dynamic point cloud inpainting as a joint optimization problem of the desired point cloud and underlying spatial-temporal graph, which is regularized by consistency in the temporal edge weights and smoothness in the spatial domain. We analyze and reformulate the optimization, leading to an efficient alternating minimization algorithm. Experimental results show that the proposed approach outperforms several competing methods significantly, both on synthetic holes and real holes.},
  eventtitle = {{{IEEE Transactions}} on {{Multimedia}}},
  keywords = {3D dynamic point clouds,Coherence,Dynamics,Geometry,inpainting,inter-frame coherence,Laplace equations,Measurement,Optimization,spatial-temporal graph,Three-dimensional displays},
  file = {/Users/marcel/Zotero/storage/I4MUS6KV/Fu and Hu - 2021 - Dynamic Point Cloud Inpainting via Spatial-Tempora.pdf}
}

@article{fukushimaNeocognitronSelforganizingNeural1980,
  title = {Neocognitron: {{A}} Self-Organizing Neural Network Model for a Mechanism of Pattern Recognition Unaffected by Shift in Position},
  shorttitle = {Neocognitron},
  author = {Fukushima, Kunihiko},
  date = {1980-04-01},
  journaltitle = {Biological Cybernetics},
  shortjournal = {Biol. Cybernetics},
  volume = {36},
  number = {4},
  pages = {193--202},
  issn = {1432-0770},
  doi = {10.1007/BF00344251},
  url = {https://doi.org/10.1007/BF00344251},
  urldate = {2022-04-29},
  abstract = {A neural network model for a mechanism of visual pattern recognition is proposed in this paper. The network is self-organized by “learning without a teacher”, and acquires an ability to recognize stimulus patterns based on the geometrical similarity (Gestalt) of their shapes without affected by their positions. This network is given a nickname “neocognitron”. After completion of self-organization, the network has a structure similar to the hierarchy model of the visual nervous system proposed by Hubel and Wiesel. The network consits of an input layer (photoreceptor array) followed by a cascade connection of a number of modular structures, each of which is composed of two layers of cells connected in a cascade. The first layer of each module consists of “S-cells”, which show characteristics similar to simple cells or lower order hypercomplex cells, and the second layer consists of “C-cells” similar to complex cells or higher order hypercomplex cells. The afferent synapses to each S-cell have plasticity and are modifiable. The network has an ability of unsupervised learning: We do not need any “teacher” during the process of self-organization, and it is only needed to present a set of stimulus patterns repeatedly to the input layer of the network. The network has been simulated on a digital computer. After repetitive presentation of a set of stimulus patterns, each stimulus pattern has become to elicit an output only from one of the C-cell of the last layer, and conversely, this C-cell has become selectively responsive only to that stimulus pattern. That is, none of the C-cells of the last layer responds to more than one stimulus pattern. The response of the C-cells of the last layer is not affected by the pattern's position at all. Neither is it affected by a small change in shape nor in size of the stimulus pattern.},
  langid = {english},
  keywords = {Complex Cell,Digital Computer,Input Layer,Neural Network Model,Pattern Recognition},
  file = {/Users/marcel/Zotero/storage/TCYLX4RU/Fukushima - 1980 - Neocognitron A self-organizing neural network mod.pdf}
}

@online{gaoRetrievalAugmentedGenerationLarge2024,
  title = {Retrieval-{{Augmented Generation}} for {{Large Language Models}}: {{A Survey}}},
  shorttitle = {Retrieval-{{Augmented Generation}} for {{Large Language Models}}},
  author = {Gao, Yunfan and Xiong, Yun and Gao, Xinyu and Jia, Kangxiang and Pan, Jinliu and Bi, Yuxi and Dai, Yi and Sun, Jiawei and Guo, Qianyu and Wang, Meng and Wang, Haofen},
  date = {2024-01-04},
  eprint = {2312.10997},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2312.10997},
  url = {http://arxiv.org/abs/2312.10997},
  urldate = {2024-03-15},
  abstract = {Large Language Models (LLMs) demonstrate significant capabilities but face challenges such as hallucination, outdated knowledge, and non-transparent, untraceable reasoning processes. Retrieval-Augmented Generation (RAG) has emerged as a promising solution by incorporating knowledge from external databases. This enhances the accuracy and credibility of the models, particularly for knowledge-intensive tasks, and allows for continuous knowledge updates and integration of domain-specific information. RAG synergistically merges LLMs' intrinsic knowledge with the vast, dynamic repositories of external databases. This comprehensive review paper offers a detailed examination of the progression of RAG paradigms, encompassing the Naive RAG, the Advanced RAG, and the Modular RAG. It meticulously scrutinizes the tripartite foundation of RAG frameworks, which includes the retrieval , the generation and the augmentation techniques. The paper highlights the state-of-the-art technologies embedded in each of these critical components, providing a profound understanding of the advancements in RAG systems. Furthermore, this paper introduces the metrics and benchmarks for assessing RAG models, along with the most up-to-date evaluation framework. In conclusion, the paper delineates prospective avenues for research, including the identification of challenges, the expansion of multi-modalities, and the progression of the RAG infrastructure and its ecosystem.},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
  file = {/Users/marcel/Zotero/storage/WQTY9FCD/Gao et al. - 2024 - Retrieval-Augmented Generation for Large Language Models A Survey.pdf;/Users/marcel/Zotero/storage/KXBFJE4E/2312.html}
}

@online{gasteigerDiffusionImprovesGraph2022,
  title = {Diffusion {{Improves Graph Learning}}},
  author = {Gasteiger, Johannes and Weißenberger, Stefan and Günnemann, Stephan},
  date = {2022-04-05},
  eprint = {1911.05485},
  eprinttype = {arXiv},
  eprintclass = {cs, stat},
  doi = {10.48550/arXiv.1911.05485},
  url = {http://arxiv.org/abs/1911.05485},
  urldate = {2023-02-28},
  abstract = {Graph convolution is the core of most Graph Neural Networks (GNNs) and usually approximated by message passing between direct (one-hop) neighbors. In this work, we remove the restriction of using only the direct neighbors by introducing a powerful, yet spatially localized graph convolution: Graph diffusion convolution (GDC). GDC leverages generalized graph diffusion, examples of which are the heat kernel and personalized PageRank. It alleviates the problem of noisy and often arbitrarily defined edges in real graphs. We show that GDC is closely related to spectral-based models and thus combines the strengths of both spatial (message passing) and spectral methods. We demonstrate that replacing message passing with graph diffusion convolution consistently leads to significant performance improvements across a wide range of models on both supervised and unsupervised tasks and a variety of datasets. Furthermore, GDC is not limited to GNNs but can trivially be combined with any graph-based model or algorithm (e.g. spectral clustering) without requiring any changes to the latter or affecting its computational complexity. Our implementation is available online.},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Computer Science - Social and Information Networks,Statistics - Machine Learning},
  file = {/Users/marcel/Zotero/storage/Q6BXVRKT/Gasteiger et al. - 2022 - Diffusion Improves Graph Learning.pdf;/Users/marcel/Zotero/storage/7X57EWA5/1911.html}
}

@online{gatysNeuralAlgorithmArtistic2015,
  title = {A {{Neural Algorithm}} of {{Artistic Style}}},
  author = {Gatys, Leon A. and Ecker, Alexander S. and Bethge, Matthias},
  date = {2015-09-02},
  eprint = {1508.06576},
  eprinttype = {arXiv},
  eprintclass = {cs, q-bio},
  doi = {10.48550/arXiv.1508.06576},
  url = {http://arxiv.org/abs/1508.06576},
  urldate = {2022-12-18},
  abstract = {In fine art, especially painting, humans have mastered the skill to create unique visual experiences through composing a complex interplay between the content and style of an image. Thus far the algorithmic basis of this process is unknown and there exists no artificial system with similar capabilities. However, in other key areas of visual perception such as object and face recognition near-human performance was recently demonstrated by a class of biologically inspired vision models called Deep Neural Networks. Here we introduce an artificial system based on a Deep Neural Network that creates artistic images of high perceptual quality. The system uses neural representations to separate and recombine content and style of arbitrary images, providing a neural algorithm for the creation of artistic images. Moreover, in light of the striking similarities between performance-optimised artificial neural networks and biological vision, our work offers a path forward to an algorithmic understanding of how humans create and perceive artistic imagery.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Neural and Evolutionary Computing,Quantitative Biology - Neurons and Cognition},
  file = {/Users/marcel/Zotero/storage/C2PIYLGQ/Gatys et al. - 2015 - A Neural Algorithm of Artistic Style.pdf;/Users/marcel/Zotero/storage/3TBE74TW/1508.html}
}

@online{geigerE3nnEuclideanNeural2022,
  title = {E3nn: {{Euclidean Neural Networks}}},
  shorttitle = {E3nn},
  author = {Geiger, Mario and Smidt, Tess},
  date = {2022-07-18},
  eprint = {2207.09453},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2207.09453},
  url = {http://arxiv.org/abs/2207.09453},
  urldate = {2022-08-18},
  abstract = {We present e3nn, a generalized framework for creating E(3) equivariant trainable functions, also known as Euclidean neural networks. e3nn naturally operates on geometry and geometric tensors that describe systems in 3D and transform predictably under a change of coordinate system. The core of e3nn are equivariant operations such as the TensorProduct class or the spherical harmonics functions that can be composed to create more complex modules such as convolutions and attention mechanisms. These core operations of e3nn can be used to efficiently articulate Tensor Field Networks, 3D Steerable CNNs, Clebsch-Gordan Networks, SE(3) Transformers and other E(3) equivariant networks.},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing},
  file = {/Users/marcel/Zotero/storage/HT3MRT7X/Geiger and Smidt - 2022 - e3nn Euclidean Neural Networks.pdf;/Users/marcel/Zotero/storage/5KZT2K3J/2207.html}
}

@article{genovChargemodeParallelArchitecture2001,
  title = {Charge-Mode Parallel Architecture for Vector-Matrix Multiplication},
  author = {Genov, R. and Cauwenberghs, G.},
  date = {2001-10},
  journaltitle = {IEEE Transactions on Circuits and Systems II: Analog and Digital Signal Processing},
  volume = {48},
  number = {10},
  pages = {930--936},
  issn = {1558-125X},
  doi = {10.1109/82.974781},
  url = {https://ieeexplore.ieee.org/abstract/document/974781},
  urldate = {2023-10-21},
  abstract = {An internally analog, externally digital architecture for parallel vector-matrix multiplication is presented. A three-transistor unit cell combines a single-bit dynamic random-access memory and a charge injection device binary multiplier and analog accumulator. Digital multiplication of variable resolution is obtained with bit-serial inputs and bit-parallel storage of matrix elements, by combining quantized outputs from multiple rows of cells over time. A prototype 512/spl times/128 vector-matrix multiplier on a single 3 mm /spl times/3 mm chip fabricated in standard 0.5-/spl mu/m CMOS technology achieves 8-bit effective resolution and dissipates 0.5 pJ per multiply-accumulate.},
  eventtitle = {{{IEEE Transactions}} on {{Circuits}} and {{Systems II}}: {{Analog}} and {{Digital Signal Processing}}},
  file = {/Users/marcel/Zotero/storage/Y8FHS65J/Genov and Cauwenberghs - 2001 - Charge-mode parallel architecture for vector-matrix multiplication.pdf;/Users/marcel/Zotero/storage/HN3YM73Q/974781.html}
}

@article{gielenAnalogCircuitDesign1990,
  title = {Analog Circuit Design Optimization Based on Symbolic Simulation and Simulated Annealing},
  author = {Gielen, G.G.E. and Walscharts, H.C.C. and Sansen, W.M.C.},
  date = {1990-06},
  journaltitle = {IEEE Journal of Solid-State Circuits},
  volume = {25},
  number = {3},
  pages = {707--713},
  issn = {1558-173X},
  doi = {10.1109/4.102664},
  url = {https://ieeexplore.ieee.org/document/102664},
  urldate = {2023-12-16},
  abstract = {A methodology for the automatic design optimization of analog integrated circuits is presented. A non-fixed-topology approach is realized by combining the optimization program OPTIMAN with the symbolic simulator ISAAC. After selecting a circuit topology, the user invokes ISAAC to model the circuit. ISAAC generates both exact and simplified analytic expressions, describing the circuit's behavior. The model is then passed to the design optimization program OPTIMAN. This program is based on a generalized formulation of the analog design problem. For the selected topology, the independent design variables are automatically extracted and OPTIMAN sizes all elements to satisfy the performance constraints, thereby optimizing a user-defined design objective. The global optimization method used on the analytic circuit models is simulated annealing. Practical examples show that OPTIMAN quickly designs analog circuits, closely meeting the specifications, and that it is a flexible and reliable design and exploration tool.{$<>$}},
  eventtitle = {{{IEEE Journal}} of {{Solid-State Circuits}}},
  file = {/Users/marcel/Zotero/storage/9GC9TDQJ/102664.html}
}

@online{gilmerNeuralMessagePassing2017,
  title = {Neural {{Message Passing}} for {{Quantum Chemistry}}},
  author = {Gilmer, Justin and Schoenholz, Samuel S. and Riley, Patrick F. and Vinyals, Oriol and Dahl, George E.},
  date = {2017-06-12},
  eprint = {1704.01212},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.1704.01212},
  url = {http://arxiv.org/abs/1704.01212},
  urldate = {2022-09-22},
  abstract = {Supervised learning on molecules has incredible potential to be useful in chemistry, drug discovery, and materials science. Luckily, several promising and closely related neural network models invariant to molecular symmetries have already been described in the literature. These models learn a message passing algorithm and aggregation procedure to compute a function of their entire input graph. At this point, the next step is to find a particularly effective variant of this general approach and apply it to chemical prediction benchmarks until we either solve them or reach the limits of the approach. In this paper, we reformulate existing models into a single common framework we call Message Passing Neural Networks (MPNNs) and explore additional novel variations within this framework. Using MPNNs we demonstrate state of the art results on an important molecular property prediction benchmark; these results are strong enough that we believe future work should focus on datasets with larger molecules or more accurate ground truth labels.},
  pubstate = {prepublished},
  keywords = {Computer Science - Machine Learning,I.2.6},
  file = {/Users/marcel/Zotero/storage/ZLNXH4BF/Gilmer et al. - 2017 - Neural Message Passing for Quantum Chemistry.pdf;/Users/marcel/Zotero/storage/KWRUWNR8/1704.html}
}

@book{gleickChaosMakingNew1988,
  title = {Chaos: Making a New Science},
  shorttitle = {Chaos},
  author = {Gleick, James},
  date = {1988},
  publisher = {Penguin Books},
  location = {New York},
  isbn = {978-0-14-009250-9},
  langid = {english},
  pagetotal = {352},
  file = {/Users/marcel/Zotero/storage/7JPBXKSY/James Gleick Chaos.pdf}
}

@unpublished{golkarBiologicallyPlausibleNeural2020,
  title = {A Biologically Plausible Neural Network for Local Supervision in Cortical Microcircuits},
  author = {Golkar, Siavash and Lipshutz, David and Bahroun, Yanis and Sengupta, Anirvan M. and Chklovskii, Dmitri B.},
  date = {2020-11-30},
  eprint = {2011.15031},
  eprinttype = {arXiv},
  eprintclass = {cs, q-bio},
  url = {http://arxiv.org/abs/2011.15031},
  urldate = {2022-04-19},
  abstract = {The backpropagation algorithm is an invaluable tool for training artificial neural networks; however, because of a weight sharing requirement, it does not provide a plausible model of brain function. Here, in the context of a two-layer network, we derive an algorithm for training a neural network which avoids this problem by not requiring explicit error computation and backpropagation. Furthermore, our algorithm maps onto a neural network that bears a remarkable resemblance to the connectivity structure and learning rules of the cortex. We find that our algorithm empirically performs comparably to backprop on a number of datasets.},
  keywords = {Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing,Quantitative Biology - Neurons and Cognition},
  file = {/Users/marcel/Zotero/storage/NXPC3TM6/Golkar et al. - 2020 - A biologically plausible neural network for local .pdf;/Users/marcel/Zotero/storage/GAWKW9S3/2011.html}
}

@online{GoodMinima,
  title = {The {{Good Minima}}},
  url = {https://johanwind.github.io/},
  urldate = {2022-12-01},
  abstract = {A blog about implicit biases in deep learning.},
  langid = {english},
  organization = {The Good Minima},
  file = {/Users/marcel/Zotero/storage/VKWZDNRV/johanwind.github.io.html}
}

@article{GraphMETROMitigatingComplex,
  title = {{{GraphMETRO}}: {{Mitigating Complex Graph Distribution Shifts}} via {{Mixture}} of {{Aligned Experts}}},
  file = {/Users/marcel/Zotero/storage/C8L49AQW/GraphMETRO Mitigating Complex Graph Distribution Shifts via Mixture of Aligned Experts.pdf}
}

@unpublished{grathwohlFFJORDFreeformContinuous2018,
  title = {{{FFJORD}}: {{Free-form Continuous Dynamics}} for {{Scalable Reversible Generative Models}}},
  shorttitle = {{{FFJORD}}},
  author = {Grathwohl, Will and Chen, Ricky T. Q. and Bettencourt, Jesse and Sutskever, Ilya and Duvenaud, David},
  date = {2018-10-22},
  eprint = {1810.01367},
  eprinttype = {arXiv},
  eprintclass = {cs, stat},
  url = {http://arxiv.org/abs/1810.01367},
  urldate = {2021-07-27},
  abstract = {A promising class of generative models maps points from a simple distribution to a complex distribution through an invertible neural network. Likelihood-based training of these models requires restricting their architectures to allow cheap computation of Jacobian determinants. Alternatively, the Jacobian trace can be used if the transformation is specified by an ordinary differential equation. In this paper, we use Hutchinson's trace estimator to give a scalable unbiased estimate of the log-density. The result is a continuous-time invertible generative model with unbiased density estimation and one-pass sampling, while allowing unrestricted neural network architectures. We demonstrate our approach on high-dimensional density estimation, image generation, and variational inference, achieving the state-of-the-art among exact likelihood methods with efficient sampling.},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/marcel/Zotero/storage/3L6TCNCW/Grathwohl et al_2018_FFJORD.pdf;/Users/marcel/Zotero/storage/CBG8FBER/1810.html}
}

@online{guMambaLinearTimeSequence2024,
  title = {Mamba: {{Linear-Time Sequence Modeling}} with {{Selective State Spaces}}},
  shorttitle = {Mamba},
  author = {Gu, Albert and Dao, Tri},
  date = {2024-05-31},
  eprint = {2312.00752},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2312.00752},
  url = {http://arxiv.org/abs/2312.00752},
  urldate = {2025-01-30},
  abstract = {Foundation models, now powering most of the exciting applications in deep learning, are almost universally based on the Transformer architecture and its core attention module. Many subquadratic-time architectures such as linear attention, gated convolution and recurrent models, and structured state space models (SSMs) have been developed to address Transformers' computational inefficiency on long sequences, but they have not performed as well as attention on important modalities such as language. We identify that a key weakness of such models is their inability to perform content-based reasoning, and make several improvements. First, simply letting the SSM parameters be functions of the input addresses their weakness with discrete modalities, allowing the model to selectively propagate or forget information along the sequence length dimension depending on the current token. Second, even though this change prevents the use of efficient convolutions, we design a hardware-aware parallel algorithm in recurrent mode. We integrate these selective SSMs into a simplified end-to-end neural network architecture without attention or even MLP blocks (Mamba). Mamba enjoys fast inference (5\$\textbackslash times\$ higher throughput than Transformers) and linear scaling in sequence length, and its performance improves on real data up to million-length sequences. As a general sequence model backbone, Mamba achieves state-of-the-art performance across several modalities such as language, audio, and genomics. On language modeling, our Mamba-3B model outperforms Transformers of the same size and matches Transformers twice its size, both in pretraining and downstream evaluation.},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning},
  file = {/Users/marcel/Zotero/storage/EXX6VVER/Gu and Dao - 2024 - Mamba Linear-Time Sequence Modeling with Selective State Spaces.pdf;/Users/marcel/Zotero/storage/4KXI4VED/2312.html}
}

@article{guss2019minerldata,
  title = {{{MineRL}}: {{A}} Large-Scale Dataset of {{Minecraft}} Demonstrations},
  author = {Guss, William H. and Houghton, Brandon and Topin, Nicholay and Wang, Phillip and Codel, Cayden and Veloso, Manuela and Salakhutdinov, Ruslan},
  date = {2019},
  journaltitle = {Twenty-Eighth International Joint Conference on Artificial Intelligence},
  url = {http://minerl.io}
}

@online{HabanaGaudi2,
  title = {Habana {{Gaudi2}}},
  url = {https://habana.ai/training/gaudi2/},
  urldate = {2023-02-28},
  abstract = {INTRODUCING THE GAUDI2 PROCESSOR FOR TRAINING DEEP LEARNING WORKLOADS.BUILT ON THE HIGH-EFFICIENCY GAUDI ARCHITECTURE, NOW IN 7nm},
  langid = {american},
  organization = {Habana},
  file = {/Users/marcel/Zotero/storage/7P44XKM4/gaudi2.html}
}

@online{hageleScalingLawsComputeOptimal2024,
  title = {Scaling {{Laws}} and {{Compute-Optimal Training Beyond Fixed Training Durations}}},
  author = {Hägele, Alexander and Bakouch, Elie and Kosson, Atli and Allal, Loubna Ben and Werra, Leandro Von and Jaggi, Martin},
  date = {2024-10-17},
  eprint = {2405.18392},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2405.18392},
  url = {http://arxiv.org/abs/2405.18392},
  urldate = {2024-12-04},
  abstract = {Scale has become a main ingredient in obtaining strong machine learning models. As a result, understanding a model's scaling properties is key to effectively designing both the right training setup as well as future generations of architectures. In this work, we argue that scale and training research has been needlessly complex due to reliance on the cosine schedule, which prevents training across different lengths for the same model size. We investigate the training behavior of a direct alternative -- constant learning rate and cooldowns -- and find that it scales predictably and reliably similar to cosine. Additionally, we show that stochastic weight averaging yields improved performance along the training trajectory, without additional training costs, across different scales. Importantly, with these findings we demonstrate that scaling experiments can be performed with significantly reduced compute and GPU hours by utilizing fewer but reusable training runs. Our code is available at \textbackslash url\{https://github.com/epfml/schedules-and-scaling/\}.},
  pubstate = {prepublished},
  keywords = {Computer Science - Machine Learning},
  file = {/Users/marcel/Zotero/storage/BU9RK5QY/Hägele et al. - 2024 - Scaling Laws and Compute-Optimal Training Beyond Fixed Training Durations.pdf;/Users/marcel/Zotero/storage/76PZY8SS/2405.html}
}

@software{haiku2020github,
  title = {Haiku: {{Sonnet}} for {{JAX}}},
  author = {Hennigan, Tom and Cai, Trevor and Norman, Tamara and Babuschkin, Igor},
  date = {2020},
  url = {http://github.com/deepmind/dm-haiku},
  version = {0.0.9}
}

@book{harpeAnalogCircuitsMachine2022,
  title = {Analog {{Circuits}} for {{Machine Learning}}, {{Current}}/{{Voltage}}/{{Temperature Sensors}}, and {{High-speed Communication}}: {{Advances}} in {{Analog Circuit Design}} 2021},
  shorttitle = {Analog {{Circuits}} for {{Machine Learning}}, {{Current}}/{{Voltage}}/{{Temperature Sensors}}, and {{High-speed Communication}}},
  editor = {Harpe, Pieter and Makinwa, Kofi A.A. and Baschirotto, Andrea},
  date = {2022},
  publisher = {Springer International Publishing},
  location = {Cham},
  doi = {10.1007/978-3-030-91741-8},
  url = {https://link.springer.com/10.1007/978-3-030-91741-8},
  urldate = {2023-10-20},
  isbn = {978-3-030-91740-1 978-3-030-91741-8},
  langid = {english},
  keywords = {Analog circuit design,Analog to digital converters,CMOS ADCs,High-performance ADCs,Nanoscale CMOS},
  file = {/Users/marcel/Zotero/storage/MYIK453F/Harpe et al. - 2022 - Analog Circuits for Machine Learning, CurrentVoltageTemperature Sensors, and High-speed Communicat.pdf}
}

@article{hastingsMonteCarloSampling1970,
  title = {Monte {{Carlo}} Sampling Methods Using {{Markov}} Chains and Their Applications},
  author = {Hastings, W. K.},
  date = {1970-04-01},
  journaltitle = {Biometrika},
  shortjournal = {Biometrika},
  volume = {57},
  number = {1},
  pages = {97--109},
  issn = {0006-3444},
  doi = {10.1093/biomet/57.1.97},
  url = {https://doi.org/10.1093/biomet/57.1.97},
  urldate = {2023-12-16},
  abstract = {A generalization of the sampling method introduced by Metropolis et al. (1953) is presented along with an exposition of the relevant theory, techniques of application and methods and difficulties of assessing the error in Monte Carlo estimates. Examples of the methods, including the generation of random orthogonal matrices and potential applications of the methods to numerical problems arising in statistics, are discussed.},
  file = {/Users/marcel/Zotero/storage/6H4MP7IA/284580.html}
}

@article{hayesSimulating500Million,
  title = {Simulating 500 Million Years of Evolution with a Language Model},
  author = {Hayes, Thomas and Rao, Roshan and Akin, Halil and Sofroniew, Nicholas James and Oktay, Deniz and Lin, Zeming and Verkuil, Robert and Tran, Vincent Quy and Deaton, Jonathan and Wiggert, Marius and Badkundri, Rohil and Shafkat, Irhum and Gong, Jun and Derry, Alexander and Molina, Raul Santiago and Thomas, Neil and Khan, Yousuf and Mishra, Chetan and Kim, Carolyn and Bartie, Liam J and Hsu, Patrick D and Sercu, Tom and Candido, Salvatore and Rives, Alexander},
  abstract = {More than three billion years of evolution have produced an image of biology encoded into the space of natural proteins. Here we show that language models trained on tokens generated by evolution can act as evolutionary simulators to generate functional proteins that are far away from known proteins. We present ESM3, a frontier multimodal generative language model that reasons over the sequence, structure, and function of proteins. ESM3 can follow complex prompts combining its modalities and is highly responsive to biological alignment. We have prompted ESM3 to generate fluorescent proteins with a chain of thought. Among the generations that we synthesized, we found a bright fluorescent protein at far distance (58\% identity) from known fluorescent proteins. Similarly distant natural fluorescent proteins are separated by over five hundred million years of evolution.},
  langid = {english},
  file = {/Users/marcel/Zotero/storage/FE3EE4SU/Hayes et al. - Simulating 500 million years of evolution with a language model.pdf}
}

@online{HeartbeatSchedulingProvable,
  title = {Heartbeat Scheduling: Provable Efficiency for Nested Parallelism | {{Proceedings}} of the 39th {{ACM SIGPLAN Conference}} on {{Programming Language Design}} and {{Implementation}}},
  url = {https://dl.acm.org/doi/10.1145/3192366.3192391},
  urldate = {2024-10-06},
  file = {/Users/marcel/Zotero/storage/UU5IQHJR/3192366.3192391.pdf;/Users/marcel/Zotero/storage/V6I2A559/3192366.html}
}

@book{hebbOrganizationBehaviorNeuropsychological2002,
  title = {The Organization of Behavior: A Neuropsychological Theory},
  shorttitle = {The Organization of Behavior},
  author = {Hebb, D. O.},
  date = {2002},
  publisher = {L. Erlbaum Associates},
  location = {Mahwah, N.J},
  isbn = {978-0-8058-4300-2},
  pagetotal = {335},
  keywords = {Neuropsychology}
}

@article{heDeepResidualLearning2015,
  title = {Deep {{Residual Learning}} for {{Image Recognition}}},
  author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  date = {2015-12-10},
  doi = {10.48550/arXiv.1512.03385},
  url = {https://arxiv.org/abs/1512.03385v1},
  urldate = {2022-05-02},
  abstract = {Deeper neural networks are more difficult to train. We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously. We explicitly reformulate the layers as learning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We provide comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets with a depth of up to 152 layers---8x deeper than VGG nets but still having lower complexity. An ensemble of these residual nets achieves 3.57\% error on the ImageNet test set. This result won the 1st place on the ILSVRC 2015 classification task. We also present analysis on CIFAR-10 with 100 and 1000 layers. The depth of representations is of central importance for many visual recognition tasks. Solely due to our extremely deep representations, we obtain a 28\% relative improvement on the COCO object detection dataset. Deep residual nets are foundations of our submissions to ILSVRC \& COCO 2015 competitions, where we also won the 1st places on the tasks of ImageNet detection, ImageNet localization, COCO detection, and COCO segmentation.},
  langid = {english},
  file = {/Users/marcel/Zotero/storage/FFXV9QXD/He et al. - 2015 - Deep Residual Learning for Image Recognition.pdf;/Users/marcel/Zotero/storage/PS9P3KJ6/1512.html}
}

@inproceedings{heLearningFilterPruning2020,
  title = {Learning {{Filter Pruning Criteria}} for {{Deep Convolutional Neural Networks Acceleration}}},
  booktitle = {2020 {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}} ({{CVPR}})},
  author = {He, Yang and Ding, Yuhang and Liu, Ping and Zhu, Linchao and Zhang, Hanwang and Yang, Yi},
  date = {2020-06},
  pages = {2006--2015},
  issn = {2575-7075},
  doi = {10.1109/CVPR42600.2020.00208},
  abstract = {Filter pruning has been widely applied to neural network compression and acceleration. Existing methods usually utilize pre-defined pruning criteria, such as Lp-norm, to prune unimportant filters. There are two major limitations to these methods. First, existing methods fail to consider the variety of filter distribution across layers. To extract features of the coarse level to the fine level, the filters of different layers have various distributions. Therefore, it is not suitable to utilize the same pruning criteria to different functional layers. Second, prevailing layer-by-layer pruning methods process each layer independently and sequentially, failing to consider that all the layers in the network collaboratively make the final prediction. In this paper, we propose Learning Filter Pruning Criteria (LFPC) to solve the above problems. Specifically, we develop a differentiable pruning criteria sampler. This sampler is learnable and optimized by the validation loss of the pruned network obtained from the sampled criteria. In this way, we could adaptively select the appropriate pruning criteria for different functional layers. Besides, when evaluating the sampled criteria, LFPC comprehensively consider the contribution of all the layers at the same time. Experiments validate our approach on three image classification benchmarks. Notably, on ILSVRC-2012, our LFPC reduces more than 60\% FLOPs on ResNet-50 with only 0.83\% top-5 accuracy loss.},
  eventtitle = {2020 {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}} ({{CVPR}})},
  keywords = {Acceleration,Benchmark testing,Computer architecture,Computer vision,Convolutional neural networks,Feature extraction,Training},
  file = {/Users/marcel/Zotero/storage/W64S37SN/He et al_2020_Learning Filter Pruning Criteria for Deep Convolutional Neural Networks.pdf;/Users/marcel/Zotero/storage/NMGUANR3/9156434.html}
}

@article{herculano-houzelRemarkableNotExtraordinary2012,
  title = {The Remarkable, yet Not Extraordinary, Human Brain as a Scaled-up Primate Brain and Its Associated Cost},
  author = {Herculano-Houzel, Suzana},
  date = {2012-06-26},
  journaltitle = {Proceedings of the National Academy of Sciences of the United States of America},
  shortjournal = {Proc Natl Acad Sci U S A},
  volume = {109},
  eprint = {22723358},
  eprinttype = {pmid},
  pages = {10661--10668},
  issn = {0027-8424},
  doi = {10.1073/pnas.1201895109},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3386878/},
  urldate = {2022-12-01},
  abstract = {Neuroscientists have become used to a number of “facts” about the human brain: It has 100 billion neurons and 10- to 50-fold more glial cells; it is the largest-than-expected for its body among primates and mammals in general, and therefore the most cognitively able; it consumes an outstanding 20\% of the total body energy budget despite representing only 2\% of body mass because of an increased metabolic need of its neurons; and it is endowed with an overdeveloped cerebral cortex, the largest compared with brain size. These facts led to the widespread notion that the human brain is literally extraordinary: an outlier among mammalian brains, defying evolutionary rules that apply to other species, with a uniqueness seemingly necessary to justify the superior cognitive abilities of humans over mammals with even larger brains. These facts, with deep implications for neurophysiology and evolutionary biology, are not grounded on solid evidence or sound assumptions, however. Our recent development of a method that allows rapid and reliable quantification of the numbers of cells that compose the whole brain has provided a means to verify these facts. Here, I review this recent evidence and argue that, with 86 billion neurons and just as many nonneuronal cells, the human brain is a scaled-up primate brain in its cellular composition and metabolic cost, with a relatively enlarged cerebral cortex that does not have a relatively larger number of brain neurons yet is remarkable in its cognitive abilities and metabolism simply because of its extremely large number of neurons.},
  issue = {Suppl 1},
  pmcid = {PMC3386878},
  file = {/Users/marcel/Zotero/storage/MDMDNDLX/Herculano-Houzel - 2012 - The remarkable, yet not extraordinary, human brain.pdf}
}

@online{hoDenoisingDiffusionProbabilistic2020,
  title = {Denoising {{Diffusion Probabilistic Models}}},
  author = {Ho, Jonathan and Jain, Ajay and Abbeel, Pieter},
  date = {2020-12-16},
  eprint = {2006.11239},
  eprinttype = {arXiv},
  eprintclass = {cs, stat},
  doi = {10.48550/arXiv.2006.11239},
  url = {http://arxiv.org/abs/2006.11239},
  urldate = {2022-07-11},
  abstract = {We present high quality image synthesis results using diffusion probabilistic models, a class of latent variable models inspired by considerations from nonequilibrium thermodynamics. Our best results are obtained by training on a weighted variational bound designed according to a novel connection between diffusion probabilistic models and denoising score matching with Langevin dynamics, and our models naturally admit a progressive lossy decompression scheme that can be interpreted as a generalization of autoregressive decoding. On the unconditional CIFAR10 dataset, we obtain an Inception score of 9.46 and a state-of-the-art FID score of 3.17. On 256x256 LSUN, we obtain sample quality similar to ProgressiveGAN. Our implementation is available at https://github.com/hojonathanho/diffusion},
  pubstate = {prepublished},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/marcel/Zotero/storage/UL35LDUM/Ho et al. - 2020 - Denoising Diffusion Probabilistic Models.pdf;/Users/marcel/Zotero/storage/N3WK8QJ4/2006.html}
}

@article{hodgkinQuantitativeDescriptionMembrane1952a,
  title = {A Quantitative Description of Membrane Current and Its Application to Conduction and Excitation in Nerve},
  author = {Hodgkin, A. L. and Huxley, A. F.},
  date = {1952-08-28},
  journaltitle = {The Journal of Physiology},
  shortjournal = {J Physiol},
  volume = {117},
  number = {4},
  eprint = {12991237},
  eprinttype = {pmid},
  pages = {500--544},
  issn = {0022-3751},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1392413/},
  urldate = {2022-05-01},
  pmcid = {PMC1392413},
  file = {/Users/marcel/Zotero/storage/N82XQIU2/Hodgkin and Huxley - 1952 - A quantitative description of membrane current and.pdf}
}

@online{hoffmannTrainingComputeOptimalLarge2022,
  title = {Training {{Compute-Optimal Large Language Models}}},
  author = {Hoffmann, Jordan and Borgeaud, Sebastian and Mensch, Arthur and Buchatskaya, Elena and Cai, Trevor and Rutherford, Eliza and Casas, Diego de Las and Hendricks, Lisa Anne and Welbl, Johannes and Clark, Aidan and Hennigan, Tom and Noland, Eric and Millican, Katie and family=Driessche, given=George, prefix=van den, useprefix=false and Damoc, Bogdan and Guy, Aurelia and Osindero, Simon and Simonyan, Karen and Elsen, Erich and Rae, Jack W. and Vinyals, Oriol and Sifre, Laurent},
  date = {2022-03-29},
  eprint = {2203.15556},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2203.15556},
  url = {http://arxiv.org/abs/2203.15556},
  urldate = {2024-05-08},
  abstract = {We investigate the optimal model size and number of tokens for training a transformer language model under a given compute budget. We find that current large language models are significantly undertrained, a consequence of the recent focus on scaling language models whilst keeping the amount of training data constant. By training over 400 language models ranging from 70 million to over 16 billion parameters on 5 to 500 billion tokens, we find that for compute-optimal training, the model size and the number of training tokens should be scaled equally: for every doubling of model size the number of training tokens should also be doubled. We test this hypothesis by training a predicted compute-optimal model, Chinchilla, that uses the same compute budget as Gopher but with 70B parameters and 4\$\textbackslash times\$ more more data. Chinchilla uniformly and significantly outperforms Gopher (280B), GPT-3 (175B), Jurassic-1 (178B), and Megatron-Turing NLG (530B) on a large range of downstream evaluation tasks. This also means that Chinchilla uses substantially less compute for fine-tuning and inference, greatly facilitating downstream usage. As a highlight, Chinchilla reaches a state-of-the-art average accuracy of 67.5\% on the MMLU benchmark, greater than a 7\% improvement over Gopher.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computation and Language,Computer Science - Machine Learning},
  file = {/Users/marcel/Zotero/storage/VD4TBQ6G/Hoffmann et al. - 2022 - Training Compute-Optimal Large Language Models.pdf;/Users/marcel/Zotero/storage/BYC6FAHV/2203.html}
}

@article{hopfieldNeuralNetworksPhysical1982,
  title = {Neural Networks and Physical Systems with Emergent Collective Computational Abilities.},
  author = {Hopfield, J J},
  date = {1982-04},
  journaltitle = {Proceedings of the National Academy of Sciences of the United States of America},
  shortjournal = {Proc Natl Acad Sci U S A},
  volume = {79},
  number = {8},
  eprint = {6953413},
  eprinttype = {pmid},
  pages = {2554--2558},
  issn = {0027-8424},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC346238/},
  urldate = {2022-05-02},
  abstract = {Computational properties of use of biological organisms or to the construction of computers can emerge as collective properties of systems having a large number of simple equivalent components (or neurons). The physical meaning of content-addressable memory is described by an appropriate phase space flow of the state of a system. A model of such a system is given, based on aspects of neurobiology but readily adapted to integrated circuits. The collective properties of this model produce a content-addressable memory which correctly yields an entire memory from any subpart of sufficient size. The algorithm for the time evolution of the state of the system is based on asynchronous parallel processing. Additional emergent collective properties include some capacity for generalization, familiarity recognition, categorization, error correction, and time sequence retention. The collective properties are only weakly sensitive to details of the modeling or the failure of individual devices.},
  pmcid = {PMC346238}
}

@article{hornikMultilayerFeedforwardNetworks1989,
  title = {Multilayer Feedforward Networks Are Universal Approximators},
  author = {Hornik, Kurt and Stinchcombe, Maxwell and White, Halbert},
  date = {1989-01-01},
  journaltitle = {Neural Networks},
  shortjournal = {Neural Networks},
  volume = {2},
  number = {5},
  pages = {359--366},
  issn = {0893-6080},
  doi = {10.1016/0893-6080(89)90020-8},
  url = {https://www.sciencedirect.com/science/article/pii/0893608089900208},
  urldate = {2022-04-28},
  abstract = {This paper rigorously establishes that standard multilayer feedforward networks with as few as one hidden layer using arbitrary squashing functions are capable of approximating any Borel measurable function from one finite dimensional space to another to any desired degree of accuracy, provided sufficiently many hidden units are available. In this sense, multilayer feedforward networks are a class of universal approximators.},
  langid = {english},
  keywords = {Back-propagation networks,Feedforward networks,Mapping networks,Network representation capability,Sigma-Pi networks,Squashing functions,Stone-Weierstrass Theorem,Universal approximation},
  file = {/Users/marcel/Zotero/storage/LFVE5I66/Hornik et al. - 1989 - Multilayer feedforward networks are universal appr.pdf;/Users/marcel/Zotero/storage/UW7CBZGB/0893608089900208.html}
}

@book{hubelBrainVisualPerception2005,
  title = {Brain and Visual Perception: The Story of a 25-Year Collaboration},
  shorttitle = {Brain and Visual Perception},
  author = {Hubel, David H. and Wiesel, Torsten N.},
  date = {2005},
  publisher = {Oxford University Press},
  location = {New York, N.Y},
  isbn = {978-0-19-517618-6},
  pagetotal = {729},
  keywords = {Biomedical Research,history,History of Medicine 20th Cent,physiology,United States,Visual pathways,Visual perception,Visual Perception}
}

@article{hubelReceptiveFieldsSingle1959,
  title = {Receptive Fields of Single Neurons in the Cat's Striate Cortex},
  author = {Hubel, D. H. and Wiesel, T. N.},
  date = {1959-10-01},
  journaltitle = {The Journal of Physiology},
  volume = {148},
  number = {3},
  pages = {574--591},
  issn = {00223751},
  doi = {10.1113/jphysiol.1959.sp006308},
  url = {https://onlinelibrary.wiley.com/doi/10.1113/jphysiol.1959.sp006308},
  urldate = {2022-04-29},
  langid = {english},
  file = {/Users/marcel/Zotero/storage/D458RJIH/Hubel and Wiesel - 1959 - Receptive fields of single neurons in the cat's st.pdf}
}

@online{huggingfaceHuggingFaceAI2024,
  title = {Hugging {{Face}} – {{The AI}} Community Building the Future.},
  author = {HuggingFace},
  date = {2024-03-14},
  url = {https://huggingface.co/},
  urldate = {2024-03-17},
  abstract = {We’re on a journey to advance and democratize artificial intelligence through open source and open science.},
  file = {/Users/marcel/Zotero/storage/TANQZCAW/huggingface.co.html}
}

@online{huLoRALowRankAdaptation2021,
  title = {{{LoRA}}: {{Low-Rank Adaptation}} of {{Large Language Models}}},
  shorttitle = {{{LoRA}}},
  author = {Hu, Edward J. and Shen, Yelong and Wallis, Phillip and Allen-Zhu, Zeyuan and Li, Yuanzhi and Wang, Shean and Wang, Lu and Chen, Weizhu},
  date = {2021-10-16},
  eprint = {2106.09685},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2106.09685},
  url = {http://arxiv.org/abs/2106.09685},
  urldate = {2024-02-13},
  abstract = {An important paradigm of natural language processing consists of large-scale pre-training on general domain data and adaptation to particular tasks or domains. As we pre-train larger models, full fine-tuning, which retrains all model parameters, becomes less feasible. Using GPT-3 175B as an example -- deploying independent instances of fine-tuned models, each with 175B parameters, is prohibitively expensive. We propose Low-Rank Adaptation, or LoRA, which freezes the pre-trained model weights and injects trainable rank decomposition matrices into each layer of the Transformer architecture, greatly reducing the number of trainable parameters for downstream tasks. Compared to GPT-3 175B fine-tuned with Adam, LoRA can reduce the number of trainable parameters by 10,000 times and the GPU memory requirement by 3 times. LoRA performs on-par or better than fine-tuning in model quality on RoBERTa, DeBERTa, GPT-2, and GPT-3, despite having fewer trainable parameters, a higher training throughput, and, unlike adapters, no additional inference latency. We also provide an empirical investigation into rank-deficiency in language model adaptation, which sheds light on the efficacy of LoRA. We release a package that facilitates the integration of LoRA with PyTorch models and provide our implementations and model checkpoints for RoBERTa, DeBERTa, and GPT-2 at https://github.com/microsoft/LoRA.},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Machine Learning},
  file = {/Users/marcel/Zotero/storage/XGY53S3C/Hu et al. - 2021 - LoRA Low-Rank Adaptation of Large Language Models.pdf;/Users/marcel/Zotero/storage/4BV5RRC4/2106.html}
}

@unpublished{hutchinsonLieTransformerEquivariantSelfattention2021,
  title = {{{LieTransformer}}: {{Equivariant}} Self-Attention for {{Lie Groups}}},
  shorttitle = {{{LieTransformer}}},
  author = {Hutchinson, Michael and Lan, Charline Le and Zaidi, Sheheryar and Dupont, Emilien and Teh, Yee Whye and Kim, Hyunjik},
  date = {2021-06-16},
  eprint = {2012.10885},
  eprinttype = {arXiv},
  eprintclass = {cs, stat},
  url = {http://arxiv.org/abs/2012.10885},
  urldate = {2021-07-27},
  abstract = {Group equivariant neural networks are used as building blocks of group invariant neural networks, which have been shown to improve generalisation performance and data efficiency through principled parameter sharing. Such works have mostly focused on group equivariant convolutions, building on the result that group equivariant linear maps are necessarily convolutions. In this work, we extend the scope of the literature to self-attention, that is emerging as a prominent building block of deep learning models. We propose the LieTransformer, an architecture composed of LieSelfAttention layers that are equivariant to arbitrary Lie groups and their discrete subgroups. We demonstrate the generality of our approach by showing experimental results that are competitive to baseline methods on a wide range of tasks: shape counting on point clouds, molecular property regression and modelling particle trajectories under Hamiltonian dynamics.},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/marcel/Zotero/storage/BDIDM8AK/Hutchinson et al_2021_LieTransformer.pdf;/Users/marcel/Zotero/storage/MVSMJ3WL/2012.html}
}

@inproceedings{huUnderstandingFactualKnowledge2023,
  title = {Towards {{Understanding Factual Knowledge}} of {{Large Language Models}}},
  author = {Hu, Xuming and Chen, Junzhe and Li, Xiaochuan and Guo, Yufei and Wen, Lijie and Yu, Philip S. and Guo, Zhijiang},
  date = {2023-10-13},
  url = {https://openreview.net/forum?id=9OevMUdods},
  urldate = {2024-03-15},
  abstract = {Large language models (LLMs) have recently driven striking performance improvements across a range of natural language processing tasks. The factual knowledge acquired during pretraining and instruction tuning can be useful in various downstream tasks, such as question answering, and language generation. Unlike conventional Knowledge Bases (KBs) that explicitly store factual knowledge, LLMs implicitly store facts in their parameters. Content generated by the LLMs can often exhibit inaccuracies or deviations from the truth, due to facts that can be incorrectly induced or become obsolete over time. To this end, we aim to explore the extent and scope of factual knowledge within LLMs by designing the benchmark Pinocchio. Pinocchio contains 20K diverse factual questions that span different sources, timelines, domains, regions, and languages. Furthermore, we investigate whether LLMs can compose multiple facts, update factual knowledge temporally, reason over multiple pieces of facts, identify subtle factual differences, and resist adversarial examples. Extensive experiments on different sizes and types of LLMs show that existing LLMs still lack factual knowledge and suffer from various spurious correlations. We believe this is a critical bottleneck for realizing trustworthy artificial intelligence. The dataset Pinocchio and our codes are publicly available at: https://github.com/THU-BPM/Pinocchio.},
  eventtitle = {The {{Twelfth International Conference}} on {{Learning Representations}}},
  langid = {english},
  file = {/Users/marcel/Zotero/storage/HZAHYX3N/Hu et al. - 2023 - Towards Understanding Factual Knowledge of Large Language Models.pdf}
}

@book{hwuProgrammingMassivelyParallel2023,
  title = {Programming Massively Parallel Processors: A Hands-on Approach},
  shorttitle = {Programming Massively Parallel Processors},
  author = {Hwu, Wen-mei W. and Kirk, David and El Hajj, Izzat},
  date = {2023},
  edition = {Fourth edition},
  publisher = {Morgan Kaufmann is an imprint of Elsevier},
  location = {Cambridge, MA},
  isbn = {978-0-323-91231-0},
  langid = {english},
  pagetotal = {551},
  file = {/Users/marcel/Zotero/storage/2Z29S87I/Programming Massively Parallel Processors.pdf;/Users/marcel/Zotero/storage/XTEBGYJ7/Hwu et al. - 2023 - Programming massively parallel processors a hands-on approach.pdf}
}

@article{illingBiologicallyPlausibleDeep2019,
  title = {Biologically Plausible Deep Learning — {{But}} How Far Can We Go with Shallow Networks?},
  author = {Illing, Bernd and Gerstner, Wulfram and Brea, Johanni},
  date = {2019-10-01},
  journaltitle = {Neural Networks},
  shortjournal = {Neural Networks},
  volume = {118},
  pages = {90--101},
  issn = {0893-6080},
  doi = {10.1016/j.neunet.2019.06.001},
  url = {https://www.sciencedirect.com/science/article/pii/S0893608019301741},
  urldate = {2022-04-19},
  abstract = {Training deep neural networks with the error backpropagation algorithm is considered implausible from a biological perspective. Numerous recent publications suggest elaborate models for biologically plausible variants of deep learning, typically defining success as reaching around 98\% test accuracy on the MNIST data set. Here, we investigate how far we can go on digit (MNIST) and object (CIFAR10) classification with biologically plausible, local learning rules in a network with one hidden layer and a single readout layer. The hidden layer weights are either fixed (random or random Gabor filters) or trained with unsupervised methods (Principal/Independent Component Analysis or Sparse Coding) that can be implemented by local learning rules. The readout layer is trained with a supervised, local learning rule. We first implement these models with rate neurons. This comparison reveals, first, that unsupervised learning does not lead to better performance than fixed random projections or Gabor filters for large hidden layers. Second, networks with localized receptive fields perform significantly better than networks with all-to-all connectivity and can reach backpropagation performance on MNIST. We then implement two of the networks – fixed, localized, random \& random Gabor filters in the hidden layer – with spiking leaky integrate-and-fire neurons and spike timing dependent plasticity to train the readout layer. These spiking models achieve {$>$}98.2\% test accuracy on MNIST, which is close to the performance of rate networks with one hidden layer trained with backpropagation. The performance of our shallow network models is comparable to most current biologically plausible models of deep learning. Furthermore, our results with a shallow spiking network provide an important reference and suggest the use of data sets other than MNIST for testing the performance of future models of biologically plausible deep learning.},
  langid = {english},
  keywords = {Deep learning,Local learning rules,MNIST,Random projections,Spiking networks,Unsupervised feature learning},
  file = {/Users/marcel/Zotero/storage/NN98A8JI/Illing et al. - 2019 - Biologically plausible deep learning — But how far.pdf}
}

@misc{IMM2012-03274,
  title = {The Matrix Cookbook},
  author = {Petersen, K. B. and Pedersen, M. S.},
  date = {2012-11},
  url = {http://www2.compute.dtu.dk/pubdb/pubs/3274-full.html},
  abstract = {Matrix identities, relations and approximations. A desktop reference for quick overview of mathematics of matrices.},
  organization = {Technical University of Denmark},
  keywords = {inverse,matrix derivative,Matrix identity,matrix relations}
}

@software{jax2018github,
  title = {{{JAX}}: Composable Transformations of {{Python}}+{{NumPy}} Programs},
  author = {Bradbury, James and Frostig, Roy and Hawkins, Peter and Johnson, Matthew James and Leary, Chris and Maclaurin, Dougal and Necula, George and Paszke, Adam and VanderPlas, Jake and Wanderman-Milne, Skye and Zhang, Qiao},
  date = {2018},
  url = {http://github.com/google/jax},
  version = {0.2.5}
}

@online{JaxLaxScatter,
  title = {Jax.Lax.Scatter — {{JAX}} Documentation},
  url = {https://jax.readthedocs.io/en/latest/_autosummary/jax.lax.scatter.html},
  urldate = {2022-09-23},
  file = {/Users/marcel/Zotero/storage/IQ522L6U/jax.lax.scatter.html}
}

@unpublished{jennerSteerablePartialDifferential2021,
  title = {Steerable {{Partial Differential Operators}} for {{Equivariant Neural Networks}}},
  author = {Jenner, Erik and Weiler, Maurice},
  date = {2021-06-18},
  eprint = {2106.10163},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2106.10163},
  urldate = {2021-07-30},
  abstract = {Recent work in equivariant deep learning bears strong similarities to physics. Fields over a base space are fundamental entities in both subjects, as are equivariant maps between these fields. In deep learning, however, these maps are usually defined by convolutions with a kernel, whereas they are partial differential operators (PDOs) in physics. Developing the theory of equivariant PDOs in the context of deep learning could bring these subjects even closer together and lead to a stronger flow of ideas. In this work, we derive a \$G\$-steerability constraint that completely characterizes when a PDO between feature vector fields is equivariant, for arbitrary symmetry groups \$G\$. We then fully solve this constraint for several important groups. We use our solutions as equivariant drop-in replacements for convolutional layers and benchmark them in that role. Finally, we develop a framework for equivariant maps based on Schwartz distributions that unifies classical convolutions and differential operators and gives insight about the relation between the two.},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning},
  file = {/Users/marcel/Zotero/storage/T8IMR2EM/Jenner_Weiler_2021_Steerable Partial Differential Operators for Equivariant Neural Networks.pdf;/Users/marcel/Zotero/storage/RUCQG2MB/2106.html}
}

@online{jiaDissectingGraphcoreIPU2019,
  title = {Dissecting the {{Graphcore IPU Architecture}} via {{Microbenchmarking}}},
  author = {Jia, Zhe and Tillman, Blake and Maggioni, Marco and Scarpazza, Daniele Paolo},
  date = {2019-12-06},
  eprint = {1912.03413},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.1912.03413},
  url = {http://arxiv.org/abs/1912.03413},
  urldate = {2022-12-12},
  abstract = {This report focuses on the architecture and performance of the Intelligence Processing Unit (IPU), a novel, massively parallel platform recently introduced by Graphcore and aimed at Artificial Intelligence/Machine Learning (AI/ML) workloads. We dissect the IPU's performance behavior using microbenchmarks that we crafted for the purpose. We study the IPU's memory organization and performance. We study the latency and bandwidth that the on-chip and off-chip interconnects offer, both in point-to-point transfers and in a spectrum of collective operations, under diverse loads. We evaluate the IPU's compute power over matrix multiplication, convolution, and AI/ML primitives. We discuss actual performance in comparison with its theoretical limits. Our findings reveal how the IPU's architectural design affects its performance. Moreover, they offer simple mental models to predict an application's performance on the IPU, on the basis of the computation and communication steps it involves. This report is the natural extension to a novel architecture of a continuing effort of ours that focuses on the microbenchmark-based discovery of massively parallel architectures.},
  pubstate = {prepublished},
  keywords = {Computer Science - Distributed Parallel and Cluster Computing,Computer Science - Hardware Architecture,Computer Science - Performance},
  file = {/Users/marcel/Zotero/storage/CVCIGQKL/Jia et al. - 2019 - Dissecting the Graphcore IPU Architecture via Micr.pdf;/Users/marcel/Zotero/storage/HJ3K7IAL/1912.html}
}

@online{jiangMistral7B2023,
  title = {Mistral {{7B}}},
  author = {Jiang, Albert Q. and Sablayrolles, Alexandre and Mensch, Arthur and Bamford, Chris and Chaplot, Devendra Singh and family=Casas, given=Diego, prefix=de las, useprefix=false and Bressand, Florian and Lengyel, Gianna and Lample, Guillaume and Saulnier, Lucile and Lavaud, Lélio Renard and Lachaux, Marie-Anne and Stock, Pierre and Scao, Teven Le and Lavril, Thibaut and Wang, Thomas and Lacroix, Timothée and Sayed, William El},
  date = {2023-10-10},
  eprint = {2310.06825},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2310.06825},
  url = {http://arxiv.org/abs/2310.06825},
  urldate = {2024-02-13},
  abstract = {We introduce Mistral 7B v0.1, a 7-billion-parameter language model engineered for superior performance and efficiency. Mistral 7B outperforms Llama 2 13B across all evaluated benchmarks, and Llama 1 34B in reasoning, mathematics, and code generation. Our model leverages grouped-query attention (GQA) for faster inference, coupled with sliding window attention (SWA) to effectively handle sequences of arbitrary length with a reduced inference cost. We also provide a model fine-tuned to follow instructions, Mistral 7B -- Instruct, that surpasses the Llama 2 13B -- Chat model both on human and automated benchmarks. Our models are released under the Apache 2.0 license.},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Machine Learning},
  file = {/Users/marcel/Zotero/storage/QHJS6Y5A/Jiang et al. - 2023 - Mistral 7B.pdf;/Users/marcel/Zotero/storage/9Q559ZLU/2310.html}
}

@online{jiangMixtralExperts2024,
  title = {Mixtral of {{Experts}}},
  author = {Jiang, Albert Q. and Sablayrolles, Alexandre and Roux, Antoine and Mensch, Arthur and Savary, Blanche and Bamford, Chris and Chaplot, Devendra Singh and family=Casas, given=Diego, prefix=de las, useprefix=false and Hanna, Emma Bou and Bressand, Florian and Lengyel, Gianna and Bour, Guillaume and Lample, Guillaume and Lavaud, Lélio Renard and Saulnier, Lucile and Lachaux, Marie-Anne and Stock, Pierre and Subramanian, Sandeep and Yang, Sophia and Antoniak, Szymon and Scao, Teven Le and Gervet, Théophile and Lavril, Thibaut and Wang, Thomas and Lacroix, Timothée and Sayed, William El},
  date = {2024-01-08},
  eprint = {2401.04088},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2401.04088},
  url = {http://arxiv.org/abs/2401.04088},
  urldate = {2024-02-14},
  abstract = {We introduce Mixtral 8x7B, a Sparse Mixture of Experts (SMoE) language model. Mixtral has the same architecture as Mistral 7B, with the difference that each layer is composed of 8 feedforward blocks (i.e. experts). For every token, at each layer, a router network selects two experts to process the current state and combine their outputs. Even though each token only sees two experts, the selected experts can be different at each timestep. As a result, each token has access to 47B parameters, but only uses 13B active parameters during inference. Mixtral was trained with a context size of 32k tokens and it outperforms or matches Llama 2 70B and GPT-3.5 across all evaluated benchmarks. In particular, Mixtral vastly outperforms Llama 2 70B on mathematics, code generation, and multilingual benchmarks. We also provide a model fine-tuned to follow instructions, Mixtral 8x7B - Instruct, that surpasses GPT-3.5 Turbo, Claude-2.1, Gemini Pro, and Llama 2 70B - chat model on human benchmarks. Both the base and instruct models are released under the Apache 2.0 license.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computation and Language,Computer Science - Machine Learning},
  file = {/Users/marcel/Zotero/storage/5XRZY5KU/Jiang et al. - 2024 - Mixtral of Experts.pdf;/Users/marcel/Zotero/storage/XGG42KSF/2401.html}
}

@incollection{jinKMeansClustering2010,
  title = {K-{{Means Clustering}}},
  booktitle = {Encyclopedia of {{Machine Learning}}},
  author = {Jin, Xin and Han, Jiawei},
  editor = {Sammut, Claude and Webb, Geoffrey I.},
  date = {2010},
  pages = {563--564},
  publisher = {Springer US},
  location = {Boston, MA},
  doi = {10.1007/978-0-387-30164-8_425},
  url = {https://doi.org/10.1007/978-0-387-30164-8_425},
  urldate = {2023-02-28},
  isbn = {978-0-387-30164-8},
  langid = {english},
  file = {/Users/marcel/Zotero/storage/KH7NMZED/Jin and Han - 2010 - K-Means Clustering.pdf}
}

@online{jouppiInDatacenterPerformanceAnalysis2017,
  title = {In-{{Datacenter Performance Analysis}} of a {{Tensor Processing Unit}}},
  author = {Jouppi, Norman P. and Young, Cliff and Patil, Nishant and Patterson, David and Agrawal, Gaurav and Bajwa, Raminder and Bates, Sarah and Bhatia, Suresh and Boden, Nan and Borchers, Al and Boyle, Rick and Cantin, Pierre-luc and Chao, Clifford and Clark, Chris and Coriell, Jeremy and Daley, Mike and Dau, Matt and Dean, Jeffrey and Gelb, Ben and Ghaemmaghami, Tara Vazir and Gottipati, Rajendra and Gulland, William and Hagmann, Robert and Ho, C. Richard and Hogberg, Doug and Hu, John and Hundt, Robert and Hurt, Dan and Ibarz, Julian and Jaffey, Aaron and Jaworski, Alek and Kaplan, Alexander and Khaitan, Harshit and Koch, Andy and Kumar, Naveen and Lacy, Steve and Laudon, James and Law, James and Le, Diemthu and Leary, Chris and Liu, Zhuyuan and Lucke, Kyle and Lundin, Alan and MacKean, Gordon and Maggiore, Adriana and Mahony, Maire and Miller, Kieran and Nagarajan, Rahul and Narayanaswami, Ravi and Ni, Ray and Nix, Kathy and Norrie, Thomas and Omernick, Mark and Penukonda, Narayana and Phelps, Andy and Ross, Jonathan and Ross, Matt and Salek, Amir and Samadiani, Emad and Severn, Chris and Sizikov, Gregory and Snelham, Matthew and Souter, Jed and Steinberg, Dan and Swing, Andy and Tan, Mercedes and Thorson, Gregory and Tian, Bo and Toma, Horia and Tuttle, Erick and Vasudevan, Vijay and Walter, Richard and Wang, Walter and Wilcox, Eric and Yoon, Doe Hyun},
  date = {2017-04-16},
  eprint = {1704.04760},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.1704.04760},
  url = {http://arxiv.org/abs/1704.04760},
  urldate = {2023-11-11},
  abstract = {Many architects believe that major improvements in cost-energy-performance must now come from domain-specific hardware. This paper evaluates a custom ASIC---called a Tensor Processing Unit (TPU)---deployed in datacenters since 2015 that accelerates the inference phase of neural networks (NN). The heart of the TPU is a 65,536 8-bit MAC matrix multiply unit that offers a peak throughput of 92 TeraOps/second (TOPS) and a large (28 MiB) software-managed on-chip memory. The TPU's deterministic execution model is a better match to the 99th-percentile response-time requirement of our NN applications than are the time-varying optimizations of CPUs and GPUs (caches, out-of-order execution, multithreading, multiprocessing, prefetching, ...) that help average throughput more than guaranteed latency. The lack of such features helps explain why, despite having myriad MACs and a big memory, the TPU is relatively small and low power. We compare the TPU to a server-class Intel Haswell CPU and an Nvidia K80 GPU, which are contemporaries deployed in the same datacenters. Our workload, written in the high-level TensorFlow framework, uses production NN applications (MLPs, CNNs, and LSTMs) that represent 95\% of our datacenters' NN inference demand. Despite low utilization for some applications, the TPU is on average about 15X - 30X faster than its contemporary GPU or CPU, with TOPS/Watt about 30X - 80X higher. Moreover, using the GPU's GDDR5 memory in the TPU would triple achieved TOPS and raise TOPS/Watt to nearly 70X the GPU and 200X the CPU.},
  pubstate = {prepublished},
  keywords = {Computer Science - Hardware Architecture,Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing},
  file = {/Users/marcel/Zotero/storage/4GTDF975/Jouppi et al. - 2017 - In-Datacenter Performance Analysis of a Tensor Processing Unit.pdf;/Users/marcel/Zotero/storage/C6BLDGDP/1704.html}
}

@online{kalamkarStudyBFLOAT16Deep2019,
  title = {A {{Study}} of {{BFLOAT16}} for {{Deep Learning Training}}},
  author = {Kalamkar, Dhiraj and Mudigere, Dheevatsa and Mellempudi, Naveen and Das, Dipankar and Banerjee, Kunal and Avancha, Sasikanth and Vooturi, Dharma Teja and Jammalamadaka, Nataraj and Huang, Jianyu and Yuen, Hector and Yang, Jiyan and Park, Jongsoo and Heinecke, Alexander and Georganas, Evangelos and Srinivasan, Sudarshan and Kundu, Abhisek and Smelyanskiy, Misha and Kaul, Bharat and Dubey, Pradeep},
  date = {2019-06-13},
  eprint = {1905.12322},
  eprinttype = {arXiv},
  eprintclass = {cs, stat},
  doi = {10.48550/arXiv.1905.12322},
  url = {http://arxiv.org/abs/1905.12322},
  urldate = {2024-03-16},
  abstract = {This paper presents the first comprehensive empirical study demonstrating the efficacy of the Brain Floating Point (BFLOAT16) half-precision format for Deep Learning training across image classification, speech recognition, language modeling, generative networks and industrial recommendation systems. BFLOAT16 is attractive for Deep Learning training for two reasons: the range of values it can represent is the same as that of IEEE 754 floating-point format (FP32) and conversion to/from FP32 is simple. Maintaining the same range as FP32 is important to ensure that no hyper-parameter tuning is required for convergence; e.g., IEEE 754 compliant half-precision floating point (FP16) requires hyper-parameter tuning. In this paper, we discuss the flow of tensors and various key operations in mixed precision training, and delve into details of operations, such as the rounding modes for converting FP32 tensors to BFLOAT16. We have implemented a method to emulate BFLOAT16 operations in Tensorflow, Caffe2, IntelCaffe, and Neon for our experiments. Our results show that deep learning training using BFLOAT16 tensors achieves the same state-of-the-art (SOTA) results across domains as FP32 tensors in the same number of iterations and with no changes to hyper-parameters.},
  pubstate = {prepublished},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/marcel/Zotero/storage/NJ7RNTS8/Kalamkar et al. - 2019 - A Study of BFLOAT16 for Deep Learning Training.pdf;/Users/marcel/Zotero/storage/23INBVVN/1905.html}
}

@online{kaplanScalingLawsNeural2020,
  title = {Scaling {{Laws}} for {{Neural Language Models}}},
  author = {Kaplan, Jared and McCandlish, Sam and Henighan, Tom and Brown, Tom B. and Chess, Benjamin and Child, Rewon and Gray, Scott and Radford, Alec and Wu, Jeffrey and Amodei, Dario},
  date = {2020-01-22},
  eprint = {2001.08361},
  eprinttype = {arXiv},
  eprintclass = {cs, stat},
  url = {http://arxiv.org/abs/2001.08361},
  urldate = {2024-05-08},
  abstract = {We study empirical scaling laws for language model performance on the cross-entropy loss. The loss scales as a power-law with model size, dataset size, and the amount of compute used for training, with some trends spanning more than seven orders of magnitude. Other architectural details such as network width or depth have minimal effects within a wide range. Simple equations govern the dependence of overfitting on model/dataset size and the dependence of training speed on model size. These relationships allow us to determine the optimal allocation of a fixed compute budget. Larger models are significantly more sample-efficient, such that optimally compute-efficient training involves training very large models on a relatively modest amount of data and stopping significantly before convergence.},
  pubstate = {prepublished},
  file = {/Users/marcel/Zotero/storage/35KWY5VE/Kaplan et al. - 2020 - Scaling Laws for Neural Language Models.pdf}
}

@article{kazanskiyOpticalComputingStatus2022,
  title = {Optical {{Computing}}: {{Status}} and {{Perspectives}}},
  shorttitle = {Optical {{Computing}}},
  author = {Kazanskiy, Nikolay L. and Butt, Muhammad A. and Khonina, Svetlana N.},
  date = {2022-06-24},
  journaltitle = {Nanomaterials},
  shortjournal = {Nanomaterials (Basel)},
  volume = {12},
  number = {13},
  eprint = {35808012},
  eprinttype = {pmid},
  pages = {2171},
  issn = {2079-4991},
  doi = {10.3390/nano12132171},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9267976/},
  urldate = {2023-10-17},
  abstract = {For many years, optics has been employed in computing, although the major focus has been and remains to be on connecting parts of computers, for communications, or more fundamentally in systems that have some optical function or element (optical pattern recognition, etc.). Optical digital computers are still evolving; however, a variety of components that can eventually lead to true optical computers, such as optical logic gates, optical switches, neural networks, and spatial light modulators have previously been developed and are discussed in this paper. High-performance off-the-shelf computers can accurately simulate and construct more complicated photonic devices and systems. These advancements have developed under unusual circumstances: photonics is an emerging tool for the next generation of computing hardware, while recent advances in digital computers have empowered the design, modeling, and creation of a new class of photonic devices and systems with unparalleled challenges. Thus, the review of the status and perspectives shows that optical technology offers incredible developments in computational efficiency; however, only separately implemented optical operations are known so far, and the launch of the world’s first commercial optical processing system was only recently announced. Most likely, the optical computer has not been put into mass production because there are still no good solutions for optical transistors, optical memory, and much more that acceptance to break the huge inertia of many proven technologies in electronics.},
  pmcid = {PMC9267976},
  file = {/Users/marcel/Zotero/storage/Q6N6APKP/Kazanskiy et al. - 2022 - Optical Computing Status and Perspectives.pdf}
}

@article{kidger2021equinox,
  title = {Equinox: Neural Networks in {{JAX}} via Callable {{PyTrees}} and Filtered Transformations},
  author = {Kidger, Patrick and Garcia, Cristian},
  date = {2021},
  journaltitle = {Differentiable Programming workshop at Neural Information Processing Systems 2021}
}

@unpublished{kidgerNeuralDifferentialEquations2022,
  title = {On {{Neural Differential Equations}}},
  author = {Kidger, Patrick},
  date = {2022-02-04},
  eprint = {2202.02435},
  eprinttype = {arXiv},
  eprintclass = {cs, math, stat},
  url = {http://arxiv.org/abs/2202.02435},
  urldate = {2022-03-31},
  abstract = {The conjoining of dynamical systems and deep learning has become a topic of great interest. In particular, neural differential equations (NDEs) demonstrate that neural networks and differential equation are two sides of the same coin. Traditional parameterised differential equations are a special case. Many popular neural network architectures, such as residual networks and recurrent networks, are discretisations. NDEs are suitable for tackling generative problems, dynamical systems, and time series (particularly in physics, finance, ...) and are thus of interest to both modern machine learning and traditional mathematical modelling. NDEs offer high-capacity function approximation, strong priors on model space, the ability to handle irregular data, memory efficiency, and a wealth of available theory on both sides. This doctoral thesis provides an in-depth survey of the field. Topics include: neural ordinary differential equations (e.g. for hybrid neural/mechanistic modelling of physical systems); neural controlled differential equations (e.g. for learning functions of irregular time series); and neural stochastic differential equations (e.g. to produce generative models capable of representing complex stochastic dynamics, or sampling from complex high-dimensional distributions). Further topics include: numerical methods for NDEs (e.g. reversible differential equations solvers, backpropagation through differential equations, Brownian reconstruction); symbolic regression for dynamical systems (e.g. via regularised evolution); and deep implicit models (e.g. deep equilibrium models, differentiable optimisation). We anticipate this thesis will be of interest to anyone interested in the marriage of deep learning with dynamical systems, and hope it will provide a useful reference for the current state of the art.},
  keywords = {Computer Science - Machine Learning,Mathematics - Classical Analysis and ODEs,Mathematics - Dynamical Systems,Mathematics - Numerical Analysis,Statistics - Machine Learning},
  file = {/Users/marcel/Zotero/storage/5VANUP73/Kidger - 2022 - On Neural Differential Equations.pdf;/Users/marcel/Zotero/storage/TIV7GPSA/2202.html}
}

@article{kimVisualExplanationsSpiking2021,
  title = {Visual Explanations from Spiking Neural Networks Using Inter-Spike Intervals},
  author = {Kim, Youngeun and Panda, Priyadarshini},
  date = {2021-09-24},
  journaltitle = {Scientific Reports},
  shortjournal = {Sci Rep},
  volume = {11},
  number = {1},
  pages = {19037},
  publisher = {Nature Publishing Group},
  issn = {2045-2322},
  doi = {10.1038/s41598-021-98448-0},
  url = {https://www.nature.com/articles/s41598-021-98448-0},
  urldate = {2022-05-02},
  abstract = {By emulating biological features in brain, Spiking Neural Networks (SNNs) offer an energy-efficient alternative to conventional deep learning. To make SNNs ubiquitous, a ‘visual explanation’ technique for analysing and explaining the internal spike behavior of such temporal deep SNNs is crucial. Explaining SNNs visually will make the network more transparent giving the end-user a tool to understand how SNNs make temporal predictions and why they make a certain decision. In this paper, we propose a bio-plausible visual explanation tool for SNNs, called Spike Activation Map (SAM). SAM yields a heatmap (i.e., localization map) corresponding to each time-step of input data by highlighting neurons with short inter-spike interval activity. Interestingly, without the use of gradients and ground truth, SAM produces a temporal localization map highlighting the region of interest in an image attributed to an SNN’s prediction at each time-step. Overall, SAM outsets the beginning of a new research area ‘explainable neuromorphic computing’ that will ultimately allow end-users to establish appropriate trust in predictions from SNNs.},
  issue = {1},
  langid = {english},
  keywords = {Computational neuroscience,Electrical and electronic engineering,Visual system},
  file = {/Users/marcel/Zotero/storage/I6UXW6C8/Kim and Panda - 2021 - Visual explanations from spiking neural networks u.pdf;/Users/marcel/Zotero/storage/IBDW4J2C/s41598-021-98448-0.html}
}

@unpublished{kingmaAdamMethodStochastic2017,
  title = {Adam: {{A Method}} for {{Stochastic Optimization}}},
  shorttitle = {Adam},
  author = {Kingma, Diederik P. and Ba, Jimmy},
  date = {2017-01-29},
  eprint = {1412.6980},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/1412.6980},
  urldate = {2022-04-28},
  abstract = {We introduce Adam, an algorithm for first-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order moments. The method is straightforward to implement, is computationally efficient, has little memory requirements, is invariant to diagonal rescaling of the gradients, and is well suited for problems that are large in terms of data and/or parameters. The method is also appropriate for non-stationary objectives and problems with very noisy and/or sparse gradients. The hyper-parameters have intuitive interpretations and typically require little tuning. Some connections to related algorithms, on which Adam was inspired, are discussed. We also analyze the theoretical convergence properties of the algorithm and provide a regret bound on the convergence rate that is comparable to the best known results under the online convex optimization framework. Empirical results demonstrate that Adam works well in practice and compares favorably to other stochastic optimization methods. Finally, we discuss AdaMax, a variant of Adam based on the infinity norm.},
  keywords = {Computer Science - Machine Learning},
  file = {/Users/marcel/Zotero/storage/ER5IRCM4/Kingma and Ba - 2017 - Adam A Method for Stochastic Optimization.pdf;/Users/marcel/Zotero/storage/34E5ZICM/1412.html}
}

@unpublished{kingmaGlowGenerativeFlow2018,
  title = {Glow: {{Generative Flow}} with {{Invertible}} 1x1 {{Convolutions}}},
  shorttitle = {Glow},
  author = {Kingma, Diederik P. and Dhariwal, Prafulla},
  date = {2018-07-10},
  eprint = {1807.03039},
  eprinttype = {arXiv},
  eprintclass = {cs, stat},
  url = {http://arxiv.org/abs/1807.03039},
  urldate = {2021-07-27},
  abstract = {Flow-based generative models (Dinh et al., 2014) are conceptually attractive due to tractability of the exact log-likelihood, tractability of exact latent-variable inference, and parallelizability of both training and synthesis. In this paper we propose Glow, a simple type of generative flow using an invertible 1x1 convolution. Using our method we demonstrate a significant improvement in log-likelihood on standard benchmarks. Perhaps most strikingly, we demonstrate that a generative model optimized towards the plain log-likelihood objective is capable of efficient realistic-looking synthesis and manipulation of large images. The code for our model is available at https://github.com/openai/glow},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/marcel/Zotero/storage/SE6H8TVJ/Kingma_Dhariwal_2018_Glow.pdf;/Users/marcel/Zotero/storage/DMGVNZCE/1807.html}
}

@online{kipfSemiSupervisedClassificationGraph2017,
  title = {Semi-{{Supervised Classification}} with {{Graph Convolutional Networks}}},
  author = {Kipf, Thomas N. and Welling, Max},
  date = {2017-02-22},
  eprint = {1609.02907},
  eprinttype = {arXiv},
  eprintclass = {cs, stat},
  doi = {10.48550/arXiv.1609.02907},
  url = {http://arxiv.org/abs/1609.02907},
  urldate = {2024-02-14},
  abstract = {We present a scalable approach for semi-supervised learning on graph-structured data that is based on an efficient variant of convolutional neural networks which operate directly on graphs. We motivate the choice of our convolutional architecture via a localized first-order approximation of spectral graph convolutions. Our model scales linearly in the number of graph edges and learns hidden layer representations that encode both local graph structure and features of nodes. In a number of experiments on citation networks and on a knowledge graph dataset we demonstrate that our approach outperforms related methods by a significant margin.},
  pubstate = {prepublished},
  version = {4},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/marcel/Zotero/storage/PRXI82VL/Kipf and Welling - 2017 - Semi-Supervised Classification with Graph Convolutional Networks.pdf;/Users/marcel/Zotero/storage/5K7VJG4D/1609.html}
}

@incollection{kiselyovTypedTaglessFinal2012,
  title = {Typed {{Tagless Final Interpreters}}},
  booktitle = {Generic and {{Indexed Programming}}: {{International Spring School}}, {{SSGIP}} 2010, {{Oxford}}, {{UK}}, {{March}} 22-26, 2010, {{Revised Lectures}}},
  author = {Kiselyov, Oleg},
  editor = {Gibbons, Jeremy},
  date = {2012},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {130--174},
  publisher = {Springer},
  location = {Berlin, Heidelberg},
  doi = {10.1007/978-3-642-32202-0_3},
  url = {https://doi.org/10.1007/978-3-642-32202-0_3},
  urldate = {2023-05-15},
  abstract = {The so-called ‘typed tagless final’ approach of [6] has collected and polished a number of techniques for representing typed higher-order languages in a typed metalanguage, along with type-preserving interpretation, compilation and partial evaluation. The approach is an alternative to the traditional, or ‘initial’ encoding of an object language as a (generalized) algebraic data type. Both approaches permit multiple interpretations of an expression, to evaluate it, pretty-print, etc. The final encoding represents all and only typed object terms without resorting to generalized algebraic data types, dependent or other fancy types. The final encoding lets us add new language forms and interpretations without breaking the existing terms and interpreters.},
  isbn = {978-3-642-32202-0},
  langid = {english},
  keywords = {Denotational Semantic,Expression Problem,Object Term,Sample Term,Type Checker},
  file = {/Users/marcel/Zotero/storage/64FEWVMP/Kiselyov - 2012 - Typed Tagless Final Interpreters.pdf}
}

@article{kobyzevNormalizingFlowsIntroduction2020,
  title = {Normalizing {{Flows}}: {{An Introduction}} and {{Review}} of {{Current Methods}}},
  shorttitle = {Normalizing {{Flows}}},
  author = {Kobyzev, Ivan and Prince, Simon J. D. and Brubaker, Marcus A.},
  date = {2020},
  journaltitle = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  shortjournal = {IEEE Trans. Pattern Anal. Mach. Intell.},
  eprint = {1908.09257},
  eprinttype = {arXiv},
  pages = {1--1},
  issn = {0162-8828, 2160-9292, 1939-3539},
  doi = {10.1109/TPAMI.2020.2992934},
  url = {http://arxiv.org/abs/1908.09257},
  urldate = {2021-07-27},
  abstract = {Normalizing Flows are generative models which produce tractable distributions where both sampling and density evaluation can be efficient and exact. The goal of this survey article is to give a coherent and comprehensive review of the literature around the construction and use of Normalizing Flows for distribution learning. We aim to provide context and explanation of the models, review current state-of-the-art literature, and identify open questions and promising future directions.},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/marcel/Zotero/storage/G8BAB6TM/Kobyzev et al_2020_Normalizing Flows.pdf;/Users/marcel/Zotero/storage/93628RDS/1908.html}
}

@unpublished{kohlerEquivariantFlowsExact2020,
  title = {Equivariant {{Flows}}: {{Exact Likelihood Generative Learning}} for {{Symmetric Densities}}},
  shorttitle = {Equivariant {{Flows}}},
  author = {Köhler, Jonas and Klein, Leon and Noé, Frank},
  date = {2020-10-26},
  eprint = {2006.02425},
  eprinttype = {arXiv},
  eprintclass = {physics, stat},
  url = {http://arxiv.org/abs/2006.02425},
  urldate = {2021-07-27},
  abstract = {Normalizing flows are exact-likelihood generative neural networks which approximately transform samples from a simple prior distribution to samples of the probability distribution of interest. Recent work showed that such generative models can be utilized in statistical mechanics to sample equilibrium states of many-body systems in physics and chemistry. To scale and generalize these results, it is essential that the natural symmetries in the probability density -- in physics defined by the invariances of the target potential -- are built into the flow. We provide a theoretical sufficient criterion showing that the distribution generated by \textbackslash textit\{equivariant\} normalizing flows is invariant with respect to these symmetries by design. Furthermore, we propose building blocks for flows which preserve symmetries which are usually found in physical/chemical many-body particle systems. Using benchmark systems motivated from molecular physics, we demonstrate that those symmetry preserving flows can provide better generalization capabilities and sampling efficiency.},
  keywords = {Computer Science - Machine Learning,Physics - Chemical Physics,Physics - Computational Physics,Statistics - Machine Learning},
  file = {/Users/marcel/Zotero/storage/VP3GL86X/Köhler et al_2020_Equivariant Flows.pdf;/Users/marcel/Zotero/storage/CHRE346C/2006.html}
}

@unpublished{kondorClebschGordanNetsFully2018,
  title = {Clebsch-{{Gordan Nets}}: A {{Fully Fourier Space Spherical Convolutional Neural Network}}},
  shorttitle = {Clebsch-{{Gordan Nets}}},
  author = {Kondor, Risi and Lin, Zhen and Trivedi, Shubhendu},
  date = {2018-11-10},
  eprint = {1806.09231},
  eprinttype = {arXiv},
  eprintclass = {cs, stat},
  url = {http://arxiv.org/abs/1806.09231},
  urldate = {2021-08-27},
  abstract = {Recent work by Cohen \textbackslash emph\{et al.\} has achieved state-of-the-art results for learning spherical images in a rotation invariant way by using ideas from group representation theory and noncommutative harmonic analysis. In this paper we propose a generalization of this work that generally exhibits improved performace, but from an implementation point of view is actually simpler. An unusual feature of the proposed architecture is that it uses the Clebsch--Gordan transform as its only source of nonlinearity, thus avoiding repeated forward and backward Fourier transforms. The underlying ideas of the paper generalize to constructing neural networks that are invariant to the action of other compact groups.},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/marcel/Zotero/storage/VBDXVEN8/Kondor et al_2018_Clebsch-Gordan Nets.pdf;/Users/marcel/Zotero/storage/WQEZITRD/1806.html}
}

@book{kreyszig11,
  title = {Advanced {{Engineering Mathematics}}},
  author = {Kreyszig, Erwin and Kreyszig, Herbert and Norminton, E. J.},
  date = {2011},
  edition = {10},
  publisher = {Wiley},
  location = {Hoboken, NJ},
  added-at = {2013-10-26T22:02:25.000+0200},
  interhash = {a1e83de970337b5df32d1c35012c6ed4},
  intrahash = {0a73312b197dea61885c5f118343ad72},
  isbn = {0-470-45836-4},
  keywords = {cramer engineering kreyszig linear.algebra math matrix textbook},
  timestamp = {2016-04-08T13:41:19.000+0200},
  file = {/Users/marcel/Zotero/storage/939RSE5A/advanced_engineering_mathematics.pdf}
}

@inproceedings{krizhevskyImageNetClassificationDeep2012,
  title = {{{ImageNet Classification}} with {{Deep Convolutional Neural Networks}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
  date = {2012},
  volume = {25},
  publisher = {Curran Associates, Inc.},
  url = {https://proceedings.neurips.cc/paper_files/paper/2012/hash/c399862d3b9d6b76c8436e924a68c45b-Abstract.html},
  urldate = {2023-05-09},
  abstract = {We trained a large, deep convolutional neural network to classify the 1.3 million high-resolution images in the LSVRC-2010 ImageNet training set into the 1000 different classes. On the test data, we achieved top-1 and top-5 error rates of 39.7\textbackslash\% and 18.9\textbackslash\% which is considerably better than the previous state-of-the-art results. The neural network, which has 60 million parameters and 500,000 neurons, consists of five convolutional layers, some of which are followed by max-pooling layers, and two globally connected layers with a final 1000-way softmax. To make training faster, we used non-saturating neurons and a very efficient GPU implementation of convolutional nets. To reduce overfitting in the globally connected layers we employed a new regularization method that proved to be very effective.},
  file = {/Users/marcel/Zotero/storage/FDUWTVNI/Krizhevsky et al. - 2012 - ImageNet Classification with Deep Convolutional Ne.pdf}
}

@article{krotovUnsupervisedLearningCompeting2019,
  title = {Unsupervised Learning by Competing Hidden Units},
  author = {Krotov, Dmitry and Hopfield, John J.},
  date = {2019-04-16},
  journaltitle = {Proceedings of the National Academy of Sciences},
  shortjournal = {Proc. Natl. Acad. Sci. U.S.A.},
  volume = {116},
  number = {16},
  pages = {7723--7731},
  issn = {0027-8424, 1091-6490},
  doi = {10.1073/pnas.1820458116},
  url = {https://pnas.org/doi/full/10.1073/pnas.1820458116},
  urldate = {2022-05-01},
  abstract = {Significance             Despite great success of deep learning a question remains to what extent the computational properties of deep neural networks are similar to those of the human brain. The particularly nonbiological aspect of deep learning is the supervised training process with the backpropagation algorithm, which requires massive amounts of labeled data, and a nonlocal learning rule for changing the synapse strengths. This paper describes a learning algorithm that does not suffer from these two problems. It learns the weights of the lower layer of neural networks in a completely unsupervised fashion. The entire algorithm utilizes local learning rules which have conceptual biological plausibility.           ,              It is widely believed that end-to-end training with the backpropagation algorithm is essential for learning good feature detectors in early layers of artificial neural networks, so that these detectors are useful for the task performed by the higher layers of that neural network. At the same time, the traditional form of backpropagation is biologically implausible. In the present paper we propose an unusual learning rule, which has a degree of biological plausibility and which is motivated by Hebb’s idea that change of the synapse strength should be local—i.e., should depend only on the activities of the pre- and postsynaptic neurons. We design a learning algorithm that utilizes global inhibition in the hidden layer and is capable of learning early feature detectors in a completely unsupervised way. These learned lower-layer feature detectors can be used to train higher-layer weights in a usual supervised way so that the performance of the full network is comparable to the performance of standard feedforward networks trained end-to-end with a backpropagation algorithm on simple tasks.},
  langid = {english},
  file = {/Users/marcel/Zotero/storage/GEIWKJSW/Krotov and Hopfield - 2019 - Unsupervised learning by competing hidden units.pdf}
}

@online{laiRobustVectorQuantizedVariational2022,
  title = {Robust {{Vector Quantized-Variational Autoencoder}}},
  author = {Lai, Chieh-Hsin and Zou, Dongmian and Lerman, Gilad},
  date = {2022-02-04},
  eprint = {2202.01987},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2202.01987},
  url = {http://arxiv.org/abs/2202.01987},
  urldate = {2022-07-31},
  abstract = {Image generative models can learn the distributions of the training data and consequently generate examples by sampling from these distributions. However, when the training dataset is corrupted with outliers, generative models will likely produce examples that are also similar to the outliers. In fact, a small portion of outliers may induce state-of-the-art generative models, such as Vector Quantized-Variational AutoEncoder (VQ-VAE), to learn a significant mode from the outliers. To mitigate this problem, we propose a robust generative model based on VQ-VAE, which we name Robust VQ-VAE (RVQ-VAE). In order to achieve robustness, RVQ-VAE uses two separate codebooks for the inliers and outliers. To ensure the codebooks embed the correct components, we iteratively update the sets of inliers and outliers during each training epoch. To ensure that the encoded data points are matched to the correct codebooks, we quantize using a weighted Euclidean distance, whose weights are determined by directional variances of the codebooks. Both codebooks, together with the encoder and decoder, are trained jointly according to the reconstruction loss and the quantization loss. We experimentally demonstrate that RVQ-VAE is able to generate examples from inliers even if a large portion of the training data points are corrupted.},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning},
  file = {/Users/marcel/Zotero/storage/AZLANL5P/Lai et al. - 2022 - Robust Vector Quantized-Variational Autoencoder.pdf;/Users/marcel/Zotero/storage/QUCMTDTQ/2202.html}
}

@online{LargeConceptModels,
  title = {Large {{Concept Models}}: {{Language Modeling}} in a {{Sentence Representation Space}}},
  url = {https://ai.meta.com/research/publications/large-concept-models-language-modeling-in-a-sentence-representation-space/},
  urldate = {2024-12-14},
  file = {/Users/marcel/Zotero/storage/ELPHEPQE/470149925_936340665123313_5359535905316748287_n.pdf;/Users/marcel/Zotero/storage/MZBKT84F/large-concept-models-language-modeling-in-a-sentence-representation-space.html}
}

@online{larsonGraphRAGNewApproach2024,
  title = {{{GraphRAG}}: {{A}} New Approach for Discovery Using Complex Information},
  shorttitle = {{{GraphRAG}}},
  author = {Larson, Jonathan and Truitt, Steven},
  date = {2024-02-13T20:00:00+00:00},
  url = {https://www.microsoft.com/en-us/research/blog/graphrag-unlocking-llm-discovery-on-narrative-private-data/},
  urldate = {2024-03-15},
  abstract = {Microsoft is transforming retrieval-augmented generation with GraphRAG, using LLM-generated knowledge graphs to significantly improve Q\&A when analyzing complex information and consistently outperforming baseline RAG. Get the details.},
  langid = {american},
  organization = {Microsoft Research},
  file = {/Users/marcel/Zotero/storage/YC4DETZM/graphrag-unlocking-llm-discovery-on-narrative-private-data.html}
}

@online{lavrijsenCppyyAutomaticPythonC,
  title = {Cppyy: {{Automatic Python-C}}++ Bindings — Cppyy 3.0.0 Documentation},
  author = {Lavrijsen},
  url = {https://cppyy.readthedocs.io/en/latest/index.html},
  urldate = {2024-03-15}
}

@inproceedings{lavrijsenHighPerformancePythonCBindings2016,
  title = {High-{{Performance Python-C}}++ {{Bindings}} with {{PyPy}} and {{Cling}}},
  booktitle = {2016 6th {{Workshop}} on {{Python}} for {{High-Performance}} and {{Scientific Computing}} ({{PyHPC}})},
  author = {Lavrijsen, Wim T.L.P. and Dutta, Aditi},
  date = {2016-11},
  pages = {27--35},
  doi = {10.1109/PyHPC.2016.008},
  url = {https://ieeexplore.ieee.org/document/7836841},
  urldate = {2024-03-15},
  abstract = {The use of Python as a high level productivity language on top of high performance libraries written in C++ requires efficient, highly functional, and easy-to-use cross-language bindings. C++ was standardized in 1998 and up until 2011 it saw only one minor revision. Since then, the pace of revisions has increased considerably, with a lot of improvements made to expressing semantic intent in interface definitions. For automatic Python-C++ bindings generators it is both the worst of times, as parsers need to keep up, and the best of times, as important information such as object ownership and thread safety can now be expressed. We present cppyy, which uses Cling, the Clang/LLVM-based C++ interpreter, to automatically generate Python-C++ bindings for PyPy. Cling provides dynamic access to a modern C++ parser and PyPy brings a full toolbox of dynamic optimizations for high performance. The use of Cling for parsing, provides up-to-date C++ support now and in the foreseeable future. We show that with PyPy the overhead of calls to C++ functions from Python can be reduced by an order of magnitude compared to the equivalent in CPython, making it sufficiently low to be unmeasurable for all but the shortest C++ functions. Similarly, access to data in C++ is reduced by two orders of magnitude over access from CPython. Our approach requires no intermediate language and more pythonistic presentations of the C++ libraries can be written in Python itself, with little performance cost due to inlining by PyPy. This allows for future dynamic optimizations to be fully transparent.},
  eventtitle = {2016 6th {{Workshop}} on {{Python}} for {{High-Performance}} and {{Scientific Computing}} ({{PyHPC}})},
  keywords = {C++ languages,Generators,Libraries,Optimization,Productivity,Semantics,Standards},
  file = {/Users/marcel/Zotero/storage/DLVZXCIG/Lavrijsen and Dutta - 2016 - High-Performance Python-C++ Bindings with PyPy and Cling.pdf;/Users/marcel/Zotero/storage/6WIN8YZL/7836841.html}
}

@article{lberniEfficientButterflyInspired2021,
  title = {Efficient Butterfly Inspired Optimization Algorithm for Analog Circuits Design},
  author = {Lberni, Abdelaziz and Marktani, Malika Alami and Ahaitouf, Abdelaziz and Ahaitouf, Ali},
  date = {2021-07-01},
  journaltitle = {Microelectronics Journal},
  shortjournal = {Microelectronics Journal},
  volume = {113},
  pages = {105078},
  issn = {0026-2692},
  doi = {10.1016/j.mejo.2021.105078},
  url = {https://www.sciencedirect.com/science/article/pii/S0026269221000896},
  urldate = {2023-12-16},
  abstract = {In this paper for the first time a butterfly inspired optimization algorithm, both in single- and multi-objective version is adapted for analog circuit design. As design examples a two-stage amplifier and a current conveyor are respectively used as a voltage and current mode circuits. For the amplifier, the effects of pole-zero compensation on the stabilization performance is first investigated and then, the proposed approach is used for its optimal sizing. Higher dc gain, larger bandwidth and phase margin are then ensured by this way. For the current conveyor, the effect of channel length and bias current on its main performances is considered. The proposed optimization algorithm allows for a high cut-off frequency and small occupation area. Compared to what previously published, the proposed approach provides better figures of merit for both circuits and can be helpful for the optimal sizing of integrated analog circuits, to meet the challenge of automated design in Very-Large-Scale Integration microelectronic domain.},
  keywords = {Automated circuit design,Current conveyor,Multi-objective optimization,Two stage amplifier,Weighted min-max method}
}

@article{lecunGradientbasedLearningApplied1998,
  title = {Gradient-Based Learning Applied to Document Recognition},
  author = {Lecun, Y. and Bottou, L. and Bengio, Y. and Haffner, P.},
  date = {1998-11},
  journaltitle = {Proceedings of the IEEE},
  volume = {86},
  number = {11},
  pages = {2278--2324},
  issn = {1558-2256},
  doi = {10.1109/5.726791},
  abstract = {Multilayer neural networks trained with the back-propagation algorithm constitute the best example of a successful gradient based learning technique. Given an appropriate network architecture, gradient-based learning algorithms can be used to synthesize a complex decision surface that can classify high-dimensional patterns, such as handwritten characters, with minimal preprocessing. This paper reviews various methods applied to handwritten character recognition and compares them on a standard handwritten digit recognition task. Convolutional neural networks, which are specifically designed to deal with the variability of 2D shapes, are shown to outperform all other techniques. Real-life document recognition systems are composed of multiple modules including field extraction, segmentation recognition, and language modeling. A new learning paradigm, called graph transformer networks (GTN), allows such multimodule systems to be trained globally using gradient-based methods so as to minimize an overall performance measure. Two systems for online handwriting recognition are described. Experiments demonstrate the advantage of global training, and the flexibility of graph transformer networks. A graph transformer network for reading a bank cheque is also described. It uses convolutional neural network character recognizers combined with global training techniques to provide record accuracy on business and personal cheques. It is deployed commercially and reads several million cheques per day.},
  eventtitle = {Proceedings of the {{IEEE}}},
  keywords = {Character recognition,Feature extraction,Hidden Markov models,Machine learning,Multi-layer neural network,Neural networks,Optical character recognition software,Optical computing,Pattern recognition,Principal component analysis},
  file = {/Users/marcel/Zotero/storage/CE6JRHB8/Lecun et al. - 1998 - Gradient-based learning applied to document recogn.pdf;/Users/marcel/Zotero/storage/IWA9SBAC/726791.html}
}

@article{liAdaptiveDropoutMethod2021a,
  title = {Adaptive {{Dropout Method Based}} on {{Biological Principles}}},
  author = {Li, Hailiang and Weng, Jian and Mao, Yijun and Wang, Yonghua and Zhan, Yiju and Cai, Qingling and Gu, Wanrong},
  date = {2021-09},
  journaltitle = {IEEE Transactions on Neural Networks and Learning Systems},
  volume = {32},
  number = {9},
  pages = {4267--4276},
  issn = {2162-2388},
  doi = {10.1109/TNNLS.2021.3070895},
  abstract = {Dropout is one of the most widely used methods to avoid overfitting neural networks. However, it rigidly and randomly activates neurons according to a fixed probability, which is not consistent with the activation mode of neurons in the human cerebral cortex. Inspired by gene theory and the activation mechanism of brain neurons, we propose a more intelligent adaptive dropout, in which a variational self-encoder (VAE) overlaps to an existing neural network to regularize its hidden neurons by adaptively setting activities to zero. Through alternating iterative training, the discarding probability of each hidden neuron can be learned according to the weights and thus effectively avoid the shortcomings of the standard dropout method. The experimental results in multiple data sets illustrate that this method can better suppress overfitting in various neural networks than can the standard dropout. Additionally, this adaptive dropout technique can reduce the number of neurons and improve training efficiency.},
  eventtitle = {{{IEEE Transactions}} on {{Neural Networks}} and {{Learning Systems}}},
  keywords = {Adaptive dropout,Adaptive systems,Biological neural networks,deep learning,dropout,Feature extraction,Neurons,overfitting,Standards,Training,Unsupervised learning},
  file = {/Users/marcel/Zotero/storage/2R3ZPAG5/Li et al. - 2021 - Adaptive Dropout Method Based on Biological Princi.pdf;/Users/marcel/Zotero/storage/N2X7RWCD/9408375.html}
}

@online{lianPersiaOpenHybrid2021,
  title = {Persia: {{An Open}}, {{Hybrid System Scaling Deep Learning-based Recommenders}} up to 100 {{Trillion Parameters}}},
  shorttitle = {Persia},
  author = {Lian, Xiangru and Yuan, Binhang and Zhu, Xuefeng and Wang, Yulong and He, Yongjun and Wu, Honghuan and Sun, Lei and Lyu, Haodong and Liu, Chengjun and Dong, Xing and Liao, Yiqiao and Luo, Mingnan and Zhang, Congfei and Xie, Jingru and Li, Haonan and Chen, Lei and Huang, Renjie and Lin, Jianying and Shu, Chengchun and Qiu, Xuezhong and Liu, Zhishan and Kong, Dongying and Yuan, Lei and Yu, Hai and Yang, Sen and Zhang, Ce and Liu, Ji},
  date = {2021-11-23},
  eprint = {2111.05897},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2111.05897},
  url = {http://arxiv.org/abs/2111.05897},
  urldate = {2022-12-01},
  abstract = {Deep learning based models have dominated the current landscape of production recommender systems. Furthermore, recent years have witnessed an exponential growth of the model scale--from Google's 2016 model with 1 billion parameters to the latest Facebook's model with 12 trillion parameters. Significant quality boost has come with each jump of the model capacity, which makes us believe the era of 100 trillion parameters is around the corner. However, the training of such models is challenging even within industrial scale data centers. This difficulty is inherited from the staggering heterogeneity of the training computation--the model's embedding layer could include more than 99.99\% of the total model size, which is extremely memory-intensive; while the rest neural network is increasingly computation-intensive. To support the training of such huge models, an efficient distributed training system is in urgent need. In this paper, we resolve this challenge by careful co-design of both the optimization algorithm and the distributed system architecture. Specifically, in order to ensure both the training efficiency and the training accuracy, we design a novel hybrid training algorithm, where the embedding layer and the dense neural network are handled by different synchronization mechanisms; then we build a system called Persia (short for parallel recommendation training system with hybrid acceleration) to support this hybrid training algorithm. Both theoretical demonstration and empirical study up to 100 trillion parameters have conducted to justified the system design and implementation of Persia. We make Persia publicly available (at https://github.com/PersiaML/Persia) so that anyone would be able to easily train a recommender model at the scale of 100 trillion parameters.},
  pubstate = {prepublished},
  keywords = {Computer Science - Distributed Parallel and Cluster Computing,Computer Science - Machine Learning},
  file = {/Users/marcel/Zotero/storage/YE5Q44LC/Lian et al. - 2021 - Persia An Open, Hybrid System Scaling Deep Learni.pdf;/Users/marcel/Zotero/storage/49T6JYN7/2111.html}
}

@article{lillicrapBackpropagationBrain2020,
  title = {Backpropagation and the Brain},
  author = {Lillicrap, Timothy P. and Santoro, Adam and Marris, Luke and Akerman, Colin J. and Hinton, Geoffrey},
  date = {2020-06},
  journaltitle = {Nature Reviews Neuroscience},
  shortjournal = {Nat Rev Neurosci},
  volume = {21},
  number = {6},
  pages = {335--346},
  publisher = {Nature Publishing Group},
  issn = {1471-0048},
  doi = {10.1038/s41583-020-0277-3},
  url = {https://www.nature.com/articles/s41583-020-0277-3},
  urldate = {2022-04-30},
  abstract = {During learning, the brain modifies synapses to improve behaviour. In the cortex, synapses are embedded within multilayered networks, making it difficult to determine the effect of an individual synaptic modification on the behaviour of the system. The backpropagation algorithm solves this problem in deep artificial neural networks, but historically it has been viewed as biologically problematic. Nonetheless, recent developments in neuroscience and the successes of artificial neural networks have reinvigorated interest in whether backpropagation offers insights for understanding learning in the cortex. The backpropagation algorithm learns quickly by computing synaptic updates using feedback connections to deliver error signals. Although feedback connections are ubiquitous in the cortex, it is difficult to see how they could deliver the error signals required by strict formulations of backpropagation. Here we build on past and recent developments to argue that feedback connections may instead induce neural activities whose differences can be used to locally approximate these signals and hence drive effective learning in deep networks in the brain.},
  issue = {6},
  langid = {english},
  keywords = {Cortex,Learning algorithms,Long-term potentiation,Network models,Neurophysiology},
  file = {/Users/marcel/Zotero/storage/HTRK6RNQ/Lillicrap et al. - 2020 - Backpropagation and the brain.pdf;/Users/marcel/Zotero/storage/Z3QA3YBE/s41583-020-0277-3.html}
}

@article{limEvolutionMetastableStructures2020,
  title = {Evolution of {{Metastable Structures}} at {{Bimetallic Surfaces}} from {{Microscopy}} and {{Machine-Learning Molecular Dynamics}}},
  author = {Lim, Jin Soo and Vandermause, Jonathan and family=Spronsen, given=Matthijs A., prefix=van, useprefix=true and Musaelian, Albert and Xie, Yu and Sun, Lixin and O’Connor, Christopher R. and Egle, Tobias and Molinari, Nicola and Florian, Jacob and Duanmu, Kaining and Madix, Robert J. and Sautet, Philippe and Friend, Cynthia M. and Kozinsky, Boris},
  date = {2020-09-16},
  journaltitle = {Journal of the American Chemical Society},
  shortjournal = {J. Am. Chem. Soc.},
  volume = {142},
  number = {37},
  pages = {15907--15916},
  publisher = {American Chemical Society},
  issn = {0002-7863},
  doi = {10.1021/jacs.0c06401},
  url = {https://doi.org/10.1021/jacs.0c06401},
  urldate = {2023-01-10},
  abstract = {The restructuring of interfaces plays a crucial role in materials science and heterogeneous catalysis. Bimetallic systems, in particular, often adopt very different compositions and morphologies at surfaces compared to the bulk. For the first time, we reveal a detailed atomistic picture of long-time scale restructuring of Pd deposited on Ag using microscopy, spectroscopy, and novel simulation methods. By developing and performing accelerated machine-learning molecular dynamics followed by an automated analysis method, we discover and characterize previously unidentified surface restructuring mechanisms in an unbiased fashion, including Pd–Ag place exchange and Ag pop-out as well as step ascent and descent. Remarkably, layer-by-layer dissolution of Pd into Ag is always preceded by an encapsulation of Pd islands by Ag, resulting in a significant migration of Ag out of the surface and a formation of extensive vacancy pits within a period of microseconds. These metastable structures are of vital catalytic importance, as Ag-encapsulated Pd remains much more accessible to reactants than bulk-dissolved Pd. Our approach is broadly applicable to complex multimetallic systems and enables the previously intractable mechanistic investigation of restructuring dynamics at atomic resolution.},
  file = {/Users/marcel/Zotero/storage/42JV765M/Lim et al. - 2020 - Evolution of Metastable Structures at Bimetallic S.pdf}
}

@online{linAcceleratingSpMMKernel2021,
  title = {Accelerating {{SpMM Kernel}} with {{Cache-First Edge Sampling}} for {{Graph Neural Networks}}},
  author = {Lin, Chien-Yu and Luo, Liang and Ceze, Luis},
  date = {2021-04-23},
  eprint = {2104.10716},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2104.10716},
  urldate = {2022-09-23},
  abstract = {Graph neural networks (GNNs), an emerging deep learning model class, can extract meaningful representations from highly expressive graph-structured data and are therefore gaining popularity for wider ranges of applications. However, current GNNs suffer from the poor performance of their sparse-dense matrix multiplication (SpMM) operator, even when using powerful GPUs. Our analysis shows that 95\% of the inference time could be spent on SpMM when running popular GNN models on NVIDIA's advanced V100 GPU. Such SpMM performance bottleneck hinders GNNs' applicability to large-scale problems or the development of more sophisticated GNN models. To address this inference time bottleneck, we introduce ES-SpMM, a cache-first edge sampling mechanism and codesigned SpMM kernel. ES-SpMM uses edge sampling to downsize the graph to fit into GPU's shared memory. It thus reduces the computation cost and improves SpMM's cache locality. To evaluate ES-SpMM's performance, we integrated it with a popular GNN framework, DGL, and tested it using representative GNN models and datasets. Our results show that ES-SpMM outperforms the highly optimized cuSPARSE SpMM kernel by up to 4.35x with no accuracy loss and by 45.3x with less than a 1\% accuracy loss.},
  pubstate = {prepublished},
  keywords = {Computer Science - Distributed Parallel and Cluster Computing,Computer Science - Machine Learning},
  file = {/Users/marcel/Zotero/storage/KSTVAV36/Lin et al. - 2021 - Accelerating SpMM Kernel with Cache-First Edge Sam.pdf;/Users/marcel/Zotero/storage/6WVHY6VA/2104.html}
}

@article{linAllopticalMachineLearning2018,
  title = {All-Optical Machine Learning Using Diffractive Deep Neural Networks},
  author = {Lin, Xing and Rivenson, Yair and Yardimci, Nezih T. and Veli, Muhammed and Luo, Yi and Jarrahi, Mona and Ozcan, Aydogan},
  date = {2018-09-07},
  journaltitle = {Science},
  volume = {361},
  number = {6406},
  pages = {1004--1008},
  publisher = {American Association for the Advancement of Science},
  doi = {10.1126/science.aat8084},
  url = {https://www.science.org/doi/10.1126/science.aat8084},
  urldate = {2023-10-21},
  abstract = {Deep learning has been transforming our ability to execute advanced inference tasks using computers. Here we introduce a physical mechanism to perform machine learning by demonstrating an all-optical diffractive deep neural network (D2NN) architecture that can implement various functions following the deep learning–based design of passive diffractive layers that work collectively. We created 3D-printed D2NNs that implement classification of images of handwritten digits and fashion products, as well as the function of an imaging lens at a terahertz spectrum. Our all-optical deep learning framework can perform, at the speed of light, various complex functions that computer-based neural networks can execute; will find applications in all-optical image analysis, feature detection, and object classification; and will also enable new camera designs and optical components that perform distinctive tasks using D2NNs.},
  file = {/Users/marcel/Zotero/storage/TGCELSQH/Lin et al. - 2018 - All-optical machine learning using diffractive deep neural networks.pdf}
}

@unpublished{liPruningFiltersEfficient2017,
  title = {Pruning {{Filters}} for {{Efficient ConvNets}}},
  author = {Li, Hao and Kadav, Asim and Durdanovic, Igor and Samet, Hanan and Graf, Hans Peter},
  date = {2017-03-10},
  eprint = {1608.08710},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/1608.08710},
  urldate = {2021-07-27},
  abstract = {The success of CNNs in various applications is accompanied by a significant increase in the computation and parameter storage costs. Recent efforts toward reducing these overheads involve pruning and compressing the weights of various layers without hurting original accuracy. However, magnitude-based pruning of weights reduces a significant number of parameters from the fully connected layers and may not adequately reduce the computation costs in the convolutional layers due to irregular sparsity in the pruned networks. We present an acceleration method for CNNs, where we prune filters from CNNs that are identified as having a small effect on the output accuracy. By removing whole filters in the network together with their connecting feature maps, the computation costs are reduced significantly. In contrast to pruning weights, this approach does not result in sparse connectivity patterns. Hence, it does not need the support of sparse convolution libraries and can work with existing efficient BLAS libraries for dense matrix multiplications. We show that even simple filter pruning techniques can reduce inference costs for VGG-16 by up to 34\% and ResNet-110 by up to 38\% on CIFAR10 while regaining close to the original accuracy by retraining the networks.},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning},
  file = {/Users/marcel/Zotero/storage/M33784WY/Li et al_2017_Pruning Filters for Efficient ConvNets.pdf;/Users/marcel/Zotero/storage/7D76A2H2/1608.html}
}

@article{lipshutzBiologicallyPlausibleNeural2021,
  title = {A {{Biologically Plausible Neural Network}} for {{Multichannel Canonical Correlation Analysis}}},
  author = {Lipshutz, David and Bahroun, Yanis and Golkar, Siavash and Sengupta, Anirvan M. and Chklovskii, Dmitri B.},
  date = {2021-08-19},
  journaltitle = {Neural Computation},
  shortjournal = {Neural Comput},
  volume = {33},
  number = {9},
  eprint = {34412114},
  eprinttype = {pmid},
  pages = {2309--2352},
  issn = {1530-888X},
  doi = {10.1162/neco_a_01414},
  abstract = {Cortical pyramidal neurons receive inputs from multiple distinct neural populations and integrate these inputs in separate dendritic compartments. We explore the possibility that cortical microcircuits implement canonical correlation analysis (CCA), an unsupervised learning method that projects the inputs onto a common subspace so as to maximize the correlations between the projections. To this end, we seek a multichannel CCA algorithm that can be implemented in a biologically plausible neural network. For biological plausibility, we require that the network operates in the online setting and its synaptic update rules are local. Starting from a novel CCA objective function, we derive an online optimization algorithm whose optimization steps can be implemented in a single-layer neural network with multicompartmental neurons and local non-Hebbian learning rules. We also derive an extension of our online CCA algorithm with adaptive output rank and output whitening. Interestingly, the extension maps onto a neural network whose neural architecture and synaptic updates resemble neural circuitry and non-Hebbian plasticity observed in the cortex.},
  langid = {english},
  keywords = {Algorithms,Canonical Correlation Analysis,Neural Networks Computer,Neurons},
  file = {/Users/marcel/Zotero/storage/RQNMYR95/Lipshutz et al. - 2021 - A Biologically Plausible Neural Network for Multic.pdf}
}

@inreference{ListAnimalsNumber2022,
  title = {List of Animals by Number of Neurons},
  booktitle = {Wikipedia},
  date = {2022-09-17T13:37:58Z},
  url = {https://en.wikipedia.org/w/index.php?title=List_of_animals_by_number_of_neurons&oldid=1110783299},
  urldate = {2022-12-01},
  abstract = {The following are two lists of animals ordered by the size of their nervous system.  The first list shows number of neurons in their entire nervous system, indicating their overall neural complexity.  The second list shows the number of neurons in the structure that has been found to be representative of animal intelligence. The human brain contains 86 billion neurons, with 16 billion neurons in the cerebral cortex.},
  langid = {english},
  annotation = {Page Version ID: 1110783299},
  file = {/Users/marcel/Zotero/storage/3YLL3CIC/List_of_animals_by_number_of_neurons.html}
}

@online{liuBlockwiseParallelTransformer2023,
  title = {Blockwise {{Parallel Transformer}} for {{Large Context Models}}},
  author = {Liu, Hao and Abbeel, Pieter},
  date = {2023-08-28},
  eprint = {2305.19370},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2305.19370},
  url = {http://arxiv.org/abs/2305.19370},
  urldate = {2024-02-22},
  abstract = {Transformers have emerged as the cornerstone of state-of-the-art natural language processing models, showcasing exceptional performance across a wide range of AI applications. However, the memory demands posed by the self-attention mechanism and the large feedforward network in Transformers limit their ability to handle long sequences, thereby creating challenges for tasks involving multiple long sequences or long-term dependencies. We present a distinct approach, Blockwise Parallel Transformer (BPT), that leverages blockwise computation of self-attention and feedforward network fusion to minimize memory costs. By processing longer input sequences while maintaining memory efficiency, BPT enables training sequences 32 times longer than vanilla Transformers and up to 4 times longer than previous memory-efficient methods. Extensive experiments on language modeling and reinforcement learning tasks demonstrate the effectiveness of BPT in reducing memory requirements and improving performance.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computation and Language,Computer Science - Machine Learning},
  file = {/Users/marcel/Zotero/storage/UGMMJY6V/Liu and Abbeel - 2023 - Blockwise Parallel Transformer for Large Context Models.pdf;/Users/marcel/Zotero/storage/NQCACKC8/2305.html}
}

@online{liuGenerating3DMolecules2022,
  title = {Generating {{3D Molecules}} for {{Target Protein Binding}}},
  author = {Liu, Meng and Luo, Youzhi and Uchino, Kanji and Maruhashi, Koji and Ji, Shuiwang},
  date = {2022-05-30},
  eprint = {2204.09410},
  eprinttype = {arXiv},
  eprintclass = {cs, q-bio},
  doi = {10.48550/arXiv.2204.09410},
  url = {http://arxiv.org/abs/2204.09410},
  urldate = {2022-07-18},
  abstract = {A fundamental problem in drug discovery is to design molecules that bind to specific proteins. To tackle this problem using machine learning methods, here we propose a novel and effective framework, known as GraphBP, to generate 3D molecules that bind to given proteins by placing atoms of specific types and locations to the given binding site one by one. In particular, at each step, we first employ a 3D graph neural network to obtain geometry-aware and chemically informative representations from the intermediate contextual information. Such context includes the given binding site and atoms placed in the previous steps. Second, to preserve the desirable equivariance property, we select a local reference atom according to the designed auxiliary classifiers and then construct a local spherical coordinate system. Finally, to place a new atom, we generate its atom type and relative location w.r.t. the constructed local coordinate system via a flow model. We also consider generating the variables of interest sequentially to capture the underlying dependencies among them. Experiments demonstrate that our GraphBP is effective to generate 3D molecules with binding ability to target protein binding sites. Our implementation is available at https://github.com/divelab/GraphBP.},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Quantitative Biology - Biomolecules},
  file = {/Users/marcel/Zotero/storage/TJ6BTQ79/Liu et al. - 2022 - Generating 3D Molecules for Target Protein Binding.pdf;/Users/marcel/Zotero/storage/MBTIS33A/2204.html}
}

@inproceedings{liulian-xiDesignPLLSystem2005,
  title = {Design of {{PLL}} System Based Verilog-{{AMS}} Behavior Models},
  booktitle = {Proceedings of 2005 {{IEEE International Workshop}} on {{VLSI Design}} and {{Video Technology}}, 2005.},
  author = {{Liu Lian-xi} and {Yang Yin-tang} and {Zhu Zhang-ming} and {Li Yam}},
  date = {2005},
  pages = {67--70},
  publisher = {IEEE},
  location = {Suzhou, China},
  doi = {10.1109/IWVDVT.2005.1504466},
  url = {http://ieeexplore.ieee.org/document/1504466/},
  urldate = {2023-10-17},
  abstract = {A top-down design method on analog PLL system based Verilog-AMS HDL behavior models is proposed. A PLL contained a VCO behavior model with center frequency IZOMHz and a two-order passive filter with cut-off frequency 300.0KHz is implemented. The Verilog-AMS behavior models are verified and used in PLL system simulation by the tools of Cadence Spectre.},
  eventtitle = {2005 {{IEEE International Workshop}} on {{VLSI Design}} and {{Video Technology}}, 2005.},
  isbn = {978-0-7803-9005-8},
  langid = {english},
  file = {/Users/marcel/Zotero/storage/K82T9PVP/Liu Lian-xi et al. - 2005 - Design of PLL system based verilog-AMS behavior models.pdf}
}

@online{liuNeRFInFreeFormNeRF2022,
  title = {{{NeRF-In}}: {{Free-Form NeRF Inpainting}} with {{RGB-D Priors}}},
  shorttitle = {{{NeRF-In}}},
  author = {Liu, Hao-Kang and Shen, I.-Chao and Chen, Bing-Yu},
  date = {2022-06-10},
  eprint = {2206.04901},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2206.04901},
  url = {http://arxiv.org/abs/2206.04901},
  urldate = {2022-09-30},
  abstract = {Though Neural Radiance Field (NeRF) demonstrates compelling novel view synthesis results, it is still unintuitive to edit a pre-trained NeRF because the neural network's parameters and the scene geometry/appearance are often not explicitly associated. In this paper, we introduce the first framework that enables users to remove unwanted objects or retouch undesired regions in a 3D scene represented by a pre-trained NeRF without any category-specific data and training. The user first draws a free-form mask to specify a region containing unwanted objects over a rendered view from the pre-trained NeRF. Our framework first transfers the user-provided mask to other rendered views and estimates guiding color and depth images within these transferred masked regions. Next, we formulate an optimization problem that jointly inpaints the image content in all masked regions across multiple views by updating the NeRF model's parameters. We demonstrate our framework on diverse scenes and show it obtained visual plausible and structurally consistent results across multiple views using shorter time and less user manual efforts.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Graphics},
  file = {/Users/marcel/Zotero/storage/NNA2ITXN/Liu et al. - 2022 - NeRF-In Free-Form NeRF Inpainting with RGB-D Prio.pdf;/Users/marcel/Zotero/storage/WQ7JSABR/2206.html}
}

@online{liuRingAttentionBlockwise2023,
  title = {Ring {{Attention}} with {{Blockwise Transformers}} for {{Near-Infinite Context}}},
  author = {Liu, Hao and Zaharia, Matei and Abbeel, Pieter},
  date = {2023-11-27},
  eprint = {2310.01889},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2310.01889},
  url = {http://arxiv.org/abs/2310.01889},
  urldate = {2024-02-16},
  abstract = {Transformers have emerged as the architecture of choice for many state-of-the-art AI models, showcasing exceptional performance across a wide range of AI applications. However, the memory demands imposed by Transformers limit their ability to handle long sequences, thereby posing challenges in utilizing videos, actions, and other long-form sequences and modalities in complex environments. We present a novel approach, Ring Attention with Blockwise Transformers (Ring Attention), which leverages blockwise computation of self-attention and feedforward to distribute long sequences across multiple devices while fully overlapping the communication of key-value blocks with the computation of blockwise attention. Our approach enables training and inference of sequences that are up to device count times longer than those achievable by prior memory-efficient Transformers, without resorting to approximations or incurring additional communication and computation overheads. Extensive experiments on language modeling and reinforcement learning tasks demonstrate the effectiveness of our approach in allowing millions of tokens context size and improving performance.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computation and Language},
  file = {/Users/marcel/Zotero/storage/5XVFTMVM/Liu et al. - 2023 - Ring Attention with Blockwise Transformers for Near-Infinite Context.pdf;/Users/marcel/Zotero/storage/DL2DR3QU/2310.html}
}

@online{liuRoBERTaRobustlyOptimized2019,
  title = {{{RoBERTa}}: {{A Robustly Optimized BERT Pretraining Approach}}},
  shorttitle = {{{RoBERTa}}},
  author = {Liu, Yinhan and Ott, Myle and Goyal, Naman and Du, Jingfei and Joshi, Mandar and Chen, Danqi and Levy, Omer and Lewis, Mike and Zettlemoyer, Luke and Stoyanov, Veselin},
  date = {2019-07-26},
  eprint = {1907.11692},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.1907.11692},
  url = {http://arxiv.org/abs/1907.11692},
  urldate = {2024-02-14},
  abstract = {Language model pretraining has led to significant performance gains but careful comparison between different approaches is challenging. Training is computationally expensive, often done on private datasets of different sizes, and, as we will show, hyperparameter choices have significant impact on the final results. We present a replication study of BERT pretraining (Devlin et al., 2019) that carefully measures the impact of many key hyperparameters and training data size. We find that BERT was significantly undertrained, and can match or exceed the performance of every model published after it. Our best model achieves state-of-the-art results on GLUE, RACE and SQuAD. These results highlight the importance of previously overlooked design choices, and raise questions about the source of recently reported improvements. We release our models and code.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computation and Language},
  file = {/Users/marcel/Zotero/storage/MAMEAXZZ/Liu et al. - 2019 - RoBERTa A Robustly Optimized BERT Pretraining Approach.pdf;/Users/marcel/Zotero/storage/W67NJMLS/1907.html}
}

@online{liuSMEReRAMbasedSparseMultiplicationEngine2021,
  title = {{{SME}}: {{ReRAM-based Sparse-Multiplication-Engine}} to {{Squeeze-Out Bit Sparsity}} of {{Neural Network}}},
  shorttitle = {{{SME}}},
  author = {Liu, Fangxin and Zhao, Wenbo and Zhao, Yilong and Wang, Zongwu and Yang, Tao and He, Zhezhi and Jing, Naifeng and Liang, Xiaoyao and Jiang, Li},
  date = {2021-03-02},
  eprint = {2103.01705},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2103.01705},
  url = {http://arxiv.org/abs/2103.01705},
  urldate = {2023-11-11},
  abstract = {Resistive Random-Access-Memory (ReRAM) crossbar is a promising technique for deep neural network (DNN) accelerators, thanks to its in-memory and in-situ analog computing abilities for Vector-Matrix Multiplication-and-Accumulations (VMMs). However, it is challenging for crossbar architecture to exploit the sparsity in the DNN. It inevitably causes complex and costly control to exploit fine-grained sparsity due to the limitation of tightly-coupled crossbar structure. As the countermeasure, we developed a novel ReRAM-based DNN accelerator, named Sparse-Multiplication-Engine (SME), based on a hardware and software co-design framework. First, we orchestrate the bit-sparse pattern to increase the density of bit-sparsity based on existing quantization methods. Second, we propose a novel weigh mapping mechanism to slice the bits of a weight across the crossbars and splice the activation results in peripheral circuits. This mechanism can decouple the tightly-coupled crossbar structure and cumulate the sparsity in the crossbar. Finally, a superior squeeze-out scheme empties the crossbars mapped with highly-sparse non-zeros from the previous two steps. We design the SME architecture and discuss its use for other quantization methods and different ReRAM cell technologies. Compared with prior state-of-the-art designs, the SME shrinks the use of crossbars up to 8.7x and 2.1x using Resent-50 and MobileNet-v2, respectively, with less than 0.3\% accuracy drop on ImageNet.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Hardware Architecture,Computer Science - Machine Learning},
  file = {/Users/marcel/Zotero/storage/IZEH8TC2/Liu et al. - 2021 - SME ReRAM-based Sparse-Multiplication-Engine to Squeeze-Out Bit Sparsity of Neural Network.pdf;/Users/marcel/Zotero/storage/HBWN4JP9/2103.html}
}

@unpublished{liuSSDSingleShot2016,
  title = {{{SSD}}: {{Single Shot MultiBox Detector}}},
  shorttitle = {{{SSD}}},
  author = {Liu, Wei and Anguelov, Dragomir and Erhan, Dumitru and Szegedy, Christian and Reed, Scott and Fu, Cheng-Yang and Berg, Alexander C.},
  date = {2016},
  volume = {9905},
  eprint = {1512.02325},
  eprinttype = {arXiv},
  eprintclass = {cs},
  pages = {21--37},
  doi = {10.1007/978-3-319-46448-0_2},
  url = {http://arxiv.org/abs/1512.02325},
  urldate = {2021-09-28},
  abstract = {We present a method for detecting objects in images using a single deep neural network. Our approach, named SSD, discretizes the output space of bounding boxes into a set of default boxes over different aspect ratios and scales per feature map location. At prediction time, the network generates scores for the presence of each object category in each default box and produces adjustments to the box to better match the object shape. Additionally, the network combines predictions from multiple feature maps with different resolutions to naturally handle objects of various sizes. Our SSD model is simple relative to methods that require object proposals because it completely eliminates proposal generation and subsequent pixel or feature resampling stage and encapsulates all computation in a single network. This makes SSD easy to train and straightforward to integrate into systems that require a detection component. Experimental results on the PASCAL VOC, MS COCO, and ILSVRC datasets confirm that SSD has comparable accuracy to methods that utilize an additional object proposal step and is much faster, while providing a unified framework for both training and inference. Compared to other single stage methods, SSD has much better accuracy, even with a smaller input image size. For \$300\textbackslash times 300\$ input, SSD achieves 72.1\% mAP on VOC2007 test at 58 FPS on a Nvidia Titan X and for \$500\textbackslash times 500\$ input, SSD achieves 75.1\% mAP, outperforming a comparable state of the art Faster R-CNN model. Code is available at https://github.com/weiliu89/caffe/tree/ssd .},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {/Users/marcel/Zotero/storage/3EC4DG8A/Liu et al_2016_SSD.pdf;/Users/marcel/Zotero/storage/QGFH5FT6/1512.html}
}

@online{liuWorldModelMillionLength2024,
  title = {World {{Model}} on {{Million-Length Video And Language With RingAttention}}},
  author = {Liu, Hao and Yan, Wilson and Zaharia, Matei and Abbeel, Pieter},
  date = {2024-02-13},
  eprint = {2402.08268},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2402.08268},
  url = {http://arxiv.org/abs/2402.08268},
  urldate = {2024-02-22},
  abstract = {Current language models fall short in understanding aspects of the world not easily described in words, and struggle with complex, long-form tasks. Video sequences offer valuable temporal information absent in language and static images, making them attractive for joint modeling with language. Such models could develop a understanding of both human textual knowledge and the physical world, enabling broader AI capabilities for assisting humans. However, learning from millions of tokens of video and language sequences poses challenges due to memory constraints, computational complexity, and limited datasets. To address these challenges, we curate a large dataset of diverse videos and books, utilize the RingAttention technique to scalably train on long sequences, and gradually increase context size from 4K to 1M tokens. This paper makes the following contributions: (a) Largest context size neural network: We train one of the largest context size transformers on long video and language sequences, setting new benchmarks in difficult retrieval tasks and long video understanding. (b) Solutions for overcoming vision-language training challenges, including using masked sequence packing for mixing different sequence lengths, loss weighting to balance language and vision, and model-generated QA dataset for long sequence chat. (c) A highly-optimized implementation with RingAttention, masked sequence packing, and other key features for training on millions-length multimodal sequences. (d) Fully open-sourced a family of 7B parameter models capable of processing long text documents (LWM-Text, LWM-Text-Chat) and videos (LWM, LWM-Chat) of over 1M tokens. This work paves the way for training on massive datasets of long video and language to develop understanding of both human knowledge and the multimodal world, and broader capabilities.},
  pubstate = {prepublished},
  keywords = {Computer Science - Machine Learning},
  file = {/Users/marcel/Zotero/storage/DBHSLGV3/Liu et al. - 2024 - World Model on Million-Length Video And Language With RingAttention.pdf;/Users/marcel/Zotero/storage/CCBFJ7H9/2402.html}
}

@article{lloydLeastSquaresQuantization1982,
  title = {Least Squares Quantization in {{PCM}}},
  author = {Lloyd, S.},
  date = {1982-03},
  journaltitle = {IEEE Transactions on Information Theory},
  shortjournal = {IEEE Trans. Inform. Theory},
  volume = {28},
  number = {2},
  pages = {129--137},
  issn = {0018-9448},
  doi = {10.1109/TIT.1982.1056489},
  url = {http://ieeexplore.ieee.org/document/1056489/},
  urldate = {2023-02-28},
  abstract = {It has long been realized that in pulse-code modulation (PCM), with a given ensemble of signals to handle, the quantum values should be spaced more closely in the voltage regions where the signal amplitude is more likely to fall. It has been shown by Panter and Dite that, in the limit as the number of quanta becomes infinite, the asymptotic fractional density of quanta per unit voltage should vary as the one-third power of the probability density per unit voltage of signal amplitudes. In this paper the corresponding result for any finite number of quanta is derived; that is, necessary conditions are found that the quanta and associated quantization intervals of an optimum finite quantization scheme must satisfy. The optimization criterion used is that the average quantization noise power be a minimum. It is shown that the result obtained here goes over into the Panter and Dite result as the number of quanta become large. The optimum quautization schemes for 2\textasciicircum\{b\} quanta, b=1,2, \textbackslash cdots, 7 , are given numerically for Gaussian and for Laplacian distribution of signal amplitudes.},
  langid = {english},
  file = {/Users/marcel/Zotero/storage/SFCF3X53/Lloyd - 1982 - Least squares quantization in PCM.pdf}
}

@unpublished{lonesHowAvoidMachine2021,
  title = {How to Avoid Machine Learning Pitfalls: A Guide for Academic Researchers},
  shorttitle = {How to Avoid Machine Learning Pitfalls},
  author = {Lones, Michael A.},
  date = {2021-08-05},
  eprint = {2108.02497},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2108.02497},
  urldate = {2021-08-20},
  abstract = {This document gives a concise outline of some of the common mistakes that occur when using machine learning techniques, and what can be done to avoid them. It is intended primarily as a guide for research students, and focuses on issues that are of particular concern within academic research, such as the need to do rigorous comparisons and reach valid conclusions. It covers five stages of the machine learning process: what to do before model building, how to reliably build models, how to robustly evaluate models, how to compare models fairly, and how to report results.},
  keywords = {Computer Science - Machine Learning},
  file = {/Users/marcel/Zotero/storage/NQ47HWXN/Lones_2021_How to avoid machine learning pitfalls.pdf;/Users/marcel/Zotero/storage/AHZJAQNR/2108.html}
}

@online{loshchilovDecoupledWeightDecay2019,
  title = {Decoupled {{Weight Decay Regularization}}},
  author = {Loshchilov, Ilya and Hutter, Frank},
  date = {2019-01-04},
  eprint = {1711.05101},
  eprinttype = {arXiv},
  eprintclass = {cs, math},
  doi = {10.48550/arXiv.1711.05101},
  url = {http://arxiv.org/abs/1711.05101},
  urldate = {2024-03-14},
  abstract = {L\$\_2\$ regularization and weight decay regularization are equivalent for standard stochastic gradient descent (when rescaled by the learning rate), but as we demonstrate this is \textbackslash emph\{not\} the case for adaptive gradient algorithms, such as Adam. While common implementations of these algorithms employ L\$\_2\$ regularization (often calling it "weight decay" in what may be misleading due to the inequivalence we expose), we propose a simple modification to recover the original formulation of weight decay regularization by \textbackslash emph\{decoupling\} the weight decay from the optimization steps taken w.r.t. the loss function. We provide empirical evidence that our proposed modification (i) decouples the optimal choice of weight decay factor from the setting of the learning rate for both standard SGD and Adam and (ii) substantially improves Adam's generalization performance, allowing it to compete with SGD with momentum on image classification datasets (on which it was previously typically outperformed by the latter). Our proposed decoupled weight decay has already been adopted by many researchers, and the community has implemented it in TensorFlow and PyTorch; the complete source code for our experiments is available at https://github.com/loshchil/AdamW-and-SGDW},
  pubstate = {prepublished},
  keywords = {Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing,Mathematics - Optimization and Control},
  file = {/Users/marcel/Zotero/storage/AAC2YGR6/Loshchilov and Hutter - 2019 - Decoupled Weight Decay Regularization.pdf;/Users/marcel/Zotero/storage/PBZA9Z57/1711.html}
}

@online{loshchilovSGDRStochasticGradient2017,
  title = {{{SGDR}}: {{Stochastic Gradient Descent}} with {{Warm Restarts}}},
  shorttitle = {{{SGDR}}},
  author = {Loshchilov, Ilya and Hutter, Frank},
  date = {2017-05-03},
  eprint = {1608.03983},
  eprinttype = {arXiv},
  eprintclass = {cs, math},
  doi = {10.48550/arXiv.1608.03983},
  url = {http://arxiv.org/abs/1608.03983},
  urldate = {2024-02-29},
  abstract = {Restart techniques are common in gradient-free optimization to deal with multimodal functions. Partial warm restarts are also gaining popularity in gradient-based optimization to improve the rate of convergence in accelerated gradient schemes to deal with ill-conditioned functions. In this paper, we propose a simple warm restart technique for stochastic gradient descent to improve its anytime performance when training deep neural networks. We empirically study its performance on the CIFAR-10 and CIFAR-100 datasets, where we demonstrate new state-of-the-art results at 3.14\% and 16.21\%, respectively. We also demonstrate its advantages on a dataset of EEG recordings and on a downsampled version of the ImageNet dataset. Our source code is available at https://github.com/loshchil/SGDR},
  pubstate = {prepublished},
  version = {5},
  keywords = {Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing,Mathematics - Optimization and Control},
  file = {/Users/marcel/Zotero/storage/AWKUPX8S/Loshchilov and Hutter - 2017 - SGDR Stochastic Gradient Descent with Warm Restarts.pdf;/Users/marcel/Zotero/storage/EIJ4IIEV/1608.html}
}

@unpublished{lotterDeepPredictiveCoding2017,
  title = {Deep {{Predictive Coding Networks}} for {{Video Prediction}} and {{Unsupervised Learning}}},
  author = {Lotter, William and Kreiman, Gabriel and Cox, David},
  date = {2017-02-28},
  eprint = {1605.08104},
  eprinttype = {arXiv},
  eprintclass = {cs, q-bio},
  url = {http://arxiv.org/abs/1605.08104},
  urldate = {2022-05-01},
  abstract = {While great strides have been made in using deep learning algorithms to solve supervised learning tasks, the problem of unsupervised learning - leveraging unlabeled examples to learn about the structure of a domain - remains a difficult unsolved challenge. Here, we explore prediction of future frames in a video sequence as an unsupervised learning rule for learning about the structure of the visual world. We describe a predictive neural network ("PredNet") architecture that is inspired by the concept of "predictive coding" from the neuroscience literature. These networks learn to predict future frames in a video sequence, with each layer in the network making local predictions and only forwarding deviations from those predictions to subsequent network layers. We show that these networks are able to robustly learn to predict the movement of synthetic (rendered) objects, and that in doing so, the networks learn internal representations that are useful for decoding latent object parameters (e.g. pose) that support object recognition with fewer training views. We also show that these networks can scale to complex natural image streams (car-mounted camera videos), capturing key aspects of both egocentric movement and the movement of objects in the visual scene, and the representation learned in this setting is useful for estimating the steering angle. Altogether, these results suggest that prediction represents a powerful framework for unsupervised learning, allowing for implicit learning of object and scene structure.},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing,Quantitative Biology - Neurons and Cognition},
  file = {/Users/marcel/Zotero/storage/8KVI8XIK/Lotter et al. - 2017 - Deep Predictive Coding Networks for Video Predicti.pdf;/Users/marcel/Zotero/storage/U7UKLNNH/1605.html}
}

@online{ltdIPUProcessors,
  title = {{{IPU Processors}}},
  author = {Ltd, Graphcore},
  url = {https://www.graphcore.ai/products/ipu},
  urldate = {2023-02-28},
  abstract = {The IPU, or Intelligence Processing Unit, is a highly flexible, easy-to-use parallel processor designed from the ground up for AI workloads.},
  langid = {english},
  file = {/Users/marcel/Zotero/storage/IG2C6ED7/ipu.html}
}

@article{luanDeepPhotoStyle2017,
  title = {Deep {{Photo Style Transfer}}},
  author = {Luan, Fujun and Paris, Sylvain and Shechtman, Eli and Bala, Kavita},
  date = {2017-03-22},
  doi = {10.48550/arXiv.1703.07511},
  url = {https://arxiv.org/abs/1703.07511v3},
  urldate = {2022-12-18},
  abstract = {This paper introduces a deep-learning approach to photographic style transfer that handles a large variety of image content while faithfully transferring the reference style. Our approach builds upon the recent work on painterly transfer that separates style from the content of an image by considering different layers of a neural network. However, as is, this approach is not suitable for photorealistic style transfer. Even when both the input and reference images are photographs, the output still exhibits distortions reminiscent of a painting. Our contribution is to constrain the transformation from the input to the output to be locally affine in colorspace, and to express this constraint as a custom fully differentiable energy term. We show that this approach successfully suppresses distortion and yields satisfying photorealistic style transfers in a broad variety of scenarios, including transfer of the time of day, weather, season, and artistic edits.},
  langid = {english},
  file = {/Users/marcel/Zotero/storage/PQI6K3ED/Luan et al. - 2017 - Deep Photo Style Transfer.pdf}
}

@online{luDPMSolverFastODE2022,
  title = {{{DPM-Solver}}: {{A Fast ODE Solver}} for {{Diffusion Probabilistic Model Sampling}} in {{Around}} 10 {{Steps}}},
  shorttitle = {{{DPM-Solver}}},
  author = {Lu, Cheng and Zhou, Yuhao and Bao, Fan and Chen, Jianfei and Li, Chongxuan and Zhu, Jun},
  date = {2022-10-13},
  eprint = {2206.00927},
  eprinttype = {arXiv},
  eprintclass = {cs, stat},
  doi = {10.48550/arXiv.2206.00927},
  url = {http://arxiv.org/abs/2206.00927},
  urldate = {2022-12-06},
  abstract = {Diffusion probabilistic models (DPMs) are emerging powerful generative models. Despite their high-quality generation performance, DPMs still suffer from their slow sampling as they generally need hundreds or thousands of sequential function evaluations (steps) of large neural networks to draw a sample. Sampling from DPMs can be viewed alternatively as solving the corresponding diffusion ordinary differential equations (ODEs). In this work, we propose an exact formulation of the solution of diffusion ODEs. The formulation analytically computes the linear part of the solution, rather than leaving all terms to black-box ODE solvers as adopted in previous works. By applying change-of-variable, the solution can be equivalently simplified to an exponentially weighted integral of the neural network. Based on our formulation, we propose DPM-Solver, a fast dedicated high-order solver for diffusion ODEs with the convergence order guarantee. DPM-Solver is suitable for both discrete-time and continuous-time DPMs without any further training. Experimental results show that DPM-Solver can generate high-quality samples in only 10 to 20 function evaluations on various datasets. We achieve 4.70 FID in 10 function evaluations and 2.87 FID in 20 function evaluations on the CIFAR10 dataset, and a \$4\textbackslash sim 16\textbackslash times\$ speedup compared with previous state-of-the-art training-free samplers on various datasets.},
  pubstate = {prepublished},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/marcel/Zotero/storage/3KSCPV76/Lu et al. - 2022 - DPM-Solver A Fast ODE Solver for Diffusion Probab.pdf;/Users/marcel/Zotero/storage/DXWD96MX/2206.html}
}

@article{maassNetworksSpikingNeurons1997,
  title = {Networks of Spiking Neurons: {{The}} Third Generation of Neural Network Models},
  shorttitle = {Networks of Spiking Neurons},
  author = {Maass, Wolfgang},
  date = {1997-12-01},
  journaltitle = {Neural Networks},
  shortjournal = {Neural Networks},
  volume = {10},
  number = {9},
  pages = {1659--1671},
  issn = {0893-6080},
  doi = {10.1016/S0893-6080(97)00011-7},
  url = {https://www.sciencedirect.com/science/article/pii/S0893608097000117},
  urldate = {2022-05-01},
  abstract = {The computational power of formal models for networks of spiking neurons is compared with that of other neural network models based on McCulloch Pitts neurons (i.e., threshold gates), respectively, sigmoidal gates. In particular it is shown that networks of spiking neurons are, with regard to the number of neurons that are needed, computationally more powerful than these other neural network models. A concrete biologically relevant function is exhibited which can be computed by a single spiking neuron (for biologically reasonable values of its parameters), but which requires hundreds of hidden units on a sigmoidal neural net. On the other hand, it is known that any function that can be computed by a small sigmoidal neural net can also be computed by a small network of spiking neurons. This article does not assume prior knowledge about spiking neurons, and it contains an extensive list of references to the currently available literature on computations in networks of spiking neurons and relevant results from neurobiology.},
  langid = {english},
  keywords = {Computational complexity,Integrate-and-fire neutron,Lower bounds,Sigmoidal neural nets,Spiking neuron},
  file = {/Users/marcel/Zotero/storage/P48KIM57/Maass - 1997 - Networks of spiking neurons The third generation .pdf;/Users/marcel/Zotero/storage/DH5BALMQ/S0893608097000117.html}
}

@video{machinelearningstreettalk041DrSIMON2021,
  entrysubtype = {video},
  title = {\#041 {{Dr}}. {{SIMON STRINGER}} - {{Biologically Plausible Neural Networks}}},
  editor = {{Machine Learning Street Talk}},
  editortype = {director},
  date = {2021-02-03},
  url = {https://www.youtube.com/watch?v=aisgNLypUKs},
  urldate = {2022-04-19},
  abstract = {Dr. Simon Stringer. Obtained his Ph.D in mathematical state space control theory and has been a Senior Research Fellow at Oxford University for over 27 years. Simon is the director of the the Oxford Centre for Theoretical Neuroscience and Artificial Intelligence, which is based within the Oxford University Department of Experimental Psychology. His department covers vision, spatial processing, motor function, language and consciousness -- in particular -- how the primate visual system learns to make sense of complex natural scenes. Dr. Stringers laboratory houses a team of theoreticians, who are developing computer models of a range of different aspects of brain function. Simon's lab is investigating the neural and synaptic dynamics that underpin brain function. An important matter here is the The feature-binding problem which concerns how the visual system represents the hierarchical relationships between features. the visual system must represent hierarchical binding relations across the entire visual field at every spatial scale and level in the hierarchy of visual primitives. We discuss the emergence of self-organised behaviour, complex information processing, invariant sensory representations and hierarchical feature binding which emerges when you build biologically plausible neural networks with temporal spiking dynamics.  00:00:00 Tim Intro  00:09:31 Show kickoff  00:14:37 Hierarchical Feature binding and timing of action potentials  00:30:16 Hebb to Spike-timing-dependent plasticity (STDP)  00:35:27 Encoding of shape primitives  00:38:50 Is imagination working in the same place in the brain  00:41:12 Compare to supervised CNNs  00:45:59 Speech recognition, motor system, learning mazes  00:49:28 How practical are these spiking NNs  00:50:19 Why simulate the human brain  00:52:46 How much computational power do you gain from differential timings  00:55:08 Adversarial inputs  00:59:41 Generative / causal component needed?  01:01:46 Modalities of processing i.e. language  01:03:42 Understanding  01:04:37 Human hardware  01:06:19 Roadmap of NNs?  01:10:36 Intepretability methods for these new models  01:13:03 Won't GPT just scale and do this anyway?  01:15:51 What about trace learning and transformation learning  01:18:50 Categories of invariance  01:19:47 Biological plausibility  Pod version: https://anchor.fm/machinelearningstre... https://www.neuroscience.ox.ac.uk/res... https://en.wikipedia.org/wiki/Simon\_S... https://www.linkedin.com/in/simon-str... "A new approach to solving the feature-binding problem in primate vision" https://royalsocietypublishing.org/do... James B. Isbister, Akihiro Eguchi, Nasir Ahmad, Juan M. Galeazzi, Mark J. Buckley and Simon Stringer Simon's department is looking for funding, please do get in touch with him if you can facilitate this.  \#machinelearning \#neuroscience}
}

@incollection{maclennanAnalogComputation2009,
  title = {Analog {{Computation}}},
  booktitle = {Encyclopedia of {{Complexity}} and {{Systems Science}}},
  author = {MacLennan, Bruce J.},
  editor = {Meyers, Robert A.},
  date = {2009},
  pages = {271--294},
  publisher = {Springer},
  location = {New York, NY},
  doi = {10.1007/978-0-387-30440-3_19},
  url = {https://doi.org/10.1007/978-0-387-30440-3_19},
  urldate = {2023-10-17},
  isbn = {978-0-387-30440-3},
  langid = {english},
  file = {/Users/marcel/Zotero/storage/7HKCVW4W/MacLennan - 2009 - Analog Computation.pdf}
}

@article{maDiffaquaDifferentiableComputational2021,
  title = {Diffaqua: {{A}} Differentiable Computational Design Pipeline for Soft Underwater Swimmers with Shape Interpolation},
  shorttitle = {Diffaqua},
  author = {Ma, Pingchuan and Du, Tao and Zhang, John Z. and Wu, Kui and Spielberg, Andrew and Katzschmann, Robert K. and Matusik, Wojciech},
  date = {2021},
  journaltitle = {ACM Transactions on Graphics (TOG)},
  volume = {40},
  number = {4},
  pages = {1--14},
  publisher = {ACM New York, NY, USA}
}

@article{maDiffAquaDifferentiableComputational2021,
  title = {{{DiffAqua}}: A Differentiable Computational Design Pipeline for Soft Underwater Swimmers with Shape Interpolation},
  shorttitle = {{{DiffAqua}}},
  author = {Ma, Pingchuan and Du, Tao and Zhang, John Z. and Wu, Kui and Spielberg, Andrew and Katzschmann, Robert K. and Matusik, Wojciech},
  date = {2021-08-31},
  journaltitle = {ACM Transactions on Graphics},
  shortjournal = {ACM Trans. Graph.},
  volume = {40},
  number = {4},
  pages = {1--14},
  issn = {0730-0301, 1557-7368},
  doi = {10.1145/3450626.3459832},
  url = {https://dl.acm.org/doi/10.1145/3450626.3459832},
  urldate = {2023-06-29},
  abstract = {The computational design of soft underwater swimmers is challenging because of the high degrees of freedom in soft-body modeling. In this paper, we present a differentiable pipeline for co-designing a soft swimmer's geometry and controller. Our pipeline unlocks gradient-based algorithms for discovering novel swimmer designs more efficiently than traditional gradient-free solutions. We propose Wasserstein barycenters as a basis for the geometric design of soft underwater swimmers since it is differentiable and can naturally interpolate between bio-inspired base shapes               via               optimal transport. By combining this design space with differentiable simulation and control, we can efficiently optimize a soft underwater swimmer's performance with fewer simulations than baseline methods. We demonstrate the efficacy of our method on various design problems such as fast, stable, and energy-efficient swimming and demonstrate applicability to multi-objective design.},
  langid = {english},
  file = {/Users/marcel/Zotero/storage/ELQ75BM5/Ma et al. - 2021 - DiffAqua a differentiable computational design pi.pdf}
}

@incollection{magnitskiiBifurcationTheoryDynamical2018,
  title = {Bifurcation {{Theory}} of {{Dynamical Chaos}}},
  booktitle = {Chaos {{Theory}}},
  author = {Magnitskii, Nikolai A.},
  date = {2018-03-28},
  publisher = {IntechOpen},
  doi = {10.5772/intechopen.70987},
  url = {https://www.intechopen.com/chapters/57243},
  urldate = {2023-11-10},
  abstract = {The purpose of the present chapter is once again to show on concrete new examples that chaos in one-dimensional unimodal mappings, dynamical chaos in systems of ordinary differential equations, diffusion chaos in systems of the equations with partial derivatives and chaos in Hamiltonian and conservative systems are generated by cascades of bifurcations under universal bifurcation Feigenbaum-Sharkovsky-Magnitskii (FShM) scenario. And all irregular attractors of all such dissipative systems born during realization of such scenario are exclusively singular attractors that are the nonperiodic limited trajectories in finite dimensional or infinitely dimensional phase space any neighborhood of which contains the infinite number of unstable periodic trajectories.},
  isbn = {978-953-51-3946-1},
  langid = {english},
  file = {/Users/marcel/Zotero/storage/M4HWN3PS/Magnitskii - 2018 - Bifurcation Theory of Dynamical Chaos.pdf}
}

@unpublished{mathieuRiemannianContinuousNormalizing2020,
  title = {Riemannian {{Continuous Normalizing Flows}}},
  author = {Mathieu, Emile and Nickel, Maximilian},
  date = {2020-12-09},
  eprint = {2006.10605},
  eprinttype = {arXiv},
  eprintclass = {cs, stat},
  url = {http://arxiv.org/abs/2006.10605},
  urldate = {2021-07-27},
  abstract = {Normalizing flows have shown great promise for modelling flexible probability distributions in a computationally tractable way. However, whilst data is often naturally described on Riemannian manifolds such as spheres, torii, and hyperbolic spaces, most normalizing flows implicitly assume a flat geometry, making them either misspecified or ill-suited in these situations. To overcome this problem, we introduce Riemannian continuous normalizing flows, a model which admits the parametrization of flexible probability measures on smooth manifolds by defining flows as the solution to ordinary differential equations. We show that this approach can lead to substantial improvements on both synthetic and real-world data when compared to standard flows or previously introduced projected flows.},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/marcel/Zotero/storage/7BL75Z5Q/Mathieu and Nickel - 2020 - Riemannian Continuous Normalizing Flows.pdf;/Users/marcel/Zotero/storage/WLWMBIXY/2006.html}
}

@article{mccallumAutomatingConstructionInternet2000,
  title = {Automating the {{Construction}} of {{Internet Portals}} with {{Machine Learning}}},
  author = {McCallum, Andrew Kachites and Nigam, Kamal and Rennie, Jason and Seymore, Kristie},
  date = {2000-07-01},
  journaltitle = {Information Retrieval},
  shortjournal = {Information Retrieval},
  volume = {3},
  number = {2},
  pages = {127--163},
  issn = {1573-7659},
  doi = {10.1023/A:1009953814988},
  url = {https://doi.org/10.1023/A:1009953814988},
  urldate = {2023-02-26},
  abstract = {Domain-specific internet portals are growing in popularity because they gather content from the Web and organize it for easy access, retrieval and search. For example, www.campsearch.com allows complex queries by age, location, cost and specialty over summer camps. This functionality is not possible with general, Web-wide search engines. Unfortunately these portals are difficult and time-consuming to maintain. This paper advocates the use of machine learning techniques to greatly automate the creation and maintenance of domain-specific Internet portals. We describe new research in reinforcement learning, information extraction and text classification that enables efficient spidering, the identification of informative text segments, and the population of topic hierarchies. Using these techniques, we have built a demonstration system: a portal for computer science research papers. It already contains over 50,000 papers and is publicly available at www.cora.justresearch.com. These techniques are widely applicable to portal creation in other domains.},
  langid = {english},
  file = {/Users/marcel/Zotero/storage/EV8WMVK8/McCallum et al. - 2000 - Automating the Construction of Internet Portals wi.pdf}
}

@article{mccarthyProposalDartmouthSummer1955,
  title = {A {{Proposal}} for the {{Dartmouth Summer Research Project}} on {{Artificial Intelligence}}, {{August}} 31, 1955},
  author = {McCarthy, John and Minsky, Marvin L. and Rochester, Nathaniel and Shannon, Claude E.},
  date = {1955-08-31},
  journaltitle = {AI Magazine},
  volume = {27},
  number = {4},
  pages = {12--12},
  issn = {2371-9621},
  doi = {10.1609/aimag.v27i4.1904},
  url = {https://ojs.aaai.org/index.php/aimagazine/article/view/1904},
  urldate = {2022-05-01},
  abstract = {The 1956 Dartmouth summer research project on artificial intelligence was initiated by this August 31, 1955 proposal, authored by John McCarthy, Marvin Minsky, Nathaniel Rochester, and Claude Shannon. The original typescript consisted of 17 pages plus a title page. Copies of the typescript are housed in the archives at Dartmouth College and Stanford University. The first 5 papers state the proposal, and the remaining pages give qualifications and interests of the four who proposed the study. In the interest of brevity, this article reproduces only the proposal itself, along with the short autobiographical statements of the proposers.},
  issue = {4},
  langid = {english},
  file = {/Users/marcel/Zotero/storage/W7EZ6N7Q/McCarthy et al. - 2006 - A Proposal for the Dartmouth Summer Research Proje.pdf}
}

@article{mccaughanMultiplexedGradientDescent2023,
  title = {Multiplexed Gradient Descent: {{Fast}} Online Training of Modern Datasets on Hardware Neural Networks without Backpropagation},
  shorttitle = {Multiplexed Gradient Descent},
  author = {McCaughan, Adam N. and Oripov, Bakhrom G. and Ganesh, Natesh and Nam, Sae Woo and Dienstfrey, Andrew and Buckley, Sonia M.},
  date = {2023-06-26},
  journaltitle = {APL Machine Learning},
  shortjournal = {APL Machine Learning},
  volume = {1},
  number = {2},
  pages = {026118},
  issn = {2770-9019},
  doi = {10.1063/5.0157645},
  url = {https://doi.org/10.1063/5.0157645},
  urldate = {2023-10-21},
  abstract = {We present multiplexed gradient descent (MGD), a gradient descent framework designed to easily train analog or digital neural networks in hardware. MGD utilizes zero-order optimization techniques for online training of hardware neural networks. We demonstrate its ability to train neural networks on modern machine learning datasets, including CIFAR-10 and Fashion-MNIST, and compare its performance to backpropagation. Assuming realistic timescales and hardware parameters, our results indicate that these optimization techniques can train a network on emerging hardware platforms orders of magnitude faster than the wall-clock time of training via backpropagation on a standard GPU, even in the presence of imperfect weight updates or device-to-device variations in the hardware. We additionally describe how it can be applied to existing hardware as part of chip-in-the-loop training or integrated directly at the hardware level. Crucially, because the MGD framework is model-free it can be applied to nearly any hardware platform with tunable parameters, and its gradient descent process can be optimized to compensate for specific hardware limitations, such as slow parameter-update speeds or limited input bandwidth.},
  file = {/Users/marcel/Zotero/storage/RZV48ZJ6/McCaughan et al. - 2023 - Multiplexed gradient descent Fast online training of modern datasets on hardware neural networks wi.pdf}
}

@article{mcclellandInteractiveActivationModel1981,
  title = {An Interactive Activation Model of Context Effects in Letter Perception: {{I}}. {{An}} Account of Basic Findings},
  shorttitle = {An Interactive Activation Model of Context Effects in Letter Perception},
  author = {McClelland, James L. and Rumelhart, David E.},
  date = {1981},
  journaltitle = {Psychological Review},
  volume = {88},
  number = {5},
  pages = {375--407},
  publisher = {American Psychological Association},
  location = {US},
  issn = {1939-1471},
  doi = {10.1037/0033-295X.88.5.375},
  abstract = {Describes a model in which perception results from excitatory and inhibitory interactions of detectors for visual features, letters, and words. A visual input excites detectors for visual features in the display and for letters consistent with the active features. Letter detectors in turn excite detectors for consistent words. It is suggested that active word detectors mutually inhibit each other and send feedback to the letter level, strengthening activation and hence perceptibility of their constituent letters. Computer simulation of the model exhibits the perceptual advantage for letters in words over unrelated contexts and is considered consistent with basic facts about word advantage. Most important, the model produces facilitation for letters in pronounceable pseudowords as well as words. Pseudowords activate detectors for words that are consistent with most active letters, and feedback from the activated words strengthens activations of the letters in the pseudoword. The model thus accounts for apparently rule-governed performance without any actual rules. (50 ref) (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  keywords = {Contextual Associations,Letters (Alphabet),Models,Visual Discrimination,Words (Phonetic Units)},
  file = {/Users/marcel/Zotero/storage/TMP6GHKW/1981-31825-001.html}
}

@article{mcculloch1943logical,
  title = {A Logical Calculus of the Ideas Immanent in Nervous Activity},
  author = {McCulloch, Warren S and Pitts, Walter},
  date = {1943},
  journaltitle = {The bulletin of mathematical biophysics},
  volume = {5},
  number = {4},
  pages = {115--133},
  publisher = {Springer},
  url = {https://home.csulb.edu/~cwallis/382/readings/482/mccolloch.logical.calculus.ideas.1943.pdf},
  file = {/Users/marcel/Zotero/storage/MFG4X8VH/McCulloch and Pitts - 1943 - A logical calculus of the ideas immanent in nervou.pdf}
}

@online{mckinzieMM1MethodsAnalysis2024,
  title = {{{MM1}}: {{Methods}}, {{Analysis}} \& {{Insights}} from {{Multimodal LLM Pre-training}}},
  shorttitle = {{{MM1}}},
  author = {McKinzie, Brandon and Gan, Zhe and Fauconnier, Jean-Philippe and Dodge, Sam and Zhang, Bowen and Dufter, Philipp and Shah, Dhruti and Du, Xianzhi and Peng, Futang and Weers, Floris and Belyi, Anton and Zhang, Haotian and Singh, Karanjeet and Kang, Doug and Hè, Hongyu and Schwarzer, Max and Gunter, Tom and Kong, Xiang and Zhang, Aonan and Wang, Jianyu and Wang, Chong and Du, Nan and Lei, Tao and Wiseman, Sam and Lee, Mark and Wang, Zirui and Pang, Ruoming and Grasch, Peter and Toshev, Alexander and Yang, Yinfei},
  date = {2024-03-14},
  eprint = {2403.09611},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2403.09611},
  url = {http://arxiv.org/abs/2403.09611},
  urldate = {2024-03-16},
  abstract = {In this work, we discuss building performant Multimodal Large Language Models (MLLMs). In particular, we study the importance of various architecture components and data choices. Through careful and comprehensive ablations of the image encoder, the vision language connector, and various pre-training data choices, we identified several crucial design lessons. For example, we demonstrate that for large-scale multimodal pre-training using a careful mix of image-caption, interleaved image-text, and text-only data is crucial for achieving state-of-the-art (SOTA) few-shot results across multiple benchmarks, compared to other published pre-training results. Further, we show that the image encoder together with image resolution and the image token count has substantial impact, while the vision-language connector design is of comparatively negligible importance. By scaling up the presented recipe, we build MM1, a family of multimodal models up to 30B parameters, consisting of both dense models and mixture-of-experts (MoE) variants, that are SOTA in pre-training metrics and achieve competitive performance after supervised fine-tuning on a range of established multimodal benchmarks. Thanks to large-scale pre-training, MM1 enjoys appealing properties such as enhanced in-context learning, and multi-image reasoning, enabling few-shot chain-of-thought prompting.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computation and Language,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning},
  file = {/Users/marcel/Zotero/storage/CLWTPQPA/McKinzie et al. - 2024 - MM1 Methods, Analysis & Insights from Multimodal LLM Pre-training.pdf;/Users/marcel/Zotero/storage/T47VWAAE/2403.html}
}

@inproceedings{mihalceaWikifyLinkingDocuments2007,
  title = {Wikify! Linking Documents to Encyclopedic Knowledge},
  booktitle = {Proceedings of the Sixteenth {{ACM}} Conference on {{Conference}} on Information and Knowledge Management},
  author = {Mihalcea, Rada and Csomai, Andras},
  date = {2007-11-06},
  series = {{{CIKM}} '07},
  pages = {233--242},
  publisher = {Association for Computing Machinery},
  location = {New York, NY, USA},
  doi = {10.1145/1321440.1321475},
  url = {https://dl.acm.org/doi/10.1145/1321440.1321475},
  urldate = {2024-03-14},
  abstract = {This paper introduces the use of Wikipedia as a resource for automatic keyword extraction and word sense disambiguation, and shows how this online encyclopedia can be used to achieve state-of-the-art results on both these tasks. The paper also shows how the two methods can be combined into a system able to automatically enrich a text with links to encyclopedic knowledge. Given an input document, the system identifies the important concepts in the text and automatically links these concepts to the corresponding Wikipedia pages. Evaluations of the system show that the automatic annotations are reliable and hardly distinguishable from manual annotations.},
  isbn = {978-1-59593-803-9},
  keywords = {keyword extraction,semantic annotation,wikipedia,word sense disambiguation},
  file = {/Users/marcel/Zotero/storage/GKAX99P8/Mihalcea and Csomai - 2007 - Wikify! linking documents to encyclopedic knowledge.pdf}
}

@online{mildenhallNeRFRepresentingScenes2020,
  title = {{{NeRF}}: {{Representing Scenes}} as {{Neural Radiance Fields}} for {{View Synthesis}}},
  shorttitle = {{{NeRF}}},
  author = {Mildenhall, Ben and Srinivasan, Pratul P. and Tancik, Matthew and Barron, Jonathan T. and Ramamoorthi, Ravi and Ng, Ren},
  date = {2020-08-03},
  eprint = {2003.08934},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2003.08934},
  url = {http://arxiv.org/abs/2003.08934},
  urldate = {2022-07-31},
  abstract = {We present a method that achieves state-of-the-art results for synthesizing novel views of complex scenes by optimizing an underlying continuous volumetric scene function using a sparse set of input views. Our algorithm represents a scene using a fully-connected (non-convolutional) deep network, whose input is a single continuous 5D coordinate (spatial location \$(x,y,z)\$ and viewing direction \$(\textbackslash theta, \textbackslash phi)\$) and whose output is the volume density and view-dependent emitted radiance at that spatial location. We synthesize views by querying 5D coordinates along camera rays and use classic volume rendering techniques to project the output colors and densities into an image. Because volume rendering is naturally differentiable, the only input required to optimize our representation is a set of images with known camera poses. We describe how to effectively optimize neural radiance fields to render photorealistic novel views of scenes with complicated geometry and appearance, and demonstrate results that outperform prior work on neural rendering and view synthesis. View synthesis results are best viewed as videos, so we urge readers to view our supplementary video for convincing comparisons.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Graphics},
  file = {/Users/marcel/Zotero/storage/GWM5FPJD/Mildenhall et al. - 2020 - NeRF Representing Scenes as Neural Radiance Field.pdf;/Users/marcel/Zotero/storage/2689R62Y/2003.html}
}

@online{mildenhallNeRFRepresentingScenes2020a,
  title = {{{NeRF}}: {{Representing Scenes}} as {{Neural Radiance Fields}} for {{View Synthesis}}},
  shorttitle = {{{NeRF}}},
  author = {Mildenhall, Ben and Srinivasan, Pratul P. and Tancik, Matthew and Barron, Jonathan T. and Ramamoorthi, Ravi and Ng, Ren},
  date = {2020-08-03},
  eprint = {2003.08934},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2003.08934},
  url = {http://arxiv.org/abs/2003.08934},
  urldate = {2022-09-30},
  abstract = {We present a method that achieves state-of-the-art results for synthesizing novel views of complex scenes by optimizing an underlying continuous volumetric scene function using a sparse set of input views. Our algorithm represents a scene using a fully-connected (non-convolutional) deep network, whose input is a single continuous 5D coordinate (spatial location \$(x,y,z)\$ and viewing direction \$(\textbackslash theta, \textbackslash phi)\$) and whose output is the volume density and view-dependent emitted radiance at that spatial location. We synthesize views by querying 5D coordinates along camera rays and use classic volume rendering techniques to project the output colors and densities into an image. Because volume rendering is naturally differentiable, the only input required to optimize our representation is a set of images with known camera poses. We describe how to effectively optimize neural radiance fields to render photorealistic novel views of scenes with complicated geometry and appearance, and demonstrate results that outperform prior work on neural rendering and view synthesis. View synthesis results are best viewed as videos, so we urge readers to view our supplementary video for convincing comparisons.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Graphics},
  file = {/Users/marcel/Zotero/storage/K6WGFE29/Mildenhall et al. - 2020 - NeRF Representing Scenes as Neural Radiance Field.pdf;/Users/marcel/Zotero/storage/TTG7G6GE/2003.html}
}

@unpublished{millidgePredictiveCodingApproximates2020,
  title = {Predictive {{Coding Approximates Backprop}} along {{Arbitrary Computation Graphs}}},
  author = {Millidge, Beren and Tschantz, Alexander and Buckley, Christopher L.},
  date = {2020-10-05},
  eprint = {2006.04182},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2006.04182},
  urldate = {2022-05-01},
  abstract = {Backpropagation of error (backprop) is a powerful algorithm for training machine learning architectures through end-to-end differentiation. However, backprop is often criticised for lacking biological plausibility. Recently, it has been shown that backprop in multilayer-perceptrons (MLPs) can be approximated using predictive coding, a biologically-plausible process theory of cortical computation which relies only on local and Hebbian updates. The power of backprop, however, lies not in its instantiation in MLPs, but rather in the concept of automatic differentiation which allows for the optimisation of any differentiable program expressed as a computation graph. Here, we demonstrate that predictive coding converges asymptotically (and in practice rapidly) to exact backprop gradients on arbitrary computation graphs using only local learning rules. We apply this result to develop a straightforward strategy to translate core machine learning architectures into their predictive coding equivalents. We construct predictive coding CNNs, RNNs, and the more complex LSTMs, which include a non-layer-like branching internal graph structure and multiplicative interactions. Our models perform equivalently to backprop on challenging machine learning benchmarks, while utilising only local and (mostly) Hebbian plasticity. Our method raises the potential that standard machine learning algorithms could in principle be directly implemented in neural circuitry, and may also contribute to the development of completely distributed neuromorphic architectures.},
  keywords = {Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing},
  file = {/Users/marcel/Zotero/storage/XK7MBX4K/Millidge et al. - 2020 - Predictive Coding Approximates Backprop along Arbi.pdf;/Users/marcel/Zotero/storage/LQ4RJRQH/2006.html}
}

@inproceedings{milneLearningLinkWikipedia2008,
  title = {Learning to Link with Wikipedia},
  booktitle = {Proceedings of the 17th {{ACM}} Conference on {{Information}} and Knowledge Management},
  author = {Milne, David and Witten, Ian H.},
  date = {2008-10-26},
  series = {{{CIKM}} '08},
  pages = {509--518},
  publisher = {Association for Computing Machinery},
  location = {New York, NY, USA},
  doi = {10.1145/1458082.1458150},
  url = {https://dl.acm.org/doi/10.1145/1458082.1458150},
  urldate = {2024-03-14},
  abstract = {This paper describes how to automatically cross-reference documents with Wikipedia: the largest knowledge base ever known. It explains how machine learning can be used to identify significant terms within unstructured text, and enrich it with links to the appropriate Wikipedia articles. The resulting link detector and disambiguator performs very well, with recall and precision of almost 75\%. This performance is constant whether the system is evaluated on Wikipedia articles or "real world" documents. This work has implications far beyond enriching documents with explanatory links. It can provide structured knowledge about any unstructured fragment of text. Any task that is currently addressed with bags of words - indexing, clustering, retrieval, and summarization to name a few - could use the techniques described here to draw on a vast network of concepts and semantics.},
  isbn = {978-1-59593-991-3},
  keywords = {data mining,semantic annotation,wikipedia,word sense disambiguation},
  file = {/Users/marcel/Zotero/storage/999JVSHH/Milne and Witten - 2008 - Learning to link with wikipedia.pdf}
}

@book{minskyPerceptronsIntroductionComputational1969,
  title = {Perceptrons: {{An Introduction}} to {{Computational Geometry}}},
  shorttitle = {Perceptrons},
  author = {Minsky, Marvin and Papert, Seymour A.},
  date = {1969-01-15},
  publisher = {MIT Press},
  location = {Cambridge, MA, USA},
  isbn = {978-0-262-13043-1},
  langid = {english},
  pagetotal = {258},
  file = {/Users/marcel/Zotero/storage/NR5SNYHY/Minsky and Papert - 1969 - Perceptrons An Introduction to Computational Geom.pdf}
}

@article{minSoftConSimulationControl2019,
  title = {{{SoftCon}}: Simulation and Control of Soft-Bodied Animals with Biomimetic Actuators},
  shorttitle = {{{SoftCon}}},
  author = {Min, Sehee and Won, Jungdam and Lee, Seunghwan and Park, Jungnam and Lee, J.},
  date = {2019-11-08},
  journaltitle = {ACM Transactions on Graphics},
  shortjournal = {ACM Transactions on Graphics},
  volume = {38},
  pages = {1--12},
  doi = {10.1145/3355089.3356497},
  abstract = {We present a novel and general framework for the design and control of underwater soft-bodied animals. The whole body of an animal consisting of soft tissues is modeled by tetrahedral and triangular FEM meshes. The contraction of muscles embedded in the soft tissues actuates the body and limbs to move. We present a novel muscle excitation model that mimics the anatomy of muscular hydrostats and their muscle excitation patterns. Our deep reinforcement learning algorithm equipped with the muscle excitation model successfully learned the control policy of soft-bodied animals, which can be physically simulated in real-time, controlled interactively, and resilient to external perturbations. We demonstrate the effectiveness of our approach with various simulated animals including octopuses, lampreys, starfishes, stingrays and cuttlefishes. They learn diverse behaviors such as swimming, grasping, and escaping from a bottle. We also implemented a simple user interface system that allows the user to easily create their creatures.}
}

@article{minSoftConSimulationControl2019a,
  title = {{{SoftCon}}: Simulation and Control of Soft-Bodied Animals with Biomimetic Actuators},
  shorttitle = {{{SoftCon}}},
  author = {Min, Sehee and Won, Jungdam and Lee, Seunghwan and Park, Jungnam and Lee, Jehee},
  date = {2019-11-08},
  journaltitle = {ACM Transactions on Graphics},
  shortjournal = {ACM Trans. Graph.},
  volume = {38},
  number = {6},
  pages = {208:1--208:12},
  issn = {0730-0301},
  doi = {10.1145/3355089.3356497},
  url = {https://dl.acm.org/doi/10.1145/3355089.3356497},
  urldate = {2023-06-29},
  abstract = {We present a novel and general framework for the design and control of underwater soft-bodied animals. The whole body of an animal consisting of soft tissues is modeled by tetrahedral and triangular FEM meshes. The contraction of muscles embedded in the soft tissues actuates the body and limbs to move. We present a novel muscle excitation model that mimics the anatomy of muscular hydrostats and their muscle excitation patterns. Our deep reinforcement learning algorithm equipped with the muscle excitation model successfully learned the control policy of soft-bodied animals, which can be physically simulated in real-time, controlled interactively, and resilient to external perturbations. We demonstrate the effectiveness of our approach with various simulated animals including octopuses, lampreys, starfishes, stingrays and cuttlefishes. They learn diverse behaviors such as swimming, grasping, and escaping from a bottle. We also implemented a simple user interface system that allows the user to easily create their creatures.},
  keywords = {character animation,deformable character,finite element method,optimal control,physics-based control,reinforcement learning,soft-bodied animal},
  file = {/Users/marcel/Zotero/storage/TD4ZA334/Min et al. - 2019 - SoftCon simulation and control of soft-bodied ani.pdf}
}

@report{mitchellNeedBiasesLearning1980,
  title = {The {{Need}} for {{Biases}} in {{Learning Generalizations}}},
  author = {Mitchell, Tom M.},
  date = {1980},
  abstract = {This paper defines precisely the notion of bias in generalization problems, then shows that biases are necessary for the inductive leap. Classes of justifiable biases are considered, and the relationship between bias and domain-independence is considered},
  file = {/Users/marcel/Zotero/storage/WUTLMF9M/Mitchell - 1980 - The Need for Biases in Learning Generalizations.pdf;/Users/marcel/Zotero/storage/LLGYVVCL/summary.html}
}

@online{mittalSelfSupervisedPointCloud2021,
  title = {Self-{{Supervised Point Cloud Completion}} via {{Inpainting}}},
  author = {Mittal, Himangi and Okorn, Brian and Jangid, Arpit and Held, David},
  date = {2021-11-20},
  eprint = {2111.10701},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2111.10701},
  url = {http://arxiv.org/abs/2111.10701},
  urldate = {2022-09-30},
  abstract = {When navigating in urban environments, many of the objects that need to be tracked and avoided are heavily occluded. Planning and tracking using these partial scans can be challenging. The aim of this work is to learn to complete these partial point clouds, giving us a full understanding of the object's geometry using only partial observations. Previous methods achieve this with the help of complete, ground-truth annotations of the target objects, which are available only for simulated datasets. However, such ground truth is unavailable for real-world LiDAR data. In this work, we present a self-supervised point cloud completion algorithm, PointPnCNet, which is trained only on partial scans without assuming access to complete, ground-truth annotations. Our method achieves this via inpainting. We remove a portion of the input data and train the network to complete the missing region. As it is difficult to determine which regions were occluded in the initial cloud and which were synthetically removed, our network learns to complete the full cloud, including the missing regions in the initial partial cloud. We show that our method outperforms previous unsupervised and weakly-supervised methods on both the synthetic dataset, ShapeNet, and real-world LiDAR dataset, Semantic KITTI.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning},
  file = {/Users/marcel/Zotero/storage/EZBFFXLR/Mittal et al. - 2021 - Self-Supervised Point Cloud Completion via Inpaint.pdf;/Users/marcel/Zotero/storage/UPFX7GWW/2111.html}
}

@inproceedings{monilUnderstandingImpactMemory2020,
  title = {Understanding the {{Impact}} of {{Memory Access Patterns}} in {{Intel Processors}}},
  booktitle = {2020 {{IEEE}}/{{ACM Workshop}} on {{Memory Centric High Performance Computing}} ({{MCHPC}})},
  author = {Monil, Mohammad Alaul Haque and Lee, Seyong and Vetter, Jeffrey S. and Malony, Allen D.},
  date = {2020-11},
  pages = {52--61},
  doi = {10.1109/MCHPC51950.2020.00012},
  abstract = {Because of increasing complexity in the memory hierarchy, predicting the performance of a given application in a given processor is becoming more difficult. The problem is worsened by the fact that the hardware needed to deal with more complex memory traffic also affects energy consumption. Moreover, in a heterogeneous system with shared main memory, the memory traffic between the last level cache (LLC) and the memory creates contention between other processors and accelerator devices. For these reasons, it is important to investigate and understand the impact of different memory access patterns on the memory system. This study investigates the interplay between Intel processors' memory hierarchy and different memory access patterns in applications. The authors explore sequential streaming and strided memory access patterns with the objective of predicting LLC-dynamic random access memory (DRAM) traffic for a given application in given Intel architectures. Moreover, the impact of prefetching is also investigated in this study. Experiments with different Intel micro-architectures uncover mechanisms to predict LLC-DRAM traffic that can yield up to 99\% accuracy for sequential streaming access patterns and up to 95\% accuracy for strided access patterns.},
  eventtitle = {2020 {{IEEE}}/{{ACM Workshop}} on {{Memory Centric High Performance Computing}} ({{MCHPC}})},
  keywords = {Broadwell,Cascade Lake,Hardware,Intel,Lakes,memory access patterns,Memory management,memory traffic prediction,Predictive models,Prefetching,Program processors,Random access memory,Sky Lake},
  file = {/Users/marcel/Zotero/storage/9SXQXGK4/Monil et al. - 2020 - Understanding the Impact of Memory Access Patterns.pdf}
}

@article{mullerInstantNeuralGraphics2022,
  title = {Instant Neural Graphics Primitives with a Multiresolution Hash Encoding},
  author = {Müller, Thomas and Evans, Alex and Schied, Christoph and Keller, Alexander},
  date = {2022-07},
  journaltitle = {ACM Transactions on Graphics},
  shortjournal = {ACM Trans. Graph.},
  volume = {41},
  number = {4},
  pages = {1--15},
  issn = {0730-0301, 1557-7368},
  doi = {10.1145/3528223.3530127},
  url = {https://dl.acm.org/doi/10.1145/3528223.3530127},
  urldate = {2022-09-30},
  abstract = {Neural graphics primitives, parameterized by fully connected neural networks, can be costly to train and evaluate. We reduce this cost with a versatile new input encoding that permits the use of a smaller network without sacrificing quality, thus significantly reducing the number of floating point and memory access operations: a small neural network is augmented by a multiresolution hash table of trainable feature vectors whose values are optimized through stochastic gradient descent. The multiresolution structure allows the network to disambiguate hash collisions, making for a simple architecture that is trivial to parallelize on modern GPUs. We leverage this parallelism by implementing the whole system using fully-fused CUDA kernels with a focus on minimizing wasted bandwidth and compute operations. We achieve a combined speedup of several orders of magnitude, enabling training of high-quality neural graphics primitives in a matter of seconds, and rendering in tens of milliseconds at a resolution of 1920×1080.},
  langid = {english},
  file = {/Users/marcel/Zotero/storage/HFNDNBBD/Müller et al. - 2022 - Instant neural graphics primitives with a multires.pdf}
}

@online{musaelianLearningLocalEquivariant2022,
  title = {Learning {{Local Equivariant Representations}} for {{Large-Scale Atomistic Dynamics}}},
  author = {Musaelian, Albert and Batzner, Simon and Johansson, Anders and Sun, Lixin and Owen, Cameron J. and Kornbluth, Mordechai and Kozinsky, Boris},
  date = {2022-04-11},
  eprint = {2204.05249},
  eprinttype = {arXiv},
  eprintclass = {cond-mat, physics:physics},
  doi = {10.48550/arXiv.2204.05249},
  url = {http://arxiv.org/abs/2204.05249},
  urldate = {2023-01-10},
  abstract = {A simultaneously accurate and computationally efficient parametrization of the energy and atomic forces of molecules and materials is a long-standing goal in the natural sciences. In pursuit of this goal, neural message passing has lead to a paradigm shift by describing many-body correlations of atoms through iteratively passing messages along an atomistic graph. This propagation of information, however, makes parallel computation difficult and limits the length scales that can be studied. Strictly local descriptor-based methods, on the other hand, can scale to large systems but do not currently match the high accuracy observed with message passing approaches. This work introduces Allegro, a strictly local equivariant deep learning interatomic potential that simultaneously exhibits excellent accuracy and scalability of parallel computation. Allegro learns many-body functions of atomic coordinates using a series of tensor products of learned equivariant representations, but without relying on message passing. Allegro obtains improvements over state-of-the-art methods on the QM9 and revised MD-17 data sets. A single tensor product layer is shown to outperform existing deep message passing neural networks and transformers on the QM9 benchmark. Furthermore, Allegro displays remarkable generalization to out-of-distribution data. Molecular dynamics simulations based on Allegro recover structural and kinetic properties of an amorphous phosphate electrolyte in excellent agreement with first principles calculations. Finally, we demonstrate the parallel scaling of Allegro with a dynamics simulation of 100 million atoms.},
  pubstate = {prepublished},
  keywords = {Computer Science - Machine Learning,Condensed Matter - Materials Science,Physics - Chemical Physics,Physics - Computational Physics},
  file = {/Users/marcel/Zotero/storage/IYBDH3ND/Musaelian et al. - 2022 - Learning Local Equivariant Representations for Lar.pdf;/Users/marcel/Zotero/storage/4S6Y8KGP/2204.html}
}

@article{narasimhanFourierHeatConduction1999,
  title = {Fourier’s Heat Conduction Equation: {{History}}, Influence, and Connections},
  shorttitle = {Fourier’s Heat Conduction Equation},
  author = {Narasimhan, T. N.},
  date = {1999-09-01},
  journaltitle = {Proceedings of the Indian Academy of Sciences - Earth and Planetary Sciences},
  shortjournal = {Proc. Indian Acad. Sci. (Earth Planet Sci.)},
  volume = {108},
  number = {3},
  pages = {117--148},
  issn = {0973-774X},
  doi = {10.1007/BF02842327},
  url = {https://doi.org/10.1007/BF02842327},
  urldate = {2022-09-26},
  abstract = {The equation describing the conduction of heat in solids has, over the past two centuries, proved to be a powerful tool for analyzing the dynamic motion of heat as well as for solving an enormous array of diffusion-type problems in physical sciences, biological sciences, earth sciences, and social sciences. This equation was formulated at the beginning of the nineteenth century by one of the most gifted scholars of modern science, Joseph Fourier of France. A study of the historical context in which Fourier made his remarkable contribution and the subsequent impact his work has had on the development of modern science is as fascinating as it is educational. This paper is an attempt to present a picture of how certain ideas initially led to Fourier’s development of the heat equation and how, subsequently, Fourier’s work directly influenced and inspired others to use the heat diffusion model to describe other dynamic physical systems. Conversely, others concerned with the study of random processes found that the equations governing such random processes reduced, in the limit, to Fourier’s equation of heat diffusion. In the process of developing the flow of ideas, the paper also presents, to the extent possible, an account of the history and personalities involved.},
  langid = {english},
  keywords = {diffusion,Fourier,history},
  file = {/Users/marcel/Zotero/storage/58PI4UWD/Narasimhan - 1999 - Fourier’s heat conduction equation History, influ.pdf}
}

@thesis{nascenziGradientbasedDesignOptimization2020,
  title = {Gradient-Based Design Optimization Using {{CAD-based}} Parameterization},
  author = {Nascenzi, Thomas Richard},
  date = {2020},
  institution = {UC San Diego},
  url = {https://escholarship.org/uc/item/8rx2900b},
  urldate = {2022-12-15},
  abstract = {Reconciling optimized designs with the original model can be a time-consuming process. This thesis presents a process for gradient-based optimization using CAD-based parameterization that avoids the reconciliation process by directly altering CAD parameters and automatically updating the design. However, the complexities surrounding most commercial CAD tools make analytically obtaining design sensitivities necessary for gradient-based optimization virtually impossible. The value of this process lies in its ability to numerically compute design sensitivities.This is done with the use of an intermediary surface discretization of the model called the master-mesh. The master-mesh maintains continuity as CAD parameters change through the use of a mesh smoothing process consisting of two optimizations. This smoothing process ensures that the master-mesh deforms smoothly with the design. Other meshes can be derived from the master-mesh, and therefore, can also deform smoothly with the design. This allows for the finite-difference method to be used to calculate their gradients.This master-mesh is demonstrated with three distinct applications. The first application consists of an aerodynamic optimization of a wing designed with a custom geometry engine. The second application consists of an aerodynamic shape optimization of a jet plug nozzle designed in CATIA V5. The third application consists of an aerostructural optimization of a wing designed in FreeCAD.},
  langid = {english},
  file = {/Users/marcel/Zotero/storage/VE33HKWC/Nascenzi - 2020 - Gradient-based design optimization using CAD-based.pdf}
}

@online{navaFastAquaticSwimmer2022,
  title = {Fast {{Aquatic Swimmer Optimization}} with {{Differentiable Projective Dynamics}} and {{Neural Network Hydrodynamic Models}}},
  author = {Nava, Elvis and Zhang, John Z. and Michelis, Mike Y. and Du, Tao and Ma, Pingchuan and Grewe, Benjamin F. and Matusik, Wojciech and Katzschmann, Robert K.},
  date = {2022-06-22},
  eprint = {2204.12584},
  eprinttype = {arXiv},
  eprintclass = {physics},
  doi = {10.48550/arXiv.2204.12584},
  url = {http://arxiv.org/abs/2204.12584},
  urldate = {2022-12-15},
  abstract = {Aquatic locomotion is a classic fluid-structure interaction (FSI) problem of interest to biologists and engineers. Solving the fully coupled FSI equations for incompressible Navier-Stokes and finite elasticity is computationally expensive. Optimizing robotic swimmer design within such a system generally involves cumbersome, gradient-free procedures on top of the already costly simulation. To address this challenge we present a novel, fully differentiable hybrid approach to FSI that combines a 2D direct numerical simulation for the deformable solid structure of the swimmer and a physics-constrained neural network surrogate to capture hydrodynamic effects of the fluid. For the deformable solid simulation of the swimmer's body, we use state-of-the-art techniques from the field of computer graphics to speed up the finite-element method (FEM). For the fluid simulation, we use a U-Net architecture trained with a physics-based loss function to predict the flow field at each time step. The pressure and velocity field outputs from the neural network are sampled around the boundary of our swimmer using an immersed boundary method (IBM) to compute its swimming motion accurately and efficiently. We demonstrate the computational efficiency and differentiability of our hybrid simulator on a 2D carangiform swimmer. Due to differentiability, the simulator can be used for computational design of controls for soft bodies immersed in fluids via direct gradient-based optimization.},
  pubstate = {prepublished},
  keywords = {Computer Science - Machine Learning,Computer Science - Robotics,Physics - Fluid Dynamics},
  file = {/Users/marcel/Zotero/storage/AYR9G9NB/Nava et al. - 2022 - Fast Aquatic Swimmer Optimization with Differentia.pdf;/Users/marcel/Zotero/storage/P96UK3QH/2204.html}
}

@inproceedings{navaFastAquaticSwimmer2022a,
  title = {Fast Aquatic Swimmer Optimization with Differentiable Projective Dynamics and Neural Network Hydrodynamic Models},
  booktitle = {International {{Conference}} on {{Machine Learning}}},
  author = {Nava, Elvis and Zhang, John Z. and Michelis, Mike Yan and Du, Tao and Ma, Pingchuan and Grewe, Benjamin F. and Matusik, Wojciech and Katzschmann, Robert Kevin},
  date = {2022},
  pages = {16413--16427},
  publisher = {PMLR}
}

@inproceedings{navaFastAquaticSwimmer2022b,
  title = {Fast {{Aquatic Swimmer Optimization}} with {{Differentiable Projective Dynamics}} and {{Neural Network Hydrodynamic Models}}},
  booktitle = {Proceedings of the 39th {{International Conference}} on {{Machine Learning}}},
  author = {Nava, Elvis and Zhang, John Z. and Michelis, Mike Yan and Du, Tao and Ma, Pingchuan and Grewe, Benjamin F. and Matusik, Wojciech and Katzschmann, Robert Kevin},
  date = {2022-06-28},
  pages = {16413--16427},
  publisher = {PMLR},
  issn = {2640-3498},
  url = {https://proceedings.mlr.press/v162/nava22a.html},
  urldate = {2023-06-29},
  abstract = {Aquatic locomotion is a classic fluid-structure interaction (FSI) problem of interest to biologists and engineers. Solving the fully coupled FSI equations for incompressible Navier-Stokes and finite elasticity is computationally expensive. Optimizing robotic swimmer design within such a system generally involves cumbersome, gradient-free procedures on top of the already costly simulation. To address this challenge we present a novel, fully differentiable hybrid approach to FSI that combines a 2D direct numerical simulation for the deformable solid structure of the swimmer and a physics-constrained neural network surrogate to capture hydrodynamic effects of the fluid. For the deformable solid simulation of the swimmer’s body, we use state-of-the-art techniques from the field of computer graphics to speed up the finite-element method (FEM). For the fluid simulation, we use a U-Net architecture trained with a physics-based loss function to predict the flow field at each time step. The pressure and velocity field outputs from the neural network are sampled around the boundary of our swimmer using an immersed boundary method (IBM) to compute its swimming motion accurately and efficiently. We demonstrate the computational efficiency and differentiability of our hybrid simulator on a 2D carangiform swimmer. Due to differentiability, the simulator can be used for computational design of controls for soft bodies immersed in fluids via direct gradient-based optimization.},
  eventtitle = {International {{Conference}} on {{Machine Learning}}},
  langid = {english},
  file = {/Users/marcel/Zotero/storage/3AU6MFYF/Nava et al. - 2022 - Fast Aquatic Swimmer Optimization with Differentia.pdf}
}

@article{NeuralHarmonicFlow,
  title = {Neural {{Harmonic Flow}} on {{Graphs}}},
  file = {/Users/marcel/Zotero/storage/LGDF7B2H/Neural Harmonic Flow on Graphs.pdf}
}

@online{neurotrayHowManyCalculations2021,
  title = {How {{Many Calculations Per Second Can The Human Brain Do}}? - {{NeuroTray}}},
  shorttitle = {How {{Many Calculations Per Second Can The Human Brain Do}}?},
  author = {{neurotray}},
  date = {2021-02-14T05:47:25+00:00},
  url = {https://neurotray.com/how-many-calculations-per-second-can-the-human-brain-do/},
  urldate = {2022-05-02},
  abstract = {In this post we are going to answer the question ‘’How many calculations per second can the human brain do?’’ We will explain to you how the human brain has},
  langid = {american},
  file = {/Users/marcel/Zotero/storage/AVC79ZAE/how-many-calculations-per-second-can-the-human-brain-do.html}
}

@book{newmanStructureDynamicsNetworks2006,
  title = {The {{Structure}} and {{Dynamics}} of {{Networks}}:},
  shorttitle = {The {{Structure}} and {{Dynamics}} of {{Networks}}},
  author = {Newman, Mark and Barabási, Albert-László and Watts, Duncan J.},
  date = {2006-05-07},
  eprint = {6LvQIIP0TQ8C},
  eprinttype = {googlebooks},
  publisher = {Princeton University Press},
  abstract = {From the Internet to networks of friendship, disease transmission, and even terrorism, the concept--and the reality--of networks has come to pervade modern society. But what exactly is a network? What different types of networks are there? Why are they interesting, and what can they tell us? In recent years, scientists from a range of fields--including mathematics, physics, computer science, sociology, and biology--have been pursuing these questions and building a new "science of networks." This book brings together for the first time a set of seminal articles representing research from across these disciplines. It is an ideal sourcebook for the key research in this fast-growing field. The book is organized into four sections, each preceded by an editors' introduction summarizing its contents and general theme. The first section sets the stage by discussing some of the historical antecedents of contemporary research in the area. From there the book moves to the empirical side of the science of networks before turning to the foundational modeling ideas that have been the focus of much subsequent activity. The book closes by taking the reader to the cutting edge of network science--the relationship between network structure and system dynamics. From network robustness to the spread of disease, this section offers a potpourri of topics on this rapidly expanding frontier of the new science.},
  isbn = {978-0-691-11357-9},
  langid = {english},
  pagetotal = {596},
  keywords = {Computers / Networking / General,Mathematics / Applied,Mathematics / Discrete Mathematics,Science / Chaotic Behavior in Systems}
}

@online{nicholGLIDEPhotorealisticImage2022,
  title = {{{GLIDE}}: {{Towards Photorealistic Image Generation}} and {{Editing}} with {{Text-Guided Diffusion Models}}},
  shorttitle = {{{GLIDE}}},
  author = {Nichol, Alex and Dhariwal, Prafulla and Ramesh, Aditya and Shyam, Pranav and Mishkin, Pamela and McGrew, Bob and Sutskever, Ilya and Chen, Mark},
  date = {2022-03-08},
  eprint = {2112.10741},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2112.10741},
  url = {http://arxiv.org/abs/2112.10741},
  urldate = {2022-07-31},
  abstract = {Diffusion models have recently been shown to generate high-quality synthetic images, especially when paired with a guidance technique to trade off diversity for fidelity. We explore diffusion models for the problem of text-conditional image synthesis and compare two different guidance strategies: CLIP guidance and classifier-free guidance. We find that the latter is preferred by human evaluators for both photorealism and caption similarity, and often produces photorealistic samples. Samples from a 3.5 billion parameter text-conditional diffusion model using classifier-free guidance are favored by human evaluators to those from DALL-E, even when the latter uses expensive CLIP reranking. Additionally, we find that our models can be fine-tuned to perform image inpainting, enabling powerful text-driven image editing. We train a smaller model on a filtered dataset and release the code and weights at https://github.com/openai/glide-text2im.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Graphics,Computer Science - Machine Learning},
  file = {/Users/marcel/Zotero/storage/3C869CBV/Nichol et al. - 2022 - GLIDE Towards Photorealistic Image Generation and.pdf;/Users/marcel/Zotero/storage/3B34IMYE/2112.html}
}

@online{nicholImprovedDenoisingDiffusion2021,
  title = {Improved {{Denoising Diffusion Probabilistic Models}}},
  author = {Nichol, Alex and Dhariwal, Prafulla},
  date = {2021-02-18},
  eprint = {2102.09672},
  eprinttype = {arXiv},
  eprintclass = {cs, stat},
  doi = {10.48550/arXiv.2102.09672},
  url = {http://arxiv.org/abs/2102.09672},
  urldate = {2022-07-11},
  abstract = {Denoising diffusion probabilistic models (DDPM) are a class of generative models which have recently been shown to produce excellent samples. We show that with a few simple modifications, DDPMs can also achieve competitive log-likelihoods while maintaining high sample quality. Additionally, we find that learning variances of the reverse diffusion process allows sampling with an order of magnitude fewer forward passes with a negligible difference in sample quality, which is important for the practical deployment of these models. We additionally use precision and recall to compare how well DDPMs and GANs cover the target distribution. Finally, we show that the sample quality and likelihood of these models scale smoothly with model capacity and training compute, making them easily scalable. We release our code at https://github.com/openai/improved-diffusion},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/marcel/Zotero/storage/ZK8PL3KK/Nichol and Dhariwal - 2021 - Improved Denoising Diffusion Probabilistic Models.pdf;/Users/marcel/Zotero/storage/K6MEX45Z/2102.html}
}

@inproceedings{niEnergyefficientMatrixMultiplication2016a,
  title = {An Energy-Efficient Matrix Multiplication Accelerator by Distributed in-Memory Computing on Binary {{RRAM}} Crossbar},
  booktitle = {2016 21st {{Asia}} and {{South Pacific Design Automation Conference}} ({{ASP-DAC}})},
  author = {Ni, Leibin and Wang, Yuhao and Yu, Hao and Yang, Wei and Weng, Chuliang and Zhao, Junfeng},
  date = {2016-01},
  pages = {280--285},
  issn = {2153-697X},
  doi = {10.1109/ASPDAC.2016.7428024},
  url = {https://ieeexplore.ieee.org/document/7428024},
  urldate = {2023-11-11},
  abstract = {Emerging resistive random-access memory (RRAM) can provide non-volatile memory storage but also intrinsic logic for matrix-vector multiplication, which is ideal for low-power and high-throughput data analytics accelerator performed in memory. However, the existing RRAM-based computing device is mainly assumed on a multi-level analog computing, whose result is sensitive to process non-uniformity as well as additional AD- conversion and I/O overhead. This paper explores the data analytics accelerator on binary RRAM-crossbar. Accordingly, one distributed in-memory computing architecture is proposed with design of according component and control protocol. Both memory array and logic accelerator can be implemented by RRAM-crossbar purely in binary, where logic-memory pairs can be distributed with protocol of control bus. Based on numerical results for fingerprint matching that is mapped on the proposed RRAM-crossbar, the proposed architecture has shown 2.86x faster speed, 154x better energy efficiency, and 100x smaller area when compared to the same design by CMOS-based ASIC.},
  eventtitle = {2016 21st {{Asia}} and {{South Pacific Design Automation Conference}} ({{ASP-DAC}})},
  file = {/Users/marcel/Zotero/storage/8GKPCQJC/Ni et al. - 2016 - An energy-efficient matrix multiplication accelerator by distributed in-memory computing on binary R.pdf;/Users/marcel/Zotero/storage/HT34UMWZ/7428024.html}
}

@online{NORAM,
  title = {{{NORAM}}},
  url = {https://www.noram.no/en},
  urldate = {2022-12-09},
  langid = {english},
  organization = {NORAM},
  file = {/Users/marcel/Zotero/storage/HCRGTA8Z/en.html}
}

@online{NVIDIADGXA100,
  title = {{{NVIDIA DGX A100}} : {{The Universal System}} for {{AI Infrastructure}}},
  shorttitle = {{{NVIDIA DGX A100}}},
  url = {https://www.nvidia.com/en-us/data-center/dgx-a100/},
  urldate = {2022-12-01},
  abstract = {Essential Building Block of the AI Data Center \& Offering Best Performance.},
  langid = {american},
  organization = {NVIDIA},
  file = {/Users/marcel/Zotero/storage/RZUMZ7FT/dgx-a100.html}
}

@article{onenNanosecondProtonicProgrammable2022,
  title = {Nanosecond Protonic Programmable Resistors for Analog Deep Learning},
  author = {Onen, Murat and Emond, Nicolas and Wang, Baoming and Zhang, Difei and Ross, Frances M. and Li, Ju and Yildiz, Bilge and family=Alamo, given=Jesús A., prefix=del, useprefix=true},
  date = {2022-07-29},
  journaltitle = {Science},
  volume = {377},
  number = {6605},
  pages = {539--543},
  publisher = {American Association for the Advancement of Science},
  doi = {10.1126/science.abp8064},
  url = {https://www.science.org/doi/10.1126/science.abp8064},
  urldate = {2023-10-21},
  abstract = {Nanoscale ionic programmable resistors for analog deep learning are 1000 times smaller than biological cells, but it is not yet clear how much faster they can be relative to neurons and synapses. Scaling analyses of ionic transport and charge-transfer reaction rates point to operation in the nonlinear regime, where extreme electric fields are present within the solid electrolyte and its interfaces. In this work, we generated silicon-compatible nanoscale protonic programmable resistors with highly desirable characteristics under extreme electric fields. This operation regime enabled controlled shuttling and intercalation of protons in nanoseconds at room temperature in an energy-efficient manner. The devices showed symmetric, linear, and reversible modulation characteristics with many conductance states covering a 20× dynamic range. Thus, the space-time-energy performance of the all–solid-state artificial synapses can greatly exceed that of their biological counterparts.},
  file = {/Users/marcel/Zotero/storage/SMQDHK2B/Onen et al. - 2022 - Nanosecond protonic programmable resistors for analog deep learning.pdf}
}

@unpublished{onkenOTFlowFastAccurate2021,
  title = {{{OT-Flow}}: {{Fast}} and {{Accurate Continuous Normalizing Flows}} via {{Optimal Transport}}},
  shorttitle = {{{OT-Flow}}},
  author = {Onken, Derek and Fung, Samy Wu and Li, Xingjian and Ruthotto, Lars},
  date = {2021-03-23},
  eprint = {2006.00104},
  eprinttype = {arXiv},
  eprintclass = {cs, stat},
  url = {http://arxiv.org/abs/2006.00104},
  urldate = {2021-07-27},
  abstract = {A normalizing flow is an invertible mapping between an arbitrary probability distribution and a standard normal distribution; it can be used for density estimation and statistical inference. Computing the flow follows the change of variables formula and thus requires invertibility of the mapping and an efficient way to compute the determinant of its Jacobian. To satisfy these requirements, normalizing flows typically consist of carefully chosen components. Continuous normalizing flows (CNFs) are mappings obtained by solving a neural ordinary differential equation (ODE). The neural ODE's dynamics can be chosen almost arbitrarily while ensuring invertibility. Moreover, the log-determinant of the flow's Jacobian can be obtained by integrating the trace of the dynamics' Jacobian along the flow. Our proposed OT-Flow approach tackles two critical computational challenges that limit a more widespread use of CNFs. First, OT-Flow leverages optimal transport (OT) theory to regularize the CNF and enforce straight trajectories that are easier to integrate. Second, OT-Flow features exact trace computation with time complexity equal to trace estimators used in existing CNFs. On five high-dimensional density estimation and generative modeling tasks, OT-Flow performs competitively to state-of-the-art CNFs while on average requiring one-fourth of the number of weights with an 8x speedup in training time and 24x speedup in inference.},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/marcel/Zotero/storage/EQ9QSR8B/Onken et al_2021_OT-Flow.pdf;/Users/marcel/Zotero/storage/MVEVUS9L/2006.html}
}

@online{onkenOTFlowFastAccurate2021a,
  title = {{{OT-Flow}}: {{Fast}} and {{Accurate Continuous Normalizing Flows}} via {{Optimal Transport}}},
  shorttitle = {{{OT-Flow}}},
  author = {Onken, Derek and Fung, Samy Wu and Li, Xingjian and Ruthotto, Lars},
  date = {2021-03-23},
  eprint = {2006.00104},
  eprinttype = {arXiv},
  eprintclass = {cs, stat},
  doi = {10.48550/arXiv.2006.00104},
  url = {http://arxiv.org/abs/2006.00104},
  urldate = {2022-11-03},
  abstract = {A normalizing flow is an invertible mapping between an arbitrary probability distribution and a standard normal distribution; it can be used for density estimation and statistical inference. Computing the flow follows the change of variables formula and thus requires invertibility of the mapping and an efficient way to compute the determinant of its Jacobian. To satisfy these requirements, normalizing flows typically consist of carefully chosen components. Continuous normalizing flows (CNFs) are mappings obtained by solving a neural ordinary differential equation (ODE). The neural ODE's dynamics can be chosen almost arbitrarily while ensuring invertibility. Moreover, the log-determinant of the flow's Jacobian can be obtained by integrating the trace of the dynamics' Jacobian along the flow. Our proposed OT-Flow approach tackles two critical computational challenges that limit a more widespread use of CNFs. First, OT-Flow leverages optimal transport (OT) theory to regularize the CNF and enforce straight trajectories that are easier to integrate. Second, OT-Flow features exact trace computation with time complexity equal to trace estimators used in existing CNFs. On five high-dimensional density estimation and generative modeling tasks, OT-Flow performs competitively to state-of-the-art CNFs while on average requiring one-fourth of the number of weights with an 8x speedup in training time and 24x speedup in inference.},
  pubstate = {prepublished},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/marcel/Zotero/storage/6PHMCFLG/Onken et al. - 2021 - OT-Flow Fast and Accurate Continuous Normalizing .pdf;/Users/marcel/Zotero/storage/ZABUPGZN/2006.html}
}

@online{oordNeuralDiscreteRepresentation2018,
  title = {Neural {{Discrete Representation Learning}}},
  author = {family=Oord, given=Aaron, prefix=van den, useprefix=false and Vinyals, Oriol and Kavukcuoglu, Koray},
  date = {2018-05-30},
  eprint = {1711.00937},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.1711.00937},
  url = {http://arxiv.org/abs/1711.00937},
  urldate = {2022-07-31},
  abstract = {Learning useful representations without supervision remains a key challenge in machine learning. In this paper, we propose a simple yet powerful generative model that learns such discrete representations. Our model, the Vector Quantised-Variational AutoEncoder (VQ-VAE), differs from VAEs in two key ways: the encoder network outputs discrete, rather than continuous, codes; and the prior is learnt rather than static. In order to learn a discrete latent representation, we incorporate ideas from vector quantisation (VQ). Using the VQ method allows the model to circumvent issues of "posterior collapse" -- where the latents are ignored when they are paired with a powerful autoregressive decoder -- typically observed in the VAE framework. Pairing these representations with an autoregressive prior, the model can generate high quality images, videos, and speech as well as doing high quality speaker conversion and unsupervised learning of phonemes, providing further evidence of the utility of the learnt representations.},
  pubstate = {prepublished},
  version = {2},
  keywords = {Computer Science - Machine Learning},
  file = {/Users/marcel/Zotero/storage/RLRPAV8B/Oord et al. - 2018 - Neural Discrete Representation Learning.pdf;/Users/marcel/Zotero/storage/ZSW276D9/1711.html}
}

@software{optax2020github,
  title = {Optax: Composable Gradient Transformation and Optimisation, in {{JAX}}!},
  author = {Hessel, Matteo and Budden, David and Viola, Fabio and Rosca, Mihaela and Sezener, Eren and Hennigan, Tom},
  date = {2020},
  url = {http://github.com/deepmind/optax},
  version = {0.0.1}
}

@article{pagnoniByteLatentTransformer,
  title = {Byte {{Latent Transformer}}: {{Patches Scale Better Than Tokens}}},
  author = {Pagnoni, Artidoro and Pasunuru, Ram and Rodriguez, Pedro and Nguyen, John and Muller, Benjamin and Li, Margaret and Zhou, Chunting and Yu, Lili and Weston, Jason and Zettlemoyer, Luke and Ghosh, Gargi and Lewis, Mike and Holtzman, Ari and Iyer, Srinivasan},
  abstract = {We introduce the Byte Latent Transformer (BLT), a new byte-level LLM architecture that, for the first time, matches tokenization-based LLM performance at scale with significant improvements in inference efficiency and robustness. BLT encodes bytes into dynamically sized patches, which serve as the primary units of computation. Patches are segmented dynamically based on the entropy of the next byte, allocating more compute and model capacity where increased data complexity demands it. We present the first flop controlled scaling study of byte-level models up to 8B parameters with 4T training bytes. Our results demonstrate the feasibility of scaling models trained on raw bytes without a fixed-vocabulary. Both training and inference efficiency improve due to dynamically selecting long patches when data is predictable, along with qualitative improvements on reasoning and long tail generalization. Overall, for fixed inference costs, BLT shows significantly better scaling than tokenization-based models, by simultaneously growing both patch and model size.},
  langid = {english},
  file = {/Users/marcel/Zotero/storage/V5NE3ZC8/Pagnoni et al. - Byte Latent Transformer Patches Scale Better Than Tokens.pdf}
}

@online{pannatierSigmaGPTsNew2024,
  title = {\{\textbackslash sigma\}-{{GPTs}}: {{A New Approach}} to {{Autoregressive Models}}},
  shorttitle = {\{\textbackslash sigma\}-{{GPTs}}},
  author = {Pannatier, Arnaud and Courdier, Evann and Fleuret, François},
  date = {2024-04-15},
  eprint = {2404.09562},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2404.09562},
  urldate = {2024-06-15},
  abstract = {Autoregressive models, such as the GPT family, use a fixed order, usually left-to-right, to generate sequences. However, this is not a necessity. In this paper, we challenge this assumption and show that by simply adding a positional encoding for the output, this order can be modulated on-the-fly per-sample which offers key advantageous properties. It allows for the sampling of and conditioning on arbitrary subsets of tokens, and it also allows sampling in one shot multiple tokens dynamically according to a rejection strategy, leading to a sub-linear number of model evaluations. We evaluate our method across various domains, including language modeling, path-solving, and aircraft vertical rate prediction, decreasing the number of steps required for generation by an order of magnitude.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning},
  file = {/Users/marcel/Zotero/storage/79GWJPTH/Pannatier et al. - 2024 - sigma -GPTs A New Approach to Autoregressive Models.pdf}
}

@inproceedings{parasharTimeloopSystematicApproach2019,
  title = {Timeloop: {{A Systematic Approach}} to {{DNN Accelerator Evaluation}}},
  shorttitle = {Timeloop},
  booktitle = {2019 {{IEEE International Symposium}} on {{Performance Analysis}} of {{Systems}} and {{Software}} ({{ISPASS}})},
  author = {Parashar, Angshuman and Raina, Priyanka and Shao, Yakun Sophia and Chen, Yu-Hsin and Ying, Victor A. and Mukkara, Anurag and Venkatesan, Rangharajan and Khailany, Brucek and Keckler, Stephen W. and Emer, Joel},
  date = {2019-03},
  pages = {304--315},
  publisher = {IEEE},
  location = {Madison, WI, USA},
  doi = {10.1109/ISPASS.2019.00042},
  url = {https://ieeexplore.ieee.org/document/8695666/},
  urldate = {2023-05-09},
  abstract = {This paper presents Timeloop, an infrastructure for evaluating and exploring the architecture design space of deep neural network (DNN) accelerators. Timeloop uses a concise and unified representation of the key architecture and implementation attributes of DNN accelerators to describe a broad space of hardware topologies. It can then emulate those topologies to generate an accurate projection of performance and energy efficiency for a DNN workload through a mapper that finds the best way to schedule operations and stage data on the specified architecture. This enables fair comparisons across different architectures and makes DNN accelerator design more systematic. This paper describes Timeloop’s underlying models and algorithms in detail and shows results from case studies enabled by Timeloop, which provide interesting insights into the current state of DNN architecture design. In particular, they reveal that dataflow and memory hierarchy co-design plays a critical role in optimizing energy efficiency. Also, there is currently still not a single architecture that achieves the best performance and energy efficiency across a diverse set of workloads due to flexibility and efficiency trade-offs. These results provide inspiration into possible directions for DNN accelerator research.},
  eventtitle = {2019 {{IEEE International Symposium}} on {{Performance Analysis}} of {{Systems}} and {{Software}} ({{ISPASS}})},
  isbn = {978-1-7281-0746-2},
  langid = {english},
  file = {/Users/marcel/Zotero/storage/H3VEX6CN/Parashar et al. - 2019 - Timeloop A Systematic Approach to DNN Accelerator.pdf}
}

@inproceedings{parasharTimeloopSystematicApproach2019a,
  title = {Timeloop: {{A Systematic Approach}} to {{DNN Accelerator Evaluation}}},
  shorttitle = {Timeloop},
  booktitle = {2019 {{IEEE International Symposium}} on {{Performance Analysis}} of {{Systems}} and {{Software}} ({{ISPASS}})},
  author = {Parashar, Angshuman and Raina, Priyanka and Shao, Yakun Sophia and Chen, Yu-Hsin and Ying, Victor A. and Mukkara, Anurag and Venkatesan, Rangharajan and Khailany, Brucek and Keckler, Stephen W. and Emer, Joel},
  date = {2019-03},
  pages = {304--315},
  doi = {10.1109/ISPASS.2019.00042},
  abstract = {This paper presents Timeloop, an infrastructure for evaluating and exploring the architecture design space of deep neural network (DNN) accelerators. Timeloop uses a concise and unified representation of the key architecture and implementation attributes of DNN accelerators to describe a broad space of hardware topologies. It can then emulate those topologies to generate an accurate projection of performance and energy efficiency for a DNN workload through a mapper that finds the best way to schedule operations and stage data on the specified architecture. This enables fair comparisons across different architectures and makes DNN accelerator design more systematic. This paper describes Timeloop's underlying models and algorithms in detail and shows results from case studies enabled by Timeloop, which provide interesting insights into the current state of DNN architecture design. In particular, they reveal that dataflow and memory hierarchy co-design plays a critical role in optimizing energy efficiency. Also, there is currently still not a single architecture that achieves the best performance and energy efficiency across a diverse set of workloads due to flexibility and efficiency trade-offs. These results provide inspiration into possible directions for DNN accelerator research.},
  eventtitle = {2019 {{IEEE International Symposium}} on {{Performance Analysis}} of {{Systems}} and {{Software}} ({{ISPASS}})},
  keywords = {accelerator architecture,Accelerator architectures,Computational modeling,deep neural networks,Hardware,modeling,neural network dataflows,Neural networks,Space exploration,Systematics},
  file = {/Users/marcel/Zotero/storage/2S3HNU83/Parashar et al. - 2019 - Timeloop A Systematic Approach to DNN Accelerator.pdf;/Users/marcel/Zotero/storage/ZM4KMBX9/8695666.html}
}

@inproceedings{Paszke_PyTorch_An_Imperative_2019,
  title = {{{PyTorch}}: {{An}} Imperative Style, High-Performance Deep Learning Library},
  booktitle = {Advances in Neural Information Processing Systems 32},
  author = {Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and Desmaison, Alban and Kopf, Andreas and Yang, Edward and DeVito, Zachary and Raison, Martin and Tejani, Alykhan and Chilamkurthy, Sasank and Steiner, Benoit and Fang, Lu and Bai, Junjie and Chintala, Soumith},
  editor = {Wallach, H. and Larochelle, H. and Beygelzimer, A. and family=Buc, given=F., prefix=d'Alché-, useprefix=true and Fox, E. and Garnett, R.},
  date = {2019},
  pages = {8024--8035},
  publisher = {Curran Associates, Inc.},
  url = {http://papers.neurips.cc/paper/9015-pytorch-an-imperative-style-high-performance-deep-learning-library.pdf}
}

@article{paszkeAutomaticDifferentiationPyTorch2017,
  title = {Automatic Differentiation in {{PyTorch}}},
  author = {Paszke, Adam and Gross, Sam and Chintala, Soumith and Chanan, Gregory and Yang, Edward and DeVito, Zachary and Lin, Zeming and Desmaison, Alban and Antiga, Luca and Lerer, Adam},
  date = {2017-10-28},
  url = {https://openreview.net/forum?id=BJJsrmfCZ},
  urldate = {2023-11-10},
  abstract = {In this article, we describe an automatic differentiation module of PyTorch — a library designed to enable rapid research on machine learning models. It builds upon a few projects, most notably Lua Torch, Chainer, and HIPS Autograd, and provides a high performance environment with easy access to automatic differentiation of models executed on different devices (CPU and GPU). To make prototyping easier, PyTorch does not follow the symbolic approach used in many other deep learning frameworks, but focuses on differentiation of purely imperative programs, with a focus on extensibility and low overhead. Note that this preprint is a draft of certain sections from an upcoming paper covering all PyTorch features.},
  langid = {english},
  file = {/Users/marcel/Zotero/storage/SE443JJL/Paszke et al. - 2017 - Automatic differentiation in PyTorch.pdf}
}

@online{pengEvaluatingEmergingAI2023,
  title = {Evaluating {{Emerging AI}}/{{ML Accelerators}}: {{IPU}}, {{RDU}}, and {{NVIDIA}}/{{AMD GPUs}}},
  shorttitle = {Evaluating {{Emerging AI}}/{{ML Accelerators}}},
  author = {Peng, Hongwu and Ding, Caiwen and Geng, Tong and Choudhury, Sutanay and Barker, Kevin and Li, Ang},
  date = {2023-11-07},
  eprint = {2311.04417},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2311.04417},
  url = {http://arxiv.org/abs/2311.04417},
  urldate = {2023-11-11},
  abstract = {The relentless advancement of artificial intelligence (AI) and machine learning (ML) applications necessitates the development of specialized hardware accelerators capable of handling the increasing complexity and computational demands. Traditional computing architectures, based on the von Neumann model, are being outstripped by the requirements of contemporary AI/ML algorithms, leading to a surge in the creation of accelerators like the Graphcore Intelligence Processing Unit (IPU), Sambanova Reconfigurable Dataflow Unit (RDU), and enhanced GPU platforms. These hardware accelerators are characterized by their innovative data-flow architectures and other design optimizations that promise to deliver superior performance and energy efficiency for AI/ML tasks. This research provides a preliminary evaluation and comparison of these commercial AI/ML accelerators, delving into their hardware and software design features to discern their strengths and unique capabilities. By conducting a series of benchmark evaluations on common DNN operators and other AI/ML workloads, we aim to illuminate the advantages of data-flow architectures over conventional processor designs and offer insights into the performance trade-offs of each platform. The findings from our study will serve as a valuable reference for the design and performance expectations of research prototypes, thereby facilitating the development of next-generation hardware accelerators tailored for the ever-evolving landscape of AI/ML applications. Through this analysis, we aspire to contribute to the broader understanding of current accelerator technologies and to provide guidance for future innovations in the field.},
  pubstate = {prepublished},
  keywords = {C.4,Computer Science - Distributed Parallel and Cluster Computing,Computer Science - Hardware Architecture,Computer Science - Machine Learning,Computer Science - Performance},
  file = {/Users/marcel/Zotero/storage/FJSY75H4/Peng et al. - 2023 - Evaluating Emerging AIML Accelerators IPU, RDU, and NVIDIAAMD GPUs.pdf;/Users/marcel/Zotero/storage/6Z7X9GCX/2311.html}
}

@online{PersamplegradientsPyTorchTutorials,
  title = {Per-Sample-Gradients — {{PyTorch Tutorials}} 2.0.1+cu117 Documentation},
  url = {https://pytorch.org/tutorials/intermediate/per_sample_grads.html},
  urldate = {2023-05-15},
  file = {/Users/marcel/Zotero/storage/MVFDVWCH/per_sample_grads.html}
}

@inproceedings{petersDeepContextualizedWord2018,
  title = {Deep {{Contextualized Word Representations}}},
  booktitle = {Proceedings of the 2018 {{Conference}} of the {{North American Chapter}} of the {{Association}} for {{Computational Linguistics}}: {{Human Language Technologies}}, {{Volume}} 1 ({{Long Papers}})},
  author = {Peters, Matthew E. and Neumann, Mark and Iyyer, Mohit and Gardner, Matt and Clark, Christopher and Lee, Kenton and Zettlemoyer, Luke},
  editor = {Walker, Marilyn and Ji, Heng and Stent, Amanda},
  date = {2018-06},
  pages = {2227--2237},
  publisher = {Association for Computational Linguistics},
  location = {New Orleans, Louisiana},
  doi = {10.18653/v1/N18-1202},
  url = {https://aclanthology.org/N18-1202},
  urldate = {2024-02-14},
  abstract = {We introduce a new type of deep contextualized word representation that models both (1) complex characteristics of word use (e.g., syntax and semantics), and (2) how these uses vary across linguistic contexts (i.e., to model polysemy). Our word vectors are learned functions of the internal states of a deep bidirectional language model (biLM), which is pre-trained on a large text corpus. We show that these representations can be easily added to existing models and significantly improve the state of the art across six challenging NLP problems, including question answering, textual entailment and sentiment analysis. We also present an analysis showing that exposing the deep internals of the pre-trained network is crucial, allowing downstream models to mix different types of semi-supervision signals.},
  eventtitle = {{{NAACL-HLT}} 2018},
  file = {/Users/marcel/Zotero/storage/DTNNYDB5/Peters et al. - 2018 - Deep Contextualized Word Representations.pdf}
}

@online{peyreComputationalOptimalTransport2020,
  title = {Computational {{Optimal Transport}}},
  author = {Peyré, Gabriel and Cuturi, Marco},
  date = {2020-03-18},
  eprint = {1803.00567},
  eprinttype = {arXiv},
  eprintclass = {stat},
  doi = {10.48550/arXiv.1803.00567},
  url = {http://arxiv.org/abs/1803.00567},
  urldate = {2022-11-02},
  abstract = {Optimal transport (OT) theory can be informally described using the words of the French mathematician Gaspard Monge (1746-1818): A worker with a shovel in hand has to move a large pile of sand lying on a construction site. The goal of the worker is to erect with all that sand a target pile with a prescribed shape (for example, that of a giant sand castle). Naturally, the worker wishes to minimize her total effort, quantified for instance as the total distance or time spent carrying shovelfuls of sand. Mathematicians interested in OT cast that problem as that of comparing two probability distributions, two different piles of sand of the same volume. They consider all of the many possible ways to morph, transport or reshape the first pile into the second, and associate a "global" cost to every such transport, using the "local" consideration of how much it costs to move a grain of sand from one place to another. Recent years have witnessed the spread of OT in several fields, thanks to the emergence of approximate solvers that can scale to sizes and dimensions that are relevant to data sciences. Thanks to this newfound scalability, OT is being increasingly used to unlock various problems in imaging sciences (such as color or texture processing), computer vision and graphics (for shape manipulation) or machine learning (for regression, classification and density fitting). This short book reviews OT with a bias toward numerical methods and their applications in data sciences, and sheds lights on the theoretical properties of OT that make it particularly useful for some of these applications.},
  pubstate = {prepublished},
  keywords = {Statistics - Machine Learning},
  file = {/Users/marcel/Zotero/storage/7WFD7CCF/Peyré and Cuturi - 2020 - Computational Optimal Transport.pdf;/Users/marcel/Zotero/storage/Q34YHG5M/1803.html}
}

@article{pfeifferDeepLearningSpiking2018,
  title = {Deep {{Learning With Spiking Neurons}}: {{Opportunities}} and {{Challenges}}},
  shorttitle = {Deep {{Learning With Spiking Neurons}}},
  author = {Pfeiffer, Michael and Pfeil, Thomas},
  date = {2018},
  journaltitle = {Frontiers in Neuroscience},
  volume = {12},
  issn = {1662-453X},
  url = {https://www.frontiersin.org/article/10.3389/fnins.2018.00774},
  urldate = {2022-05-01},
  abstract = {Spiking neural networks (SNNs) are inspired by information processing in biology, where sparse and asynchronous binary signals are communicated and processed in a massively parallel fashion. SNNs on neuromorphic hardware exhibit favorable properties such as low power consumption, fast inference, and event-driven information processing. This makes them interesting candidates for the efficient implementation of deep neural networks, the method of choice for many machine learning tasks. In this review, we address the opportunities that deep spiking networks offer and investigate in detail the challenges associated with training SNNs in a way that makes them competitive with conventional deep learning, but simultaneously allows for efficient mapping to hardware. A wide range of training methods for SNNs is presented, ranging from the conversion of conventional deep networks into SNNs, constrained training before conversion, spiking variants of backpropagation, and biologically motivated variants of STDP. The goal of our review is to define a categorization of SNN training methods, and summarize their advantages and drawbacks. We further discuss relationships between SNNs and binary networks, which are becoming popular for efficient digital hardware implementation. Neuromorphic hardware platforms have great potential to enable deep spiking networks in real-world applications. We compare the suitability of various neuromorphic systems that have been developed over the past years, and investigate potential use cases. Neuromorphic approaches and conventional machine learning should not be considered simply two solutions to the same classes of problems, instead it is possible to identify and exploit their task-specific advantages. Deep SNNs offer great opportunities to work with new types of event-based sensors, exploit temporal codes and local on-chip learning, and we have so far just scratched the surface of realizing these advantages in practical applications.},
  file = {/Users/marcel/Zotero/storage/7AHNGS48/Pfeiffer and Pfeil - 2018 - Deep Learning With Spiking Neurons Opportunities .pdf}
}

@online{polarsPolars2023,
  title = {Polars},
  author = {Polars},
  date = {2023},
  url = {https://www.pola.rs/},
  urldate = {2024-03-14},
  abstract = {DataFrames for the new era},
  langid = {english},
  file = {/Users/marcel/Zotero/storage/EIGYGWNN/pola.rs.html}
}

@article{pressAdaptiveStepsizeRungeKutta1992a,
  title = {Adaptive {{Stepsize Runge-Kutta Integration}}},
  author = {Press, William H. and Teukolsky, Saul A.},
  date = {1992},
  journaltitle = {Computers in Physics},
  shortjournal = {Comput. Phys.},
  volume = {6},
  number = {2},
  pages = {188},
  issn = {08941866},
  doi = {10.1063/1.4823060},
  url = {http://scitation.aip.org/content/aip/journal/cip/6/2/10.1063/1.4823060},
  urldate = {2022-09-11},
  langid = {english},
  file = {/Users/marcel/Zotero/storage/73GNDZB6/Press and Teukolsky - 1992 - Adaptive Stepsize Runge-Kutta Integration.pdf}
}

@online{qiPointNetDeepLearning2017,
  title = {{{PointNet}}: {{Deep Learning}} on {{Point Sets}} for {{3D Classification}} and {{Segmentation}}},
  shorttitle = {{{PointNet}}},
  author = {Qi, Charles R. and Su, Hao and Mo, Kaichun and Guibas, Leonidas J.},
  date = {2017-04-10},
  eprint = {1612.00593},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/1612.00593},
  urldate = {2022-09-22},
  abstract = {Point cloud is an important type of geometric data structure. Due to its irregular format, most researchers transform such data to regular 3D voxel grids or collections of images. This, however, renders data unnecessarily voluminous and causes issues. In this paper, we design a novel type of neural network that directly consumes point clouds and well respects the permutation invariance of points in the input. Our network, named PointNet, provides a unified architecture for applications ranging from object classification, part segmentation, to scene semantic parsing. Though simple, PointNet is highly efficient and effective. Empirically, it shows strong performance on par or even better than state of the art. Theoretically, we provide analysis towards understanding of what the network has learnt and why the network is robust with respect to input perturbation and corruption.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {/Users/marcel/Zotero/storage/IBQQWE79/Qi et al. - 2017 - PointNet Deep Learning on Point Sets for 3D Class.pdf;/Users/marcel/Zotero/storage/KRKUN3L8/1612.html}
}

@inproceedings{radfordImprovingLanguageUnderstanding2018,
  title = {Improving {{Language Understanding}} by {{Generative Pre-Training}}},
  author = {Radford, Alec and Narasimhan, Karthik},
  date = {2018},
  url = {https://www.semanticscholar.org/paper/Improving-Language-Understanding-by-Generative-Radford-Narasimhan/cd18800a0fe0b668a1cc19f2ec95b5003d0a5035},
  urldate = {2024-02-14},
  abstract = {Natural language understanding comprises a wide range of diverse tasks such as textual entailment, question answering, semantic similarity assessment, and document classification. Although large unlabeled text corpora are abundant, labeled data for learning these specific tasks is scarce, making it challenging for discriminatively trained models to perform adequately. We demonstrate that large gains on these tasks can be realized by generative pre-training of a language model on a diverse corpus of unlabeled text, followed by discriminative fine-tuning on each specific task. In contrast to previous approaches, we make use of task-aware input transformations during fine-tuning to achieve effective transfer while requiring minimal changes to the model architecture. We demonstrate the effectiveness of our approach on a wide range of benchmarks for natural language understanding. Our general task-agnostic model outperforms discriminatively trained models that use architectures specifically crafted for each task, significantly improving upon the state of the art in 9 out of the 12 tasks studied. For instance, we achieve absolute improvements of 8.9\% on commonsense reasoning (Stories Cloze Test), 5.7\% on question answering (RACE), and 1.5\% on textual entailment (MultiNLI).},
  file = {/Users/marcel/Zotero/storage/9Y64ZC3K/Radford and Narasimhan - 2018 - Improving Language Understanding by Generative Pre-Training.pdf}
}

@inproceedings{rainaLargescaleDeepUnsupervised2009,
  title = {Large-Scale Deep Unsupervised Learning Using Graphics Processors},
  booktitle = {Proceedings of the 26th {{Annual International Conference}} on {{Machine Learning}}},
  author = {Raina, Rajat and Madhavan, Anand and Ng, Andrew Y.},
  date = {2009-06-14},
  series = {{{ICML}} '09},
  pages = {873--880},
  publisher = {Association for Computing Machinery},
  location = {New York, NY, USA},
  doi = {10.1145/1553374.1553486},
  url = {https://doi.org/10.1145/1553374.1553486},
  urldate = {2022-05-01},
  abstract = {The promise of unsupervised learning methods lies in their potential to use vast amounts of unlabeled data to learn complex, highly nonlinear models with millions of free parameters. We consider two well-known unsupervised learning models, deep belief networks (DBNs) and sparse coding, that have recently been applied to a flurry of machine learning applications (Hinton \& Salakhutdinov, 2006; Raina et al., 2007). Unfortunately, current learning algorithms for both models are too slow for large-scale applications, forcing researchers to focus on smaller-scale models, or to use fewer training examples. In this paper, we suggest massively parallel methods to help resolve these problems. We argue that modern graphics processors far surpass the computational capabilities of multicore CPUs, and have the potential to revolutionize the applicability of deep unsupervised learning methods. We develop general principles for massively parallelizing unsupervised learning tasks using graphics processors. We show that these principles can be applied to successfully scaling up learning algorithms for both DBNs and sparse coding. Our implementation of DBN learning is up to 70 times faster than a dual-core CPU implementation for large models. For example, we are able to reduce the time required to learn a four-layer DBN with 100 million free parameters from several weeks to around a single day. For sparse coding, we develop a simple, inherently parallel algorithm, that leads to a 5 to 15-fold speedup over previous methods.},
  isbn = {978-1-60558-516-1},
  file = {/Users/marcel/Zotero/storage/IYDFVUJ9/Raina et al. - 2009 - Large-scale deep unsupervised learning using graph.pdf}
}

@online{rajbhandariDeepSpeedMoEAdvancingMixtureofExperts2022,
  title = {{{DeepSpeed-MoE}}: {{Advancing Mixture-of-Experts Inference}} and {{Training}} to {{Power Next-Generation AI Scale}}},
  shorttitle = {{{DeepSpeed-MoE}}},
  author = {Rajbhandari, Samyam and Li, Conglong and Yao, Zhewei and Zhang, Minjia and Aminabadi, Reza Yazdani and Awan, Ammar Ahmad and Rasley, Jeff and He, Yuxiong},
  date = {2022-07-21},
  eprint = {2201.05596},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2201.05596},
  url = {http://arxiv.org/abs/2201.05596},
  urldate = {2024-03-07},
  abstract = {As the training of giant dense models hits the boundary on the availability and capability of the hardware resources today, Mixture-of-Experts (MoE) models become one of the most promising model architectures due to their significant training cost reduction compared to a quality-equivalent dense model. Its training cost saving is demonstrated from encoder-decoder models (prior works) to a 5x saving for auto-aggressive language models (this work along with parallel explorations). However, due to the much larger model size and unique architecture, how to provide fast MoE model inference remains challenging and unsolved, limiting its practical usage. To tackle this, we present DeepSpeed-MoE, an end-to-end MoE training and inference solution as part of the DeepSpeed library, including novel MoE architecture designs and model compression techniques that reduce MoE model size by up to 3.7x, and a highly optimized inference system that provides 7.3x better latency and cost compared to existing MoE inference solutions. DeepSpeed-MoE offers an unprecedented scale and efficiency to serve massive MoE models with up to 4.5x faster and 9x cheaper inference compared to quality-equivalent dense models. We hope our innovations and systems help open a promising path to new directions in the large model landscape, a shift from dense to sparse MoE models, where training and deploying higher-quality models with fewer resources becomes more widely possible.},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Distributed Parallel and Cluster Computing,Computer Science - Machine Learning},
  file = {/Users/marcel/Zotero/storage/N535IL4T/Rajbhandari et al. - 2022 - DeepSpeed-MoE Advancing Mixture-of-Experts Inference and Training to Power Next-Generation AI Scale.pdf;/Users/marcel/Zotero/storage/I865LUFY/2201.html}
}

@online{rameshHierarchicalTextConditionalImage2022,
  title = {Hierarchical {{Text-Conditional Image Generation}} with {{CLIP Latents}}},
  author = {Ramesh, Aditya and Dhariwal, Prafulla and Nichol, Alex and Chu, Casey and Chen, Mark},
  date = {2022-04-12},
  eprint = {2204.06125},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2204.06125},
  url = {http://arxiv.org/abs/2204.06125},
  urldate = {2022-07-11},
  abstract = {Contrastive models like CLIP have been shown to learn robust representations of images that capture both semantics and style. To leverage these representations for image generation, we propose a two-stage model: a prior that generates a CLIP image embedding given a text caption, and a decoder that generates an image conditioned on the image embedding. We show that explicitly generating image representations improves image diversity with minimal loss in photorealism and caption similarity. Our decoders conditioned on image representations can also produce variations of an image that preserve both its semantics and style, while varying the non-essential details absent from the image representation. Moreover, the joint embedding space of CLIP enables language-guided image manipulations in a zero-shot fashion. We use diffusion models for the decoder and experiment with both autoregressive and diffusion models for the prior, finding that the latter are computationally more efficient and produce higher-quality samples.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {/Users/marcel/Zotero/storage/2CAARQGV/Ramesh et al. - 2022 - Hierarchical Text-Conditional Image Generation wit.pdf;/Users/marcel/Zotero/storage/GBMIGUXP/2204.html}
}

@online{ramosControlTwowayCoupled2022,
  title = {Control of {{Two-way Coupled Fluid Systems}} with {{Differentiable Solvers}}},
  author = {Ramos, Brener and Trost, Felix and Thuerey, Nils},
  date = {2022-06-01},
  eprint = {2206.00342},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2206.00342},
  urldate = {2022-12-01},
  abstract = {We investigate the use of deep neural networks to control complex nonlinear dynamical systems, specifically the movement of a rigid body immersed in a fluid. We solve the Navier Stokes equations with two way coupling, which gives rise to nonlinear perturbations that make the control task very challenging. Neural networks are trained in an unsupervised way to act as controllers with desired characteristics through a process of learning from a differentiable simulator. Here we introduce a set of physically interpretable loss terms to let the networks learn robust and stable interactions. We demonstrate that controllers trained in a canonical setting with quiescent initial conditions reliably generalize to varied and challenging environments such as previously unseen inflow conditions and forcing, although they do not have any fluid information as input. Further, we show that controllers trained with our approach outperform a variety of classical and learned alternatives in terms of evaluation metrics and generalization capabilities.},
  pubstate = {prepublished},
  keywords = {68T07,Computer Science - Machine Learning},
  file = {/Users/marcel/Zotero/storage/LFTZHT3H/Ramos et al. - 2022 - Control of Two-way Coupled Fluid Systems with Diff.pdf;/Users/marcel/Zotero/storage/YCCFZP9Y/2206.html}
}

@unpublished{ramsauerHopfieldNetworksAll2021,
  title = {Hopfield {{Networks}} Is {{All You Need}}},
  author = {Ramsauer, Hubert and Schäfl, Bernhard and Lehner, Johannes and Seidl, Philipp and Widrich, Michael and Adler, Thomas and Gruber, Lukas and Holzleitner, Markus and Pavlović, Milena and Sandve, Geir Kjetil and Greiff, Victor and Kreil, David and Kopp, Michael and Klambauer, Günter and Brandstetter, Johannes and Hochreiter, Sepp},
  date = {2021-04-28},
  eprint = {2008.02217},
  eprinttype = {arXiv},
  eprintclass = {cs, stat},
  url = {http://arxiv.org/abs/2008.02217},
  urldate = {2022-05-02},
  abstract = {We introduce a modern Hopfield network with continuous states and a corresponding update rule. The new Hopfield network can store exponentially (with the dimension of the associative space) many patterns, retrieves the pattern with one update, and has exponentially small retrieval errors. It has three types of energy minima (fixed points of the update): (1) global fixed point averaging over all patterns, (2) metastable states averaging over a subset of patterns, and (3) fixed points which store a single pattern. The new update rule is equivalent to the attention mechanism used in transformers. This equivalence enables a characterization of the heads of transformer models. These heads perform in the first layers preferably global averaging and in higher layers partial averaging via metastable states. The new modern Hopfield network can be integrated into deep learning architectures as layers to allow the storage of and access to raw input data, intermediate results, or learned prototypes. These Hopfield layers enable new ways of deep learning, beyond fully-connected, convolutional, or recurrent networks, and provide pooling, memory, association, and attention mechanisms. We demonstrate the broad applicability of the Hopfield layers across various domains. Hopfield layers improved state-of-the-art on three out of four considered multiple instance learning problems as well as on immune repertoire classification with several hundreds of thousands of instances. On the UCI benchmark collections of small classification tasks, where deep learning methods typically struggle, Hopfield layers yielded a new state-of-the-art when compared to different machine learning methods. Finally, Hopfield layers achieved state-of-the-art on two drug design datasets. The implementation is available at: https://github.com/ml-jku/hopfield-layers},
  keywords = {Computer Science - Computation and Language,Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing,Statistics - Machine Learning},
  file = {/Users/marcel/Zotero/storage/Z8RYFZ2I/Ramsauer et al. - 2021 - Hopfield Networks is All You Need.pdf;/Users/marcel/Zotero/storage/KNHN64FL/2008.html}
}

@article{raoPredictiveCodingVisual1999,
  title = {Predictive Coding in the Visual Cortex: A Functional Interpretation of Some Extra-Classical Receptive-Field Effects},
  shorttitle = {Predictive Coding in the Visual Cortex},
  author = {Rao, Rajesh P. N. and Ballard, Dana H.},
  date = {1999-01},
  journaltitle = {Nature Neuroscience},
  shortjournal = {Nat Neurosci},
  volume = {2},
  number = {1},
  pages = {79--87},
  publisher = {Nature Publishing Group},
  issn = {1546-1726},
  doi = {10.1038/4580},
  url = {https://www.nature.com/articles/nn0199_79},
  urldate = {2022-05-01},
  abstract = {We describe a model of visual processing in which feedback connections from a higher- to a lower-order visual cortical area carry predictions of lower-level neural activities, whereas the feedforward connections carry the residual errors between the predictions and the actual lower-level activities. When exposed to natural images, a hierarchical network of model neurons implementing such a model developed simple-cell-like receptive fields. A subset of neurons responsible for carrying the residual errors showed endstopping and other extra-classical receptive-field effects. These results suggest that rather than being exclusively feedforward phenomena, nonclassical surround effects in the visual cortex may also result from cortico-cortical feedback as a consequence of the visual system using an efficient hierarchical strategy for encoding natural images.},
  issue = {1},
  langid = {english},
  keywords = {Animal Genetics and Genomics,Behavioral Sciences,Biological Techniques,Biomedicine,general,Neurobiology,Neurosciences},
  file = {/Users/marcel/Zotero/storage/3J42ZI4G/Rao and Ballard - 1999 - Predictive coding in the visual cortex a function.pdf;/Users/marcel/Zotero/storage/L5V7YGBY/nn0199_79.html}
}

@article{reinhardColorTransferImages2001,
  title = {Color Transfer between Images},
  author = {Reinhard, E. and Adhikhmin, M. and Gooch, B. and Shirley, P.},
  date = {2001-07},
  journaltitle = {IEEE Computer Graphics and Applications},
  volume = {21},
  number = {5},
  pages = {34--41},
  issn = {1558-1756},
  doi = {10.1109/38.946629},
  abstract = {We use a simple statistical analysis to impose one image's color characteristics on another. We can achieve color correction by choosing an appropriate source image and apply its characteristic to another image.},
  eventtitle = {{{IEEE Computer Graphics}} and {{Applications}}},
  keywords = {Decorrelation,Humans,Image color analysis,Image converters,Least squares approximation,Matrix converters,Principal component analysis,Signal processing,Statistical analysis,Visual system},
  file = {/Users/marcel/Zotero/storage/Z6S52CNZ/Reinhard et al. - 2001 - Color transfer between images.pdf;/Users/marcel/Zotero/storage/LIQPXBLR/946629.html}
}

@article{rivesBiologicalStructureFunction2021,
  title = {Biological Structure and Function Emerge from Scaling Unsupervised Learning to 250 Million Protein Sequences},
  author = {Rives, Alexander and Meier, Joshua and Sercu, Tom and Goyal, Siddharth and Lin, Zeming and Liu, Jason and Guo, Demi and Ott, Myle and Zitnick, C. Lawrence and Ma, Jerry and Fergus, Rob},
  date = {2021-04-13},
  journaltitle = {Proceedings of the National Academy of Sciences},
  volume = {118},
  number = {15},
  pages = {e2016239118},
  publisher = {Proceedings of the National Academy of Sciences},
  doi = {10.1073/pnas.2016239118},
  url = {https://www.pnas.org/doi/10.1073/pnas.2016239118},
  urldate = {2024-10-01},
  abstract = {In the field of artificial intelligence, a combination of scale in data and model capacity enabled by unsupervised learning has led to major advances in representation learning and statistical generation. In the life sciences, the anticipated growth of sequencing promises unprecedented data on natural sequence diversity. Protein language modeling at the scale of evolution is a logical step toward predictive and generative artificial intelligence for biology. To this end, we use unsupervised learning to train a deep contextual language model on 86 billion amino acids across 250 million protein sequences spanning evolutionary diversity. The resulting model contains information about biological properties in its representations. The representations are learned from sequence data alone. The learned representation space has a multiscale organization reflecting structure from the level of biochemical properties of amino acids to remote homology of proteins. Information about secondary and tertiary structure is encoded in the representations and can be identified by linear projections. Representation learning produces features that generalize across a range of applications, enabling state-of-the-art supervised prediction of mutational effect and secondary structure and improving state-of-the-art features for long-range contact prediction.},
  file = {/Users/marcel/Zotero/storage/4DKHFMGB/Rives et al. - 2021 - Biological structure and function emerge from scaling unsupervised learning to 250 million protein s.pdf}
}

@article{RobustSymmetryDetection,
  title = {Robust {{Symmetry Detection}} via {{Riemannian Langevin Dynamics}}},
  volume = {1},
  number = {1},
  langid = {english},
  file = {/Users/marcel/Zotero/storage/G89GXCUZ/Robust Symmetry Detection via Riemannian Langevin Dynamics.pdf}
}

@article{RobustSymmetryDetectiona,
  title = {Robust {{Symmetry Detection}} via {{Riemannian Langevin Dynamics}}},
  volume = {1},
  number = {1},
  langid = {english},
  file = {/Users/marcel/Zotero/storage/Y89AA9AJ/Robust Symmetry Detection via Riemannian Langevin Dynamics.pdf}
}

@article{roedRealtimeSemanticSegmentation2022a,
  title = {Real-Time Semantic Segmentation on {{FPGAs}} for Autonomous Vehicles with Hls4ml},
  author = {Roed, Marcel and Ghielmetti, Nicolò and Loncar, Vladimir and Pierini, Maurizio and Summers, Sioni and Aarrestad, Thea and Petersson, Christoffer and Linander, Hampus and Ngadiuba, Jennifer and Lin, Kelvin and Harris, Philip},
  date = {2022-11},
  journaltitle = {Machine Learning: Science and Technology},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  volume = {3},
  number = {4},
  pages = {045011},
  publisher = {IOP Publishing},
  issn = {2632-2153},
  doi = {10.1088/2632-2153/ac9cb5},
  url = {https://dx.doi.org/10.1088/2632-2153/ac9cb5},
  urldate = {2022-12-07},
  abstract = {In this paper, we investigate how field programmable gate arrays can serve as hardware accelerators for real-time semantic segmentation tasks relevant for autonomous driving. Considering compressed versions of the ENet convolutional neural network architecture, we demonstrate a fully-on-chip deployment with a latency of 4.9 ms per image, using less than 30\% of the available resources on a Xilinx ZCU102 evaluation board. The latency is reduced to 3 ms per image when increasing the batch size to ten, corresponding to the use case where the autonomous vehicle receives inputs from multiple cameras simultaneously. We show, through aggressive filter reduction and heterogeneous quantization-aware training, and an optimized implementation of convolutional layers, that the power consumption and resource utilization can be significantly reduced while maintaining accuracy on the Cityscapes dataset.},
  langid = {english},
  file = {/Users/marcel/Zotero/storage/7Z8Y9PMR/Ghielmetti et al. - 2022 - Real-time semantic segmentation on FPGAs for auton.pdf}
}

@article{ronnebergerUNetConvolutionalNetworks2015,
  title = {U-{{Net}}: {{Convolutional Networks}} for {{Biomedical Image Segmentation}}},
  shorttitle = {U-{{Net}}},
  author = {Ronneberger, Olaf and Fischer, Philipp and Brox, Thomas},
  date = {2015-05-18},
  doi = {10.48550/arXiv.1505.04597},
  url = {https://arxiv.org/abs/1505.04597v1},
  urldate = {2022-12-18},
  abstract = {There is large consent that successful training of deep networks requires many thousand annotated training samples. In this paper, we present a network and training strategy that relies on the strong use of data augmentation to use the available annotated samples more efficiently. The architecture consists of a contracting path to capture context and a symmetric expanding path that enables precise localization. We show that such a network can be trained end-to-end from very few images and outperforms the prior best method (a sliding-window convolutional network) on the ISBI challenge for segmentation of neuronal structures in electron microscopic stacks. Using the same network trained on transmitted light microscopy images (phase contrast and DIC) we won the ISBI cell tracking challenge 2015 in these categories by a large margin. Moreover, the network is fast. Segmentation of a 512x512 image takes less than a second on a recent GPU. The full implementation (based on Caffe) and the trained networks are available at http://lmb.informatik.uni-freiburg.de/people/ronneber/u-net .},
  langid = {english},
  file = {/Users/marcel/Zotero/storage/QGKXVUSK/Ronneberger et al. - 2015 - U-Net Convolutional Networks for Biomedical Image.pdf}
}

@misc{rosenblattPerceptronProbabilisticModel,
  title = {The {{Perceptron}}: {{A Probabilistic Model}} for {{Information Storage}} and {{Organization In The Brain}}},
  shorttitle = {The {{Perceptron}}},
  author = {Rosenblatt, F.},
  abstract = {If we are eventually to understand the capability of higher organisms for perceptual recognition, generalization, recall, and thinking, we must first have answers to three fundamental questions: 1. How is information about the physical world sensed, or detected, by the biological system? 2. In what form is information stored, or remembered? 3. How does information contained in storage, or in memory, influence recognition and behavior? The first of these questions is in the province of sensory physiology, and is the only one for which appreciable understanding has been achieved. This article will be concerned primarily with the second and third questions, which are still subject to a vast amount of speculation, and where the few relevant facts currently supplied by neurophysiology have not yet been integrated into an acceptable theory. With regard to the second question, two alternative positions have been maintained. The first suggests that storage of sensory information is in the form of coded representations or images, with some sort of one-to-one mapping between the sensory stimulus 1 The development of this theory has been carried out at the Cornell Aeronautical Laboratory, Inc., under the sponsorship of the Office of Naval Research, Contract Nonr-2381(00). This article is primarily'an adaptation of material reported in Ref. IS, which constitutes the first full report on the program.},
  file = {/Users/marcel/Zotero/storage/PWBZ6C4L/Brain and Rosenblatt - The Perceptron A Probabilistic Model for Informat.pdf;/Users/marcel/Zotero/storage/7WNDUG9Z/download.html}
}

@online{rosenUniversalCellEmbeddings2023,
  title = {Towards {{Universal Cell Embeddings}}: {{Integrating Single-cell RNA-seq Datasets}} across {{Species}} with {{SATURN}}},
  shorttitle = {Towards {{Universal Cell Embeddings}}},
  author = {Rosen, Yanay and Brbić, Maria and Roohani, Yusuf and Swanson, Kyle and Li, Ziang and Leskovec, Jure},
  date = {2023-02-03},
  eprinttype = {bioRxiv},
  eprintclass = {New Results},
  pages = {2023.02.03.526939},
  doi = {10.1101/2023.02.03.526939},
  url = {https://www.biorxiv.org/content/10.1101/2023.02.03.526939v1},
  urldate = {2023-11-08},
  abstract = {Analysis of single-cell datasets generated from diverse organisms offers unprecedented opportunities to unravel fundamental evolutionary processes of conservation and diversification of cell types. However, inter-species genomic differences limit the joint analysis of crossspecies datasets to orthologous genes. Here, we present SATURN, a deep learning method for learning universal cell embeddings that encodes genes’ biological properties using protein language models. By coupling protein embeddings from language models with RNA expression, SATURN integrates datasets profiled from different species regardless of their genomic similarity. SATURN has a unique ability to detect functionally related genes co-expressed across species, redefining differential expression for cross-species analysis. We apply SATURN to three species whole-organism atlases and frog and zebrafish embryogenesis datasets. We show that cell embeddings learnt in SATURN can be effectively used to transfer annotations across species and identify both homologous and species-specific cell types, even across evolutionarily remote species. Finally, we use SATURN to reannotate the five species Cell Atlas of Human Trabecular Meshwork and Aqueous Outflow Structures and find evidence of potentially divergent functions between glaucoma associated genes in humans and other species.},
  langid = {english},
  pubstate = {prepublished},
  file = {/Users/marcel/Zotero/storage/RMCYTG2D/Rosen et al. - 2023 - Towards Universal Cell Embeddings Integrating Single-cell RNA-seq Datasets across Species with SATU.pdf}
}

@article{rudinStopExplainingBlack2019,
  title = {Stop Explaining Black Box Machine Learning Models for High Stakes Decisions and Use Interpretable Models Instead},
  author = {Rudin, Cynthia},
  date = {2019-05},
  journaltitle = {Nature Machine Intelligence},
  shortjournal = {Nat Mach Intell},
  volume = {1},
  number = {5},
  pages = {206--215},
  publisher = {Nature Publishing Group},
  issn = {2522-5839},
  doi = {10.1038/s42256-019-0048-x},
  url = {https://www.nature.com/articles/s42256-019-0048-x},
  urldate = {2023-12-16},
  abstract = {Black box machine learning models are currently being used for high-stakes decision making throughout society, causing problems in healthcare, criminal justice and other domains. Some people hope that creating methods for explaining these black box models will alleviate some of the problems, but trying to explain black box models, rather than creating models that are interpretable in the first place, is likely to perpetuate bad practice and can potentially cause great harm to society. The way forward is to design models that are inherently interpretable. This Perspective clarifies the chasm between explaining black boxes and using inherently interpretable models, outlines several key reasons why explainable black boxes should be avoided in high-stakes decisions, identifies challenges to interpretable machine learning, and provides several example applications where interpretable models could potentially replace black box models in criminal justice, healthcare and computer vision.},
  issue = {5},
  langid = {english},
  keywords = {Computer science,Criminology,Science,Statistics,technology and society},
  file = {/Users/marcel/Zotero/storage/IDAA3AS4/Rudin - 2019 - Stop explaining black box machine learning models for high stakes decisions and use interpretable mo.pdf}
}

@article{rumelhartLearningRepresentationsBackpropagating1986,
  title = {Learning Representations by Back-Propagating Errors},
  author = {Rumelhart, David E. and Hinton, Geoffrey E. and Williams, Ronald J.},
  date = {1986-10},
  journaltitle = {Nature},
  volume = {323},
  number = {6088},
  pages = {533--536},
  publisher = {Nature Publishing Group},
  issn = {1476-4687},
  doi = {10.1038/323533a0},
  url = {https://www.nature.com/articles/323533a0},
  urldate = {2022-05-01},
  abstract = {We describe a new learning procedure, back-propagation, for networks of neurone-like units. The procedure repeatedly adjusts the weights of the connections in the network so as to minimize a measure of the difference between the actual output vector of the net and the desired output vector. As a result of the weight adjustments, internal ‘hidden’ units which are not part of the input or output come to represent important features of the task domain, and the regularities in the task are captured by the interactions of these units. The ability to create useful new features distinguishes back-propagation from earlier, simpler methods such as the perceptron-convergence procedure1.},
  issue = {6088},
  langid = {english},
  keywords = {Humanities and Social Sciences,multidisciplinary,Science},
  file = {/Users/marcel/Zotero/storage/V9Q3ANZV/Rumelhart et al. - 1986 - Learning representations by back-propagating error.pdf;/Users/marcel/Zotero/storage/2BXPTRL8/323533a0.html}
}

@unpublished{satorrasEquivariantNormalizingFlows2021,
  title = {E(n) {{Equivariant Normalizing Flows}}},
  author = {Satorras, Victor Garcia and Hoogeboom, Emiel and Fuchs, Fabian B. and Posner, Ingmar and Welling, Max},
  date = {2021-06-08},
  eprint = {2105.09016},
  eprinttype = {arXiv},
  eprintclass = {physics, stat},
  url = {http://arxiv.org/abs/2105.09016},
  urldate = {2021-07-27},
  abstract = {This paper introduces a generative model equivariant to Euclidean symmetries: E(n) Equivariant Normalizing Flows (E-NFs). To construct E-NFs, we take the discriminative E(n) graph neural networks and integrate them as a differential equation to obtain an invertible equivariant function: a continuous-time normalizing flow. We demonstrate that E-NFs considerably outperform baselines and existing methods from the literature on particle systems such as DW4 and LJ13, and on molecules from QM9 in terms of log-likelihood. To the best of our knowledge, this is the first flow that jointly generates molecule features and positions in 3D.},
  keywords = {Computer Science - Machine Learning,Physics - Chemical Physics,Statistics - Machine Learning},
  file = {/Users/marcel/Zotero/storage/5LKTQSVD/Satorras et al_2021_E(n) Equivariant Normalizing Flows.pdf;/Users/marcel/Zotero/storage/BEQ7KVA5/2105.html}
}

@online{satorrasEquivariantNormalizingFlows2022,
  title = {E(n) {{Equivariant Normalizing Flows}}},
  author = {Satorras, Victor Garcia and Hoogeboom, Emiel and Fuchs, Fabian B. and Posner, Ingmar and Welling, Max},
  date = {2022-01-14},
  eprint = {2105.09016},
  eprinttype = {arXiv},
  eprintclass = {physics, stat},
  url = {http://arxiv.org/abs/2105.09016},
  urldate = {2022-11-17},
  abstract = {This paper introduces a generative model equivariant to Euclidean symmetries: E(n) Equivariant Normalizing Flows (E-NFs). To construct E-NFs, we take the discriminative E(n) graph neural networks and integrate them as a differential equation to obtain an invertible equivariant function: a continuous-time normalizing flow. We demonstrate that E-NFs considerably outperform baselines and existing methods from the literature on particle systems such as DW4 and LJ13, and on molecules from QM9 in terms of log-likelihood. To the best of our knowledge, this is the first flow that jointly generates molecule features and positions in 3D.},
  pubstate = {prepublished},
  file = {/Users/marcel/Zotero/storage/7CKEQJ3P/Satorras et al. - 2022 - E(n) Equivariant Normalizing Flows.pdf}
}

@online{saysLiesDamnLies2019,
  title = {Lies, {{Damn Lies}}, {{And TOPS}}/{{Watt}}},
  author = {Says, Olaf},
  date = {2019-01-07T20:15:00+00:00},
  url = {https://semiengineering.com/lies-damn-lies-and-tops-watt/},
  urldate = {2022-05-01},
  abstract = {Lies, Damn Lies, And TOPS/Watt Questions you need to ask to make sure you understand AI hardware performance.},
  langid = {american},
  organization = {Semiconductor Engineering},
  file = {/Users/marcel/Zotero/storage/F788WCIK/lies-damn-lies-and-tops-watt.html}
}

@inproceedings{scariaLastClickWhy2014,
  title = {The Last Click: Why Users Give up Information Network Navigation},
  shorttitle = {The Last Click},
  booktitle = {Proceedings of the 7th {{ACM}} International Conference on {{Web}} Search and Data Mining},
  author = {Scaria, Aju Thalappillil and Philip, Rose Marie and West, Robert and Leskovec, Jure},
  date = {2014-02-24},
  pages = {213--222},
  publisher = {ACM},
  location = {New York New York USA},
  doi = {10.1145/2556195.2556232},
  url = {https://dl.acm.org/doi/10.1145/2556195.2556232},
  urldate = {2024-03-14},
  abstract = {An important part of finding information online involves clicking from page to page until an information need is fully satisfied. This is a complex task that can easily be frustrating and force users to give up prematurely. An empirical analysis of what makes users abandon click-based navigation tasks is hard, since most passively collected browsing logs do not specify the exact target page that a user was trying to reach. We propose to overcome this problem by using data collected via Wikispeedia, a Wikipedia-based humancomputation game, in which users are asked to navigate from a start page to an explicitly given target page (both Wikipedia articles) by only tracing hyperlinks between Wikipedia articles. Our contributions are two-fold. First, by analyzing the differences between successful and abandoned navigation paths, we aim to understand what types of behavior are indicative of users giving up their navigation task. We also investigate how users make use of back clicks during their navigation. We find that users prefer backtracking to high-degree nodes that serve as landmarks and hubs for exploring the network of pages. Second, based on our analysis, we build statistical models for predicting whether a user will finish or abandon a navigation task, and if the next action will be a back click. Being able to predict these events is important as it can potentially help us design more human-friendly browsing interfaces and retain users who would otherwise have given up navigating a website.},
  eventtitle = {{{WSDM}} 2014: {{Seventh ACM International Conference}} on {{Web Search}} and {{Data Mining}}},
  isbn = {978-1-4503-2351-2},
  langid = {english},
  file = {/Users/marcel/Zotero/storage/IKP2QGLS/Scaria et al. - 2014 - The last click why users give up information network navigation.pdf}
}

@online{schlichtkrullModelingRelationalData2017,
  title = {Modeling {{Relational Data}} with {{Graph Convolutional Networks}}},
  author = {Schlichtkrull, Michael and Kipf, Thomas N. and Bloem, Peter and family=Berg, given=Rianne, prefix=van den, useprefix=false and Titov, Ivan and Welling, Max},
  date = {2017-10-26},
  eprint = {1703.06103},
  eprinttype = {arXiv},
  eprintclass = {cs, stat},
  doi = {10.48550/arXiv.1703.06103},
  url = {http://arxiv.org/abs/1703.06103},
  urldate = {2024-02-14},
  abstract = {Knowledge graphs enable a wide variety of applications, including question answering and information retrieval. Despite the great effort invested in their creation and maintenance, even the largest (e.g., Yago, DBPedia or Wikidata) remain incomplete. We introduce Relational Graph Convolutional Networks (R-GCNs) and apply them to two standard knowledge base completion tasks: Link prediction (recovery of missing facts, i.e. subject-predicate-object triples) and entity classification (recovery of missing entity attributes). R-GCNs are related to a recent class of neural networks operating on graphs, and are developed specifically to deal with the highly multi-relational data characteristic of realistic knowledge bases. We demonstrate the effectiveness of R-GCNs as a stand-alone model for entity classification. We further show that factorization models for link prediction such as DistMult can be significantly improved by enriching them with an encoder model to accumulate evidence over multiple inference steps in the relational graph, demonstrating a large improvement of 29.8\% on FB15k-237 over a decoder-only baseline.},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Databases,Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/marcel/Zotero/storage/2G2878QI/Schlichtkrull et al. - 2017 - Modeling Relational Data with Graph Convolutional Networks.pdf;/Users/marcel/Zotero/storage/FSTQVLAZ/1703.html}
}

@article{senguptaGoingDeeperSpiking2019,
  title = {Going {{Deeper}} in {{Spiking Neural Networks}}: {{VGG}} and {{Residual Architectures}}},
  shorttitle = {Going {{Deeper}} in {{Spiking Neural Networks}}},
  author = {Sengupta, Abhronil and Ye, Yuting and Wang, Robert and Liu, Chiao and Roy, Kaushik},
  date = {2019},
  journaltitle = {Frontiers in Neuroscience},
  volume = {13},
  issn = {1662-453X},
  url = {https://www.frontiersin.org/article/10.3389/fnins.2019.00095},
  urldate = {2022-05-02},
  abstract = {Over the past few years, Spiking Neural Networks (SNNs) have become popular as a possible pathway to enable low-power event-driven neuromorphic hardware. However, their application in machine learning have largely been limited to very shallow neural network architectures for simple problems. In this paper, we propose a novel algorithmic technique for generating an SNN with a deep architecture, and demonstrate its effectiveness on complex visual recognition problems such as CIFAR-10 and ImageNet. Our technique applies to both VGG and Residual network architectures, with significantly better accuracy than the state-of-the-art. Finally, we present analysis of the sparse event-driven computations to demonstrate reduced hardware overhead when operating in the spiking domain.},
  file = {/Users/marcel/Zotero/storage/4GVJZPI7/Sengupta et al. - 2019 - Going Deeper in Spiking Neural Networks VGG and R.pdf}
}

@online{shakirmMachineLearningTrick2015,
  title = {Machine {{Learning Trick}} of the {{Day}} (3): {{Hutchinson}}'s {{Trick}}},
  shorttitle = {Machine {{Learning Trick}} of the {{Day}} (3)},
  author = {{SHAKIRM}},
  date = {2015-09-13T14:35:03+00:00},
  url = {https://blog.shakirm.com/2015/09/machine-learning-trick-of-the-day-3-hutchinsons-trick/},
  urldate = {2022-05-04},
  abstract = {Hutchinson’s estimator [cite key=’hutchinson1990stochastic’]~is a simple way to obtain a stochastic estimate of the trace of a matrix. This is a simple trick that uses randomisati…},
  langid = {british},
  organization = {The Spectator},
  file = {/Users/marcel/Zotero/storage/BPKRDN2K/machine-learning-trick-of-the-day-3-hutchinsons-trick.html}
}

@online{ShapeAnalysisGDP,
  title = {Shape {{Analysis}} - {{GDP}} @ {{MIT}}},
  url = {http://groups.csail.mit.edu/gdpgroup/6838_spring_2021.html},
  urldate = {2022-12-09},
  file = {/Users/marcel/Zotero/storage/5Z5KJ9CB/6838_spring_2021.html}
}

@article{shiPointCloudInpainting2022,
  title = {Point Cloud Inpainting with Normal-Based Feature Matching},
  author = {Shi, Yu and Yang, Chuanchuan},
  date = {2022-04-01},
  journaltitle = {Multimedia Systems},
  shortjournal = {Multimedia Systems},
  volume = {28},
  number = {2},
  pages = {521--527},
  issn = {1432-1882},
  doi = {10.1007/s00530-021-00856-9},
  url = {https://doi.org/10.1007/s00530-021-00856-9},
  urldate = {2022-09-30},
  abstract = {With the development of LiDAR technology, point cloud as a data format for representing 3D objects has become more and more widely used. However, negative factors like occlusion or the unfavorable properties of the material surface will lead to the presence of geometric deficiencies, which usually exhibit as holes in point clouds. To solve this kind of problem, point cloud inpainting is proposed. In this paper, we propose an improved point cloud inpainting method, which searches for the proper context for the detected hole and then adopts a more efficient feature matching strategy to refine data source in the hole-filling step by aligning a set of corresponding feature points. Experimental result with comparisons demonstrates its competitive effectiveness with an average 14\% gain in GPSNR and better inpainting quality from a subjective perspective.},
  langid = {english},
  keywords = {Inpainting,Normal-based feature matching,Point cloud},
  file = {/Users/marcel/Zotero/storage/3WTRZJAM/Shi and Yang - 2022 - Point cloud inpainting with normal-based feature m.pdf}
}

@video{simonsinstituteBiologicallyPlausibleDeep2018,
  entrysubtype = {video},
  title = {Towards {{Biologically Plausible Deep Learning}}: ...},
  shorttitle = {Towards {{Biologically Plausible Deep Learning}}},
  editor = {{Simons Institute}},
  editortype = {director},
  date = {2018-04-16},
  url = {https://www.youtube.com/watch?v=d6hXF3EMv_E},
  urldate = {2022-04-19},
  abstract = {Asja Fischer, University of Bonn https://simons.berkeley.edu/talks/asj... Computational Theories of the Brain}
}

@video{simonsinstitutePredictiveCodingModels2018,
  entrysubtype = {video},
  title = {Predictive {{Coding Models}} of {{Perception}}},
  editor = {{Simons Institute}},
  editortype = {director},
  date = {2018-04-16},
  url = {https://youtu.be/P0yVuoATjzs?t=1783},
  urldate = {2022-05-02},
  abstract = {David Cox, Harvard University https://simons.berkeley.edu/talks/dav... Computational Theories of the Brain}
}

@article{simonyanVeryDeepConvolutional2014,
  title = {Very {{Deep Convolutional Networks}} for {{Large-Scale Image Recognition}}},
  author = {Simonyan, Karen and Zisserman, Andrew},
  date = {2014-09-04},
  doi = {10.48550/arXiv.1409.1556},
  url = {https://arxiv.org/abs/1409.1556v6},
  urldate = {2022-12-18},
  abstract = {In this work we investigate the effect of the convolutional network depth on its accuracy in the large-scale image recognition setting. Our main contribution is a thorough evaluation of networks of increasing depth using an architecture with very small (3x3) convolution filters, which shows that a significant improvement on the prior-art configurations can be achieved by pushing the depth to 16-19 weight layers. These findings were the basis of our ImageNet Challenge 2014 submission, where our team secured the first and the second places in the localisation and classification tracks respectively. We also show that our representations generalise well to other datasets, where they achieve state-of-the-art results. We have made our two best-performing ConvNet models publicly available to facilitate further research on the use of deep visual representations in computer vision.},
  langid = {english},
  file = {/Users/marcel/Zotero/storage/44LQEP8A/Simonyan and Zisserman - 2014 - Very Deep Convolutional Networks for Large-Scale I.pdf}
}

@online{simonyanVeryDeepConvolutional2015,
  title = {Very {{Deep Convolutional Networks}} for {{Large-Scale Image Recognition}}},
  author = {Simonyan, Karen and Zisserman, Andrew},
  date = {2015-04-10},
  eprint = {1409.1556},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.1409.1556},
  url = {http://arxiv.org/abs/1409.1556},
  urldate = {2023-05-09},
  abstract = {In this work we investigate the effect of the convolutional network depth on its accuracy in the large-scale image recognition setting. Our main contribution is a thorough evaluation of networks of increasing depth using an architecture with very small (3x3) convolution filters, which shows that a significant improvement on the prior-art configurations can be achieved by pushing the depth to 16-19 weight layers. These findings were the basis of our ImageNet Challenge 2014 submission, where our team secured the first and the second places in the localisation and classification tracks respectively. We also show that our representations generalise well to other datasets, where they achieve state-of-the-art results. We have made our two best-performing ConvNet models publicly available to facilitate further research on the use of deep visual representations in computer vision.},
  pubstate = {prepublished},
  version = {6},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {/Users/marcel/Zotero/storage/R5U3Z3VJ/Simonyan and Zisserman - 2015 - Very Deep Convolutional Networks for Large-Scale I.pdf;/Users/marcel/Zotero/storage/L57VEXEX/1409.html}
}

@online{snellLearningDistillingContext2022,
  title = {Learning by {{Distilling Context}}},
  author = {Snell, Charlie and Klein, Dan and Zhong, Ruiqi},
  date = {2022-09-30},
  eprint = {2209.15189},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2209.15189},
  url = {http://arxiv.org/abs/2209.15189},
  urldate = {2025-02-23},
  abstract = {Language models significantly benefit from context tokens, such as prompts or scratchpads. They perform better when prompted with informative instructions, and they acquire new reasoning capabilities by generating a scratch-pad before predicting the final answers. However, they do not \textbackslash textit\{internalize\} these performance gains, which disappear when the context tokens are gone. Our work proposes to apply context distillation so that a language model can improve itself by internalizing these gains. Concretely, given a synthetic unlabeled input for the target task, we condition the model on ``[instructions] + [task-input]'' to predict ``[scratch-pad] + [final answer]''; then we fine-tune the same model to predict its own ``[final answer]'' conditioned on the ``[task-input]'', without seeing the ``[instructions]'' or using the ``[scratch-pad]''. We show that context distillation is a general method to train language models, and it can effectively internalize 3 types of training signals. First, it can internalize abstract task instructions and explanations, so we can iteratively update the model parameters with new instructions and overwrite old ones. Second, it can internalize step-by-step reasoning for complex tasks (e.g., 8-digit addition), and such a newly acquired capability proves to be useful for other downstream tasks. Finally, it can internalize concrete training examples, and it outperforms directly learning with gradient descent by 9\textbackslash\% on the SPIDER Text-to-SQL dataset; furthermore, combining context distillation operations can internalize more training examples than the context window size allows.},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
  file = {/Users/marcel/Zotero/storage/ZW2UVZEL/Snell et al. - 2022 - Learning by Distilling Context.pdf;/Users/marcel/Zotero/storage/N47KRU34/2209.html}
}

@article{songCompetitiveHebbianLearning2000,
  title = {Competitive {{Hebbian}} Learning through Spike-Timing-Dependent Synaptic Plasticity},
  author = {Song, Sen and Miller, Kenneth D. and Abbott, L. F.},
  date = {2000-09},
  journaltitle = {Nature Neuroscience},
  shortjournal = {Nat Neurosci},
  volume = {3},
  number = {9},
  pages = {919--926},
  publisher = {Nature Publishing Group},
  issn = {1546-1726},
  doi = {10.1038/78829},
  url = {https://www.nature.com/articles/nn0900_919},
  urldate = {2022-05-02},
  abstract = {Hebbian models of development and learning require both activity-dependent synaptic plasticity and a mechanism that induces competition between different synapses. One form of experimentally observed long-term synaptic plasticity, which we call spike-timing-dependent plasticity (STDP), depends on the relative timing of pre- and postsynaptic action potentials. In modeling studies, we find that this form of synaptic modification can automatically balance synaptic strengths to make postsynaptic firing irregular but more sensitive to presynaptic spike timing. It has been argued that neurons in vivo operate in such a balanced regime. Synapses modifiable by STDP compete for control of the timing of postsynaptic action potentials. Inputs that fire the postsynaptic neuron with short latency or that act in correlated groups are able to compete most successfully and develop strong synapses, while synapses of longer-latency or less-effective inputs are weakened.},
  issue = {9},
  langid = {english},
  keywords = {Animal Genetics and Genomics,Behavioral Sciences,Biological Techniques,Biomedicine,general,Neurobiology,Neurosciences},
  file = {/Users/marcel/Zotero/storage/QMAZ8TRE/Song et al. - 2000 - Competitive Hebbian learning through spike-timing-.pdf;/Users/marcel/Zotero/storage/DTGFD2KJ/nn0900_919.html}
}

@article{sorbaroOptimizingEnergyConsumption2020,
  title = {Optimizing the {{Energy Consumption}} of {{Spiking Neural Networks}} for {{Neuromorphic Applications}}},
  author = {Sorbaro, Martino and Liu, Qian and Bortone, Massimo and Sheik, Sadique},
  date = {2020},
  journaltitle = {Frontiers in Neuroscience},
  volume = {14},
  issn = {1662-453X},
  url = {https://www.frontiersin.org/article/10.3389/fnins.2020.00662},
  urldate = {2022-05-01},
  abstract = {In the last few years, spiking neural networks (SNNs) have been demonstrated to perform on par with regular convolutional neural networks. Several works have proposed methods to convert a pre-trained CNN to a Spiking CNN without a significant sacrifice of performance. We demonstrate first that quantization-aware training of CNNs leads to better accuracy in SNNs. One of the benefits of converting CNNs to spiking CNNs is to leverage the sparse computation of SNNs and consequently perform equivalent computation at a lower energy consumption. Here we propose an optimization strategy to train efficient spiking networks with lower energy consumption, while maintaining similar accuracy levels. We demonstrate results on the MNIST-DVS and CIFAR-10 datasets.},
  file = {/Users/marcel/Zotero/storage/9PVQ2XC5/Sorbaro et al. - 2020 - Optimizing the Energy Consumption of Spiking Neura.pdf}
}

@article{srivastavaDropoutSimpleWay2014,
  title = {Dropout: {{A Simple Way}} to {{Prevent Neural Networks}} from {{Overfitting}}},
  shorttitle = {Dropout},
  author = {Srivastava, Nitish and Hinton, Geoffrey and Krizhevsky, Alex and Sutskever, Ilya and Salakhutdinov, Ruslan},
  date = {2014},
  journaltitle = {Journal of Machine Learning Research},
  volume = {15},
  number = {56},
  pages = {1929--1958},
  issn = {1533-7928},
  url = {http://jmlr.org/papers/v15/srivastava14a.html},
  urldate = {2022-05-02},
  abstract = {Deep neural nets with a large number of parameters are very powerful machine learning systems. However, overfitting is a serious problem in such networks. Large networks are also slow to use, making it difficult to deal with overfitting by combining the predictions of many different large neural nets at test time. Dropout is a technique for addressing this problem. The key idea is to randomly drop units (along with their connections) from the neural network during training. This prevents units from co-adapting too much. During training, dropout samples from an exponential number of different âthinnedâ networks. At test time, it is easy to approximate the effect of averaging the predictions of all these thinned networks by simply using a single unthinned network that has smaller weights. This significantly reduces overfitting and gives major improvements over other regularization methods. We show that dropout improves the performance of neural networks on supervised learning tasks in vision, speech recognition, document classification and computational biology, obtaining state-of-the-art results on many benchmark data sets.},
  file = {/Users/marcel/Zotero/storage/Q9579ZTL/Srivastava et al. - 2014 - Dropout A Simple Way to Prevent Neural Networks f.pdf}
}

@book{strogatzNonlinearDynamicsChaos2015,
  title = {Nonlinear Dynamics and Chaos: With Applications to Physics, Biology, Chemistry, and Engineering},
  shorttitle = {Nonlinear Dynamics and Chaos},
  author = {Strogatz, Steven H.},
  date = {2015},
  edition = {Second edition},
  publisher = {Westview Press, a member of the Perseus Books Group},
  location = {Boulder, CO},
  isbn = {978-0-8133-4910-7},
  langid = {english},
  pagetotal = {513},
  keywords = {Chaotic behavior in systems,Dynamics,Nonlinear theories},
  annotation = {OCLC: ocn842877119},
  file = {/Users/marcel/Zotero/storage/QECFM4IL/Strogatz - 2015 - Nonlinear dynamics and chaos with applications to physics, biology, chemistry, and engineering.pdf}
}

@online{StudentPrivacyPolicy,
  title = {Student Privacy Policy | {{Compliance}}},
  url = {https://compliance.admin.ox.ac.uk/student-privacy-policy#collapse968121},
  urldate = {2022-04-10}
}

@online{sunLearningLearnTest2024,
  title = {Learning to ({{Learn}} at {{Test Time}}): {{RNNs}} with {{Expressive Hidden States}}},
  shorttitle = {Learning to ({{Learn}} at {{Test Time}})},
  author = {Sun, Yu and Li, Xinhao and Dalal, Karan and Xu, Jiarui and Vikram, Arjun and Zhang, Genghan and Dubois, Yann and Chen, Xinlei and Wang, Xiaolong and Koyejo, Sanmi and Hashimoto, Tatsunori and Guestrin, Carlos},
  date = {2024-08-10},
  eprint = {2407.04620},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2407.04620},
  url = {http://arxiv.org/abs/2407.04620},
  urldate = {2024-09-27},
  abstract = {Self-attention performs well in long context but has quadratic complexity. Existing RNN layers have linear complexity, but their performance in long context is limited by the expressive power of their hidden state. We propose a new class of sequence modeling layers with linear complexity and an expressive hidden state. The key idea is to make the hidden state a machine learning model itself, and the update rule a step of self-supervised learning. Since the hidden state is updated by training even on test sequences, our layers are called Test-Time Training (TTT) layers. We consider two instantiations: TTT-Linear and TTT-MLP, whose hidden state is a linear model and a two-layer MLP respectively. We evaluate our instantiations at the scale of 125M to 1.3B parameters, comparing with a strong Transformer and Mamba, a modern RNN. Both TTT-Linear and TTT-MLP match or exceed the baselines. Similar to Transformer, they can keep reducing perplexity by conditioning on more tokens, while Mamba cannot after 16k context. With preliminary systems optimization, TTT-Linear is already faster than Transformer at 8k context and matches Mamba in wall-clock time. TTT-MLP still faces challenges in memory I/O, but shows larger potential in long context, pointing to a promising direction for future research.},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Machine Learning},
  file = {/Users/marcel/Zotero/storage/A22I4Z7J/Sun et al. - 2024 - Learning to (Learn at Test Time) RNNs with Expressive Hidden States.pdf;/Users/marcel/Zotero/storage/5V4AM3IM/2407.html}
}

@online{sunLearningLearnTest2024a,
  title = {Learning to ({{Learn}} at {{Test Time}})},
  author = {Sun, Yu and Li, Xinhao and Dalal, Karan and Hsu, Chloe and Koyejo, Sanmi and Guestrin, Carlos and Wang, Xiaolong and Hashimoto, Tatsunori and Chen, Xinlei},
  date = {2024-01-07},
  eprint = {2310.13807},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2310.13807},
  url = {http://arxiv.org/abs/2310.13807},
  urldate = {2025-01-30},
  abstract = {We reformulate the problem of supervised learning as learning to learn with two nested loops (i.e. learning problems). The inner loop learns on each individual instance with self-supervision before final prediction. The outer loop learns the self-supervised task used by the inner loop, such that its final prediction improves. Our inner loop turns out to be equivalent to linear attention when the inner-loop learner is only a linear model, and to self-attention when it is a kernel estimator. For practical comparison with linear or self-attention layers, we replace each of them in a transformer with an inner loop, so our outer loop is equivalent to training the architecture. When each inner-loop learner is a neural network, our approach vastly outperforms transformers with linear attention on ImageNet from 224 x 224 raw pixels in both accuracy and FLOPs, while (regular) transformers cannot run.},
  pubstate = {prepublished},
  keywords = {Computer Science - Machine Learning},
  file = {/Users/marcel/Zotero/storage/CIK62WSA/Sun et al. - 2024 - Learning to (Learn at Test Time).pdf;/Users/marcel/Zotero/storage/K6TCB5EX/2310.html}
}

@online{suRoFormerEnhancedTransformer2023,
  title = {{{RoFormer}}: {{Enhanced Transformer}} with {{Rotary Position Embedding}}},
  shorttitle = {{{RoFormer}}},
  author = {Su, Jianlin and Lu, Yu and Pan, Shengfeng and Murtadha, Ahmed and Wen, Bo and Liu, Yunfeng},
  date = {2023-11-08},
  eprint = {2104.09864},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2104.09864},
  url = {http://arxiv.org/abs/2104.09864},
  urldate = {2024-03-16},
  abstract = {Position encoding recently has shown effective in the transformer architecture. It enables valuable supervision for dependency modeling between elements at different positions of the sequence. In this paper, we first investigate various methods to integrate positional information into the learning process of transformer-based language models. Then, we propose a novel method named Rotary Position Embedding(RoPE) to effectively leverage the positional information. Specifically, the proposed RoPE encodes the absolute position with a rotation matrix and meanwhile incorporates the explicit relative position dependency in self-attention formulation. Notably, RoPE enables valuable properties, including the flexibility of sequence length, decaying inter-token dependency with increasing relative distances, and the capability of equipping the linear self-attention with relative position encoding. Finally, we evaluate the enhanced transformer with rotary position embedding, also called RoFormer, on various long text classification benchmark datasets. Our experiments show that it consistently overcomes its alternatives. Furthermore, we provide a theoretical analysis to explain some experimental results. RoFormer is already integrated into Huggingface: \textbackslash url\{https://huggingface.co/docs/transformers/model\_doc/roformer\}.},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Machine Learning},
  file = {/Users/marcel/Zotero/storage/VE87NACF/Su et al. - 2023 - RoFormer Enhanced Transformer with Rotary Position Embedding.pdf;/Users/marcel/Zotero/storage/MVII7PMD/2104.html}
}

@online{szeEfficientProcessingDeep2017,
  title = {Efficient {{Processing}} of {{Deep Neural Networks}}: {{A Tutorial}} and {{Survey}}},
  shorttitle = {Efficient {{Processing}} of {{Deep Neural Networks}}},
  author = {Sze, Vivienne and Chen, Yu-Hsin and Yang, Tien-Ju and Emer, Joel},
  date = {2017-08-13},
  eprint = {1703.09039},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.1703.09039},
  url = {http://arxiv.org/abs/1703.09039},
  urldate = {2023-11-11},
  abstract = {Deep neural networks (DNNs) are currently widely used for many artificial intelligence (AI) applications including computer vision, speech recognition, and robotics. While DNNs deliver state-of-the-art accuracy on many AI tasks, it comes at the cost of high computational complexity. Accordingly, techniques that enable efficient processing of DNNs to improve energy efficiency and throughput without sacrificing application accuracy or increasing hardware cost are critical to the wide deployment of DNNs in AI systems. This article aims to provide a comprehensive tutorial and survey about the recent advances towards the goal of enabling efficient processing of DNNs. Specifically, it will provide an overview of DNNs, discuss various hardware platforms and architectures that support DNNs, and highlight key trends in reducing the computation cost of DNNs either solely via hardware design changes or via joint hardware design and DNN algorithm changes. It will also summarize various development resources that enable researchers and practitioners to quickly get started in this field, and highlight important benchmarking metrics and design considerations that should be used for evaluating the rapidly growing number of DNN hardware designs, optionally including algorithmic co-designs, being proposed in academia and industry. The reader will take away the following concepts from this article: understand the key design considerations for DNNs; be able to evaluate different DNN hardware implementations with benchmarks and comparison metrics; understand the trade-offs between various hardware architectures and platforms; be able to evaluate the utility of various DNN design techniques for efficient processing; and understand recent implementation trends and opportunities.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {/Users/marcel/Zotero/storage/LA3HSG26/Sze et al. - 2017 - Efficient Processing of Deep Neural Networks A Tutorial and Survey.pdf;/Users/marcel/Zotero/storage/LSRBH8HT/1703.html}
}

@online{tanEfficientNetRethinkingModel2020,
  title = {{{EfficientNet}}: {{Rethinking Model Scaling}} for {{Convolutional Neural Networks}}},
  shorttitle = {{{EfficientNet}}},
  author = {Tan, Mingxing and Le, Quoc V.},
  date = {2020-09-11},
  eprint = {1905.11946},
  eprinttype = {arXiv},
  eprintclass = {cs, stat},
  doi = {10.48550/arXiv.1905.11946},
  url = {http://arxiv.org/abs/1905.11946},
  urldate = {2022-12-18},
  abstract = {Convolutional Neural Networks (ConvNets) are commonly developed at a fixed resource budget, and then scaled up for better accuracy if more resources are available. In this paper, we systematically study model scaling and identify that carefully balancing network depth, width, and resolution can lead to better performance. Based on this observation, we propose a new scaling method that uniformly scales all dimensions of depth/width/resolution using a simple yet highly effective compound coefficient. We demonstrate the effectiveness of this method on scaling up MobileNets and ResNet. To go even further, we use neural architecture search to design a new baseline network and scale it up to obtain a family of models, called EfficientNets, which achieve much better accuracy and efficiency than previous ConvNets. In particular, our EfficientNet-B7 achieves state-of-the-art 84.3\% top-1 accuracy on ImageNet, while being 8.4x smaller and 6.1x faster on inference than the best existing ConvNet. Our EfficientNets also transfer well and achieve state-of-the-art accuracy on CIFAR-100 (91.7\%), Flowers (98.8\%), and 3 other transfer learning datasets, with an order of magnitude fewer parameters. Source code is at https://github.com/tensorflow/tpu/tree/master/models/official/efficientnet.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/marcel/Zotero/storage/WYXXCQC8/Tan and Le - 2020 - EfficientNet Rethinking Model Scaling for Convolu.pdf;/Users/marcel/Zotero/storage/CNSIYMWH/1905.html}
}

@video{theuniversityofchicagoYaliAmitBiologically2012,
  entrysubtype = {video},
  title = {Yali {{Amit}} on {{Biologically Plausible Neural Networks}} for {{Invariant Visual Recognition}}},
  editor = {{The University of Chicago}},
  editortype = {director},
  date = {2012-04-12},
  url = {https://www.youtube.com/watch?v=Xj_yaBaKxPA},
  urldate = {2022-04-19},
  abstract = {"Biologically Plausible Neural Networks for Invariant Visual Recognition" Yali Amit Partha Niyogi Memorial Conference: Computer Science December 5, 2011 This conference is in honor of Partha Niyogi, the Louis Block Professor in Computer Science and Statistics at the University of Chicago. Partha lost his battle with cancer in October of 2010, at the age of 43.   Partha made fundamental contributions to a variety of fields including language evolution, statistical inference, and speech recognition. The underlying themes of learning from observations and a rigorous basis for algorithms and models permeated his work.   This conference will reflect Partha's interests and pay honor to his broad vision and unique insights. The influence of his ideas and the impact on several fields will be highlighted. ➡ Subscribe: http://bit.ly/UCHICAGOytSubscribe    About \#UChicago: Since its founding in 1890, the University of Chicago has been a destination for rigorous inquiry and field-defining research. This transformative academic experience empowers students and scholars to challenge conventional thinking in pursuit of original ideas. \#UChicago on the Web: Home: http://bit.ly/UCHICAGO-homepage News: http://bit.ly/UCHICAGO-news  Facebook: http://bit.ly/UCHICAGO-FB   Twitter: http://bit.ly/UCHICAGO-TW    Instagram: http://bit.ly/UCHICAGO-IG   University of Chicago on YouTube: https://www.youtube.com/uchicago *** ACCESSIBILITY: If you experience any technical difficulties with this video or would like to make an accessibility-related request, please email digicomm@uchicago.edu.}
}

@unpublished{thomasTensorFieldNetworks2018,
  title = {Tensor Field Networks: {{Rotation-}} and Translation-Equivariant Neural Networks for {{3D}} Point Clouds},
  shorttitle = {Tensor Field Networks},
  author = {Thomas, Nathaniel and Smidt, Tess and Kearnes, Steven and Yang, Lusann and Li, Li and Kohlhoff, Kai and Riley, Patrick},
  date = {2018-05-18},
  eprint = {1802.08219},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/1802.08219},
  urldate = {2021-07-27},
  abstract = {We introduce tensor field neural networks, which are locally equivariant to 3D rotations, translations, and permutations of points at every layer. 3D rotation equivariance removes the need for data augmentation to identify features in arbitrary orientations. Our network uses filters built from spherical harmonics; due to the mathematical consequences of this filter choice, each layer accepts as input (and guarantees as output) scalars, vectors, and higher-order tensors, in the geometric sense of these terms. We demonstrate the capabilities of tensor field networks with tasks in geometry, physics, and chemistry.},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing},
  file = {/Users/marcel/Zotero/storage/67633PJV/Thomas et al_2018_Tensor field networks.pdf;/Users/marcel/Zotero/storage/2Q6UVWK7/1802.html}
}

@inproceedings{tilletTritonIntermediateLanguage2019,
  title = {Triton: An Intermediate Language and Compiler for Tiled Neural Network Computations},
  shorttitle = {Triton},
  booktitle = {Proceedings of the 3rd {{ACM SIGPLAN International Workshop}} on {{Machine Learning}} and {{Programming Languages}}},
  author = {Tillet, Philippe and Kung, H. T. and Cox, David},
  date = {2019-06-22},
  pages = {10--19},
  publisher = {ACM},
  location = {Phoenix AZ USA},
  doi = {10.1145/3315508.3329973},
  url = {https://dl.acm.org/doi/10.1145/3315508.3329973},
  urldate = {2023-05-09},
  abstract = {The validation and deployment of novel research ideas in the field of Deep Learning is often limited by the availability of efficient compute kernels for certain basic primitives. In particular, operations that cannot leverage existing vendor libraries (e.g., cuBLAS, cuDNN) are at risk of facing poor device utilization unless custom implementations are written by experts – usually at the expense of portability. For this reason, the development of new programming abstractions for specifying custom Deep Learning workloads at a minimal performance cost has become crucial.},
  eventtitle = {{{PLDI}} '19: 40th {{ACM SIGPLAN Conference}} on {{Programming Language Design}} and {{Implementation}}},
  isbn = {978-1-4503-6719-6},
  langid = {english},
  file = {/Users/marcel/Zotero/storage/XY29HVWP/Tillet et al. - 2019 - Triton an intermediate language and compiler for .pdf}
}

@unpublished{toppingUnderstandingOversquashingBottlenecks2022,
  title = {Understanding Over-Squashing and Bottlenecks on Graphs via Curvature},
  author = {Topping, Jake and Di Giovanni, Francesco and Chamberlain, Benjamin Paul and Dong, Xiaowen and Bronstein, Michael M.},
  date = {2022-03-16},
  eprint = {2111.14522},
  eprinttype = {arXiv},
  eprintclass = {cs, stat},
  url = {http://arxiv.org/abs/2111.14522},
  urldate = {2022-04-04},
  abstract = {Most graph neural networks (GNNs) use the message passing paradigm, in which node features are propagated on the input graph. Recent works pointed to the distortion of information flowing from distant nodes as a factor limiting the efficiency of message passing for tasks relying on long-distance interactions. This phenomenon, referred to as 'over-squashing', has been heuristically attributed to graph bottlenecks where the number of \$k\$-hop neighbors grows rapidly with \$k\$. We provide a precise description of the over-squashing phenomenon in GNNs and analyze how it arises from bottlenecks in the graph. For this purpose, we introduce a new edge-based combinatorial curvature and prove that negatively curved edges are responsible for the over-squashing issue. We also propose and experimentally test a curvature-based graph rewiring method to alleviate the over-squashing.},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/marcel/Zotero/storage/A58QX3KW/Topping et al. - 2022 - Understanding over-squashing and bottlenecks on gr.pdf;/Users/marcel/Zotero/storage/8JWI5C2P/2111.html}
}

@online{TorchBmmPyTorch,
  title = {Torch.Bmm — {{PyTorch}} 2.0 Documentation},
  url = {https://pytorch.org/docs/stable/generated/torch.bmm.html},
  urldate = {2023-05-15},
  file = {/Users/marcel/Zotero/storage/NDU83EQE/torch.bmm.html}
}

@misc{torchdiffeq,
  title = {Torchdiffeq},
  author = {Chen, Ricky T. Q.},
  date = {2018},
  url = {https://github.com/rtqichen/torchdiffeq}
}

@online{TorchScriptPyTorch13,
  title = {{{TorchScript}} — {{PyTorch}} 1.13 Documentation},
  url = {https://pytorch.org/docs/stable/jit.html},
  urldate = {2022-12-18},
  file = {/Users/marcel/Zotero/storage/MPIJUEGA/jit.html}
}

@online{TorchTensorScatter,
  title = {Torch.{{Tensor}}.Scatter\_ — {{PyTorch}} 1.12 Documentation},
  url = {https://pytorch.org/docs/stable/generated/torch.Tensor.scatter_.html#torch.Tensor.scatter_},
  urldate = {2022-09-23},
  file = {/Users/marcel/Zotero/storage/JMJMT6ZB/torch.Tensor.scatter_.html}
}

@online{touvronLlamaOpenFoundation2023,
  title = {Llama 2: {{Open Foundation}} and {{Fine-Tuned Chat Models}}},
  shorttitle = {Llama 2},
  author = {Touvron, Hugo and Martin, Louis and Stone, Kevin and Albert, Peter and Almahairi, Amjad and Babaei, Yasmine and Bashlykov, Nikolay and Batra, Soumya and Bhargava, Prajjwal and Bhosale, Shruti and Bikel, Dan and Blecher, Lukas and Ferrer, Cristian Canton and Chen, Moya and Cucurull, Guillem and Esiobu, David and Fernandes, Jude and Fu, Jeremy and Fu, Wenyin and Fuller, Brian and Gao, Cynthia and Goswami, Vedanuj and Goyal, Naman and Hartshorn, Anthony and Hosseini, Saghar and Hou, Rui and Inan, Hakan and Kardas, Marcin and Kerkez, Viktor and Khabsa, Madian and Kloumann, Isabel and Korenev, Artem and Koura, Punit Singh and Lachaux, Marie-Anne and Lavril, Thibaut and Lee, Jenya and Liskovich, Diana and Lu, Yinghai and Mao, Yuning and Martinet, Xavier and Mihaylov, Todor and Mishra, Pushkar and Molybog, Igor and Nie, Yixin and Poulton, Andrew and Reizenstein, Jeremy and Rungta, Rashi and Saladi, Kalyan and Schelten, Alan and Silva, Ruan and Smith, Eric Michael and Subramanian, Ranjan and Tan, Xiaoqing Ellen and Tang, Binh and Taylor, Ross and Williams, Adina and Kuan, Jian Xiang and Xu, Puxin and Yan, Zheng and Zarov, Iliyan and Zhang, Yuchen and Fan, Angela and Kambadur, Melanie and Narang, Sharan and Rodriguez, Aurelien and Stojnic, Robert and Edunov, Sergey and Scialom, Thomas},
  date = {2023-07-19},
  eprint = {2307.09288},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2307.09288},
  url = {http://arxiv.org/abs/2307.09288},
  urldate = {2024-03-16},
  abstract = {In this work, we develop and release Llama 2, a collection of pretrained and fine-tuned large language models (LLMs) ranging in scale from 7 billion to 70 billion parameters. Our fine-tuned LLMs, called Llama 2-Chat, are optimized for dialogue use cases. Our models outperform open-source chat models on most benchmarks we tested, and based on our human evaluations for helpfulness and safety, may be a suitable substitute for closed-source models. We provide a detailed description of our approach to fine-tuning and safety improvements of Llama 2-Chat in order to enable the community to build on our work and contribute to the responsible development of LLMs.},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
  file = {/Users/marcel/Zotero/storage/9DTGVZ7K/Touvron et al. - 2023 - Llama 2 Open Foundation and Fine-Tuned Chat Models.pdf;/Users/marcel/Zotero/storage/SWD7MFA5/2307.html}
}

@article{tsitourasRungeKuttaPairs2011,
  title = {Runge–{{Kutta}} Pairs of Order 5(4) Satisfying Only the First Column Simplifying Assumption},
  author = {Tsitouras, Charalampos},
  date = {2011-07-01},
  journaltitle = {Computers \& Mathematics with Applications},
  shortjournal = {Computers \& Mathematics with Applications},
  volume = {62},
  pages = {770--775},
  doi = {10.1016/j.camwa.2011.06.002},
  abstract = {Among the most popular methods for the solution of the Initial Value Problem are the Runge–Kutta pairs of orders 5 and 4. These methods can be derived solving a system of nonlinear equations for its coefficients. To achieve this, we usually admit various simplifying assumptions. The most common of them are the so-called row simplifying assumptions. Here we neglect them and present an algorithm for the construction of Runge–Kutta pairs of orders 5 and 4 based only in the first column simplifying assumption. The result is a pair that outperforms other known pairs in the bibliography when tested to the standard set of problems of DETEST. A cost free fourth order formula is also derived for handling dense output.},
  file = {/Users/marcel/Zotero/storage/3WX9KIZ5/Tsitouras - 2011 - Runge–Kutta pairs of order 5(4) satisfying only th.pdf}
}

@online{Ttumiel,
  title = {Ttumiel},
  url = {https://ttumiel.github.io/},
  urldate = {2022-05-05},
  abstract = {My personal projects.},
  file = {/Users/marcel/Zotero/storage/27PAUQJ6/replacing-bn.html}
}

@article{TutorialSETransformation,
  title = {A Tutorial on {{SE}}(3) Transformation Parameterizations and on-Manifold Optimization},
  file = {/Users/marcel/Zotero/storage/8EPDIP9N/_}
}

@online{unknownWikipediaGame2022,
  title = {The {{Wikipedia Game}}},
  author = {Unknown},
  date = {2022},
  url = {https://www.thewikipediagame.com/},
  urldate = {2024-03-15},
  abstract = {A game where you compete with friends and family to race from one Wikipedia page to another in the least number of steps/links.},
  langid = {english},
  file = {/Users/marcel/Zotero/storage/U37TKBWL/www.thewikipediagame.com.html}
}

@online{valmeekamPlanningAbilitiesLarge2023,
  title = {On the {{Planning Abilities}} of {{Large Language Models}} : {{A Critical Investigation}}},
  shorttitle = {On the {{Planning Abilities}} of {{Large Language Models}}},
  author = {Valmeekam, Karthik and Marquez, Matthew and Sreedharan, Sarath and Kambhampati, Subbarao},
  date = {2023-11-06},
  eprint = {2305.15771},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2305.15771},
  url = {http://arxiv.org/abs/2305.15771},
  urldate = {2024-03-15},
  abstract = {Intrigued by the claims of emergent reasoning capabilities in LLMs trained on general web corpora, in this paper, we set out to investigate their planning capabilities. We aim to evaluate (1) the effectiveness of LLMs in generating plans autonomously in commonsense planning tasks and (2) the potential of LLMs in LLM-Modulo settings where they act as a source of heuristic guidance for external planners and verifiers. We conduct a systematic study by generating a suite of instances on domains similar to the ones employed in the International Planning Competition and evaluate LLMs in two distinct modes: autonomous and heuristic. Our findings reveal that LLMs' ability to generate executable plans autonomously is rather limited, with the best model (GPT-4) having an average success rate of \textasciitilde 12\% across the domains. However, the results in the LLM-Modulo setting show more promise. In the LLM-Modulo setting, we demonstrate that LLM-generated plans can improve the search process for underlying sound planners and additionally show that external verifiers can help provide feedback on the generated plans and back-prompt the LLM for better plan generation.},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence},
  file = {/Users/marcel/Zotero/storage/R8BEXJ8J/Valmeekam et al. - 2023 - On the Planning Abilities of Large Language Models  A Critical Investigation.pdf;/Users/marcel/Zotero/storage/5NLWYN4M/2305.html}
}

@article{vandermauseActiveLearningReactive2022,
  title = {Active Learning of Reactive {{Bayesian}} Force Fields: {{Application}} to Heterogeneous Hydrogen-Platinum Catalysis Dynamics},
  shorttitle = {Active Learning of Reactive {{Bayesian}} Force Fields},
  author = {Vandermause, Jonathan and Xie, Yu and Lim, Jin Soo and Owen, Cameron J. and Kozinsky, Boris},
  date = {2022-09-02},
  journaltitle = {Nature Communications},
  shortjournal = {Nat Commun},
  volume = {13},
  number = {1},
  eprint = {2106.01949},
  eprinttype = {arXiv},
  eprintclass = {cond-mat, physics:physics},
  pages = {5183},
  issn = {2041-1723},
  doi = {10.1038/s41467-022-32294-0},
  url = {http://arxiv.org/abs/2106.01949},
  urldate = {2023-01-10},
  abstract = {Accurate modeling of chemically reactive systems has traditionally relied on either expensive ab initio approaches or flexible bond-order force fields such as ReaxFF that require considerable time, effort, and expertise to parameterize. Here, we introduce FLARE++, a Bayesian active learning method for training reactive many-body force fields on the fly during molecular dynamics (MD) simulations. During the automated training loop, the predictive uncertainties of a sparse Gaussian process (SGP) force field are evaluated at each timestep of an MD simulation to determine whether additional ab initio data are needed. Once trained, the SGP is mapped onto an equivalent and much faster model that is polynomial in the local environment descriptors and whose prediction cost is independent of the training set size. We apply our method to a canonical reactive system in the field of heterogeneous catalysis, hydrogen splitting and recombination on a platinum (111) surface, obtaining a trained model within three days of wall time that is twice as fast as a recent Pt/H ReaxFF force field and considerably more accurate. Our method is fully open source and is expected to reduce the time and effort required to train fast and accurate reactive force fields for complex systems.},
  keywords = {Condensed Matter - Materials Science,Physics - Computational Physics},
  file = {/Users/marcel/Zotero/storage/KKDB4LTY/Vandermause et al. - 2022 - Active learning of reactive Bayesian force fields.pdf;/Users/marcel/Zotero/storage/RN2HCV8Q/2106.html}
}

@online{vaswaniAttentionAllYou2017,
  title = {Attention {{Is All You Need}}},
  author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N. and Kaiser, Lukasz and Polosukhin, Illia},
  date = {2017-12-05},
  eprint = {1706.03762},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.1706.03762},
  url = {http://arxiv.org/abs/1706.03762},
  urldate = {2022-09-22},
  abstract = {The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computation and Language,Computer Science - Machine Learning},
  file = {/Users/marcel/Zotero/storage/9W5DA8BA/Vaswani et al. - 2017 - Attention Is All You Need.pdf;/Users/marcel/Zotero/storage/WEJH8LKJ/1706.html}
}

@online{velickovicGraphAttentionNetworks2018,
  title = {Graph {{Attention Networks}}},
  author = {Veličković, Petar and Cucurull, Guillem and Casanova, Arantxa and Romero, Adriana and Liò, Pietro and Bengio, Yoshua},
  date = {2018-02-04},
  eprint = {1710.10903},
  eprinttype = {arXiv},
  eprintclass = {cs, stat},
  doi = {10.48550/arXiv.1710.10903},
  url = {http://arxiv.org/abs/1710.10903},
  urldate = {2024-02-13},
  abstract = {We present graph attention networks (GATs), novel neural network architectures that operate on graph-structured data, leveraging masked self-attentional layers to address the shortcomings of prior methods based on graph convolutions or their approximations. By stacking layers in which nodes are able to attend over their neighborhoods' features, we enable (implicitly) specifying different weights to different nodes in a neighborhood, without requiring any kind of costly matrix operation (such as inversion) or depending on knowing the graph structure upfront. In this way, we address several key challenges of spectral-based graph neural networks simultaneously, and make our model readily applicable to inductive as well as transductive problems. Our GAT models have achieved or matched state-of-the-art results across four established transductive and inductive graph benchmarks: the Cora, Citeseer and Pubmed citation network datasets, as well as a protein-protein interaction dataset (wherein test graphs remain unseen during training).},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Computer Science - Social and Information Networks,Statistics - Machine Learning},
  file = {/Users/marcel/Zotero/storage/RCMALHKZ/Veličković et al. - 2018 - Graph Attention Networks.pdf;/Users/marcel/Zotero/storage/QFHY56BY/1710.html}
}

@book{verhulstNonlinearDifferentialEquations1996,
  title = {Nonlinear {{Differential Equations}} and {{Dynamical Systems}}},
  author = {Verhulst, Ferdinand},
  date = {1996},
  series = {Universitext},
  publisher = {Springer},
  location = {Berlin, Heidelberg},
  doi = {10.1007/978-3-642-61453-8},
  url = {http://link.springer.com/10.1007/978-3-642-61453-8},
  urldate = {2023-10-27},
  isbn = {978-3-540-60934-6 978-3-642-61453-8},
  keywords = {averaging methods,bifurcation theory,Chaos,differential equations,dynamical systems,dynamische Systeme,nonlinear systems,oscillations},
  file = {/Users/marcel/Zotero/storage/7GHNUYJM/Verhulst - 1996 - Nonlinear Differential Equations and Dynamical Systems.pdf}
}

@article{villamizar800NWSwitchedCapacitor2021,
  title = {An 800 {{nW Switched-Capacitor Feature Extraction Filterbank}} for {{Sound Classification}}},
  author = {Villamizar, Daniel Augusto and Muratore, Dante Gabriel and Wieser, James B. and Murmann, Boris},
  date = {2021-04},
  journaltitle = {IEEE Transactions on Circuits and Systems I: Regular Papers},
  volume = {68},
  number = {4},
  pages = {1578--1588},
  issn = {1558-0806},
  doi = {10.1109/TCSI.2020.3047035},
  url = {https://ieeexplore.ieee.org/document/9321213},
  urldate = {2023-10-13},
  abstract = {This paper presents a 32-channel analog filterbank for front-end signal processing in sound classification systems. It employs a passive N-path switched capacitor topology to achieve high power efficiency and reconfigurability. The circuit's unwanted harmonic mixing products are absorbed by the machine learning model during training. To enable a systematic pre-silicon study of this effect, we develop a computationally efficient circuit model that can process large machine learning datasets on practical time scales. Measured results using a 130 nm CMOS prototype IC indicate competitive classification accuracy on datasets for baby cry detection (93.7\% AUC) and voice commands (92.4\% average precision), while lowering the feature extraction energy compared to digital realizations by approximately 2× and 10×, respectively. The 1.44 mm2 chip consumes 800 nW, which corresponds to the lowest normalized power per simultaneously sampled channel in recent literature.},
  eventtitle = {{{IEEE Transactions}} on {{Circuits}} and {{Systems I}}: {{Regular Papers}}},
  file = {/Users/marcel/Zotero/storage/F36YDGID/Villamizar et al. - 2021 - An 800 nW Switched-Capacitor Feature Extraction Filterbank for Sound Classification.pdf}
}

@thesis{villamizarLowPowerAudio2021,
  type = {phdthesis},
  title = {Low {{Power Audio Feature Extraction}} for {{Machine Learning Applications}}},
  author = {Villamizar, Daniel Augusto},
  date = {2021},
  institution = {Stanford University},
  location = {United States -- California},
  url = {https://www.proquest.com/docview/2598030889/abstract/6C1373D172C84AB6PQ/1},
  urldate = {2023-10-13},
  abstract = {Always-on sound classification is a desirable but power-intensive function for a variety of emerging applications such as wearables and IoT devices. The hardware energy consumption of sound classifiers is typically driven by signal digitization, feature extraction, classification model storage, and execution. Yet, the complexity of the signal of interest is often much lower than that of the raw signal acquired from the microphone and processed by a machine learning engine. For instance, semi-stationary sounds (e.g., engine noise, baby cry, running water, human chatter, etc.) are signals with lower information content than more complex sounds such as music or speech. In this dissertation, I will present the benefits of leveraging an engineered feature set to efficiently classify semi-stationary sounds. This approach requires one to three orders of magnitude fewer parameters and can be therefore trained over ten times faster than competitive deep learning models. I will also describe a circuit topology and system architecture that can be used to extract both engineered features as well as more general purpose ones. Our work resulted in a 32-channel analog filterbank IC for audio front-end signal processing. It employs a passive N-path switched capacitor topology to achieve high power efficiency and reconfigurability. The circuit's unwanted harmonic mixing products are absorbed by the machine learning model during training. To enable a systematic pre-silicon study of this effect, we develop a computationally efficient circuit model that can process large machine learning datasets in practical run-times. Measured results using a 130 nm CMOS prototype IC indicate competitive classification accuracy on datasets for baby cry detection (93.7\% AUC) and voice commands (92.4\% average precision), while lowering the feature extraction energy compared to digital realizations by approximately 2x and 10x, respectively. The 1.44 mm2 chip consumes 800 nW, which corresponds to the lowest normalized power per simultaneously sampled channel in recent literature.},
  isbn = {9798494463272},
  langid = {english},
  pagetotal = {103},
  keywords = {Acoustics,Algorithms,Artificial intelligence,Breakdowns,Christianity,Computer science,Deep learning,Design,Electrical engineering,Energy,Engineering,Families & family life,Human performance,Individual & family studies,Internet of Things,Keywords,Machine learning,Religion,Signal processing,Sound},
  file = {/Users/marcel/Zotero/storage/E7YAKDSY/Villamizar - 2021 - Low Power Audio Feature Extraction for Machine Learning Applications.pdf}
}

@unpublished{wagstaffUniversalApproximationFunctions2021,
  title = {Universal {{Approximation}} of {{Functions}} on {{Sets}}},
  author = {Wagstaff, Edward and Fuchs, Fabian B. and Engelcke, Martin and Osborne, Michael A. and Posner, Ingmar},
  date = {2021-07-05},
  eprint = {2107.01959},
  eprinttype = {arXiv},
  eprintclass = {cs, stat},
  url = {http://arxiv.org/abs/2107.01959},
  urldate = {2021-07-27},
  abstract = {Modelling functions of sets, or equivalently, permutation-invariant functions, is a long-standing challenge in machine learning. Deep Sets is a popular method which is known to be a universal approximator for continuous set functions. We provide a theoretical analysis of Deep Sets which shows that this universal approximation property is only guaranteed if the model's latent space is sufficiently high-dimensional. If the latent space is even one dimension lower than necessary, there exist piecewise-affine functions for which Deep Sets performs no better than a na\textbackslash "ive constant baseline, as judged by worst-case error. Deep Sets may be viewed as the most efficient incarnation of the Janossy pooling paradigm. We identify this paradigm as encompassing most currently popular set-learning methods. Based on this connection, we discuss the implications of our results for set learning more broadly, and identify some open questions on the universality of Janossy pooling in general.},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/marcel/Zotero/storage/D7WHRYXU/Wagstaff et al_2021_Universal Approximation of Functions on Sets.pdf;/Users/marcel/Zotero/storage/Q52SRY5J/2107.html}
}

@article{wangRobustTurbulenceSimulation2020,
  title = {Robust Turbulence Simulation for Particle-Based Fluids Using the {{Rankine}} Vortex Model},
  author = {Wang, Xiaokun and Liu, Sinuo and Ban, Xiaojuan and Xu, Yanrui and Zhou, Jing and Kosinka, Jiří},
  date = {2020-10-01},
  journaltitle = {The Visual Computer},
  shortjournal = {Vis Comput},
  volume = {36},
  number = {10},
  pages = {2285--2298},
  issn = {1432-2315},
  doi = {10.1007/s00371-020-01914-5},
  url = {https://doi.org/10.1007/s00371-020-01914-5},
  urldate = {2023-06-29},
  abstract = {We propose a novel turbulence refinement method based on the Rankine vortex model for smoothed particle hydrodynamics (SPH) simulations. Surface details are enhanced by recovering the energy lost due to the lack of the rotation of SPH particles. The Rankine vortex model is used to convert the diffused and stretched angular kinetic energy of particles to the linear kinetic energy of their neighbors. In previous vorticity-based refinement methods, adding more energy than required by the viscous damping effect leads to instability. In contrast, our model naturally prevents the positive feedback effect between the velocity and vorticity fields since the vortex model is designed to alter the velocity without introducing external sources. Experimental results show that our method can recover missing high-frequency details realistically and maintain convergence in both static and highly dynamic scenarios.},
  langid = {english},
  keywords = {Fluid simulation,Smoothed particle hydrodynamics,Turbulence,Vortex model},
  file = {/Users/marcel/Zotero/storage/HURAM86N/Wang et al. - 2020 - Robust turbulence simulation for particle-based fl.pdf}
}

@unpublished{weiler3DSteerableCNNs2018,
  title = {{{3D Steerable CNNs}}: {{Learning Rotationally Equivariant Features}} in {{Volumetric Data}}},
  shorttitle = {{{3D Steerable CNNs}}},
  author = {Weiler, Maurice and Geiger, Mario and Welling, Max and Boomsma, Wouter and Cohen, Taco},
  date = {2018-10-27},
  eprint = {1807.02547},
  eprinttype = {arXiv},
  eprintclass = {cs, stat},
  url = {http://arxiv.org/abs/1807.02547},
  urldate = {2021-07-27},
  abstract = {We present a convolutional network that is equivariant to rigid body motions. The model uses scalar-, vector-, and tensor fields over 3D Euclidean space to represent data, and equivariant convolutions to map between such representations. These SE(3)-equivariant convolutions utilize kernels which are parameterized as a linear combination of a complete steerable kernel basis, which is derived analytically in this paper. We prove that equivariant convolutions are the most general equivariant linear maps between fields over R\textasciicircum 3. Our experimental results confirm the effectiveness of 3D Steerable CNNs for the problem of amino acid propensity prediction and protein structure classification, both of which have inherent SE(3) symmetry.},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/marcel/Zotero/storage/IYB8IZWA/Weiler et al_2018_3D Steerable CNNs.pdf;/Users/marcel/Zotero/storage/X5RUAZUW/1807.html}
}

@unpublished{weilerCoordinateIndependentConvolutional2021,
  title = {Coordinate {{Independent Convolutional Networks}} -- {{Isometry}} and {{Gauge Equivariant Convolutions}} on {{Riemannian Manifolds}}},
  author = {Weiler, Maurice and Forré, Patrick and Verlinde, Erik and Welling, Max},
  date = {2021-06-10},
  eprint = {2106.06020},
  eprinttype = {arXiv},
  eprintclass = {cs, stat},
  url = {http://arxiv.org/abs/2106.06020},
  urldate = {2021-07-27},
  abstract = {Motivated by the vast success of deep convolutional networks, there is a great interest in generalizing convolutions to non-Euclidean manifolds. A major complication in comparison to flat spaces is that it is unclear in which alignment a convolution kernel should be applied on a manifold. The underlying reason for this ambiguity is that general manifolds do not come with a canonical choice of reference frames (gauge). Kernels and features therefore have to be expressed relative to arbitrary coordinates. We argue that the particular choice of coordinatization should not affect a network's inference -- it should be coordinate independent. A simultaneous demand for coordinate independence and weight sharing is shown to result in a requirement on the network to be equivariant under local gauge transformations (changes of local reference frames). The ambiguity of reference frames depends thereby on the G-structure of the manifold, such that the necessary level of gauge equivariance is prescribed by the corresponding structure group G. Coordinate independent convolutions are proven to be equivariant w.r.t. those isometries that are symmetries of the G-structure. The resulting theory is formulated in a coordinate free fashion in terms of fiber bundles. To exemplify the design of coordinate independent convolutions, we implement a convolutional network on the M\textbackslash "obius strip. The generality of our differential geometric formulation of convolutional networks is demonstrated by an extensive literature review which explains a large number of Euclidean CNNs, spherical CNNs and CNNs on general surfaces as specific instances of coordinate independent convolutions.},
  keywords = {Computer Science - Computational Geometry,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/marcel/Zotero/storage/QMKYGJ4Q/Weiler et al_2021_Coordinate Independent Convolutional Networks -- Isometry and Gauge Equivariant.pdf;/Users/marcel/Zotero/storage/9GS3MU3A/2106.html}
}

@unpublished{weilerGeneralEquivariantSteerable2021,
  title = {General \${{E}}(2)\$-{{Equivariant Steerable CNNs}}},
  author = {Weiler, Maurice and Cesa, Gabriele},
  date = {2021-04-06},
  eprint = {1911.08251},
  eprinttype = {arXiv},
  eprintclass = {cs, eess},
  url = {http://arxiv.org/abs/1911.08251},
  urldate = {2021-07-30},
  abstract = {The big empirical success of group equivariant networks has led in recent years to the sprouting of a great variety of equivariant network architectures. A particular focus has thereby been on rotation and reflection equivariant CNNs for planar images. Here we give a general description of \$E(2)\$-equivariant convolutions in the framework of Steerable CNNs. The theory of Steerable CNNs thereby yields constraints on the convolution kernels which depend on group representations describing the transformation laws of feature spaces. We show that these constraints for arbitrary group representations can be reduced to constraints under irreducible representations. A general solution of the kernel space constraint is given for arbitrary representations of the Euclidean group \$E(2)\$ and its subgroups. We implement a wide range of previously proposed and entirely new equivariant network architectures and extensively compare their performances. \$E(2)\$-steerable convolutions are further shown to yield remarkable gains on CIFAR-10, CIFAR-100 and STL-10 when used as a drop-in replacement for non-equivariant convolutions.},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Electrical Engineering and Systems Science - Image and Video Processing},
  file = {/Users/marcel/Zotero/storage/UDUQF6VK/Weiler_Cesa_2021_General $E(2)$-Equivariant Steerable CNNs.pdf;/Users/marcel/Zotero/storage/9J9H6Q77/1911.html}
}

@thesis{westExtractingSemanticInformation2010,
  title = {Extracting Semantic Information from {{Wikipedia}} Using Human Computation and Dimensionality Reduction},
  author = {West, Robert},
  date = {2010},
  institution = {McGill University},
  location = {Montreal, Québec},
  url = {http://central.bac-lac.gc.ca/.redirect?app=damspub&id=4a95e2c4-0052-4b5c-9fe8-81831ed8298e},
  urldate = {2024-03-15},
  langid = {english}
}

@article{westMiningMissingHyperlinks2015,
  title = {Mining {{Missing Hyperlinks}} from {{Human Navigation Traces}}: {{A Case Study}} of {{Wikipedia}}},
  shorttitle = {Mining {{Missing Hyperlinks}} from {{Human Navigation Traces}}},
  author = {West, Robert and Paranjape, Ashwin and Leskovec, Jure},
  date = {2015},
  journaltitle = {Proceedings of the ... International World-Wide Web Conference. International WWW Conference},
  shortjournal = {Proc Int World Wide Web Conf},
  volume = {2015},
  eprint = {26634229},
  eprinttype = {pmid},
  pages = {1242--1252},
  doi = {10.1145/2736277.2741666},
  abstract = {Hyperlinks are an essential feature of the World Wide Web. They are especially important for online encyclopedias such as Wikipedia: an article can often only be understood in the context of related articles, and hyperlinks make it easy to explore this context. But important links are often missing, and several methods have been proposed to alleviate this problem by learning a linking model based on the structure of the existing links. Here we propose a novel approach to identifying missing links in Wikipedia. We build on the fact that the ultimate purpose of Wikipedia links is to aid navigation. Rather than merely suggesting new links that are in tune with the structure of existing links, our method finds missing links that would immediately enhance Wikipedia's navigability. We leverage data sets of navigation paths collected through a Wikipedia-based human-computation game in which users must find a short path from a start to a target article by only clicking links encountered along the way. We harness human navigational traces to identify a set of candidates for missing links and then rank these candidates. Experiments show that our procedure identifies missing links of high quality.},
  langid = {english},
  pmcid = {PMC4664478},
  keywords = {Algorithms,browsing,Experimentation,human computation,Human Factors,link prediction,Navigation,Wikipedia,Wikispeedia},
  file = {/Users/marcel/Zotero/storage/39LGVUHX/West et al. - 2015 - Mining Missing Hyperlinks from Human Navigation Traces A Case Study of Wikipedia.pdf}
}

@inproceedings{westWikispeediaOnlineGame2009,
  title = {Wikispeedia: An Online Game for Inferring Semantic Distances between Concepts},
  shorttitle = {Wikispeedia},
  booktitle = {Proceedings of the 21st {{International Joint Conference}} on {{Artificial Intelligence}}},
  author = {West, Robert and Pineau, Joelle and Precup, Doina},
  date = {2009-07-11},
  series = {{{IJCAI}}'09},
  pages = {1598--1603},
  publisher = {Morgan Kaufmann Publishers Inc.},
  location = {San Francisco, CA, USA},
  abstract = {Computing the semantic distance between realworld concepts is crucial for many intelligent applications. We present a novel method that leverages data from 'Wikispeedia', an online game played on Wikipedia; players have to reach an article from another, unrelated article, only by clicking links in the articles encountered. In order to automatically infer semantic distances between everyday concepts, our method effectively extracts the common sense displayed by humans during play, and is thus more desirable, from a cognitive point of view, than purely corpus-based methods. We show that our method significantly outperforms Latent Semantic Analysis in a psychometric evaluation of the quality of learned semantic distances.}
}

@online{WikiGameWikipedia,
  title = {The {{Wiki Game}} - {{Wikipedia Game}} - {{Explore Wikipedia}}!},
  url = {https://www.thewikigame.com/},
  urldate = {2024-03-14},
  file = {/Users/marcel/Zotero/storage/Q3WPJDUI/www.thewikigame.com.html}
}

@inreference{wikipediaHelpLink2024,
  title = {Help:{{Link}}},
  shorttitle = {Help},
  booktitle = {Wikipedia},
  author = {Wikipedia},
  date = {2024-02-08T22:29:22Z},
  url = {https://en.wikipedia.org/w/index.php?title=Help:Link&oldid=1205116426},
  urldate = {2024-03-15},
  abstract = {This page explains how to make the wikilink, interwiki link, or external web link (as hyperlinks) connections on Wikipedia, which gives readers one-click access to other Wikipedia pages, other Wikimedia projects, and external websites. A link has various (changeable) appearances on the "anchor" page, and the "target" page, which owns the "backlinks", and which can count the links to it with the WP:What links here tool. For a short list of some basic shortcuts, see Wikipedia:Cheatsheet. For guidelines on how links should be used in Wikipedia, see Wikipedia:Manual of Style/Linking.},
  langid = {english},
  annotation = {Page Version ID: 1205116426},
  file = {/Users/marcel/Zotero/storage/BQH9FE4K/HelpLink.html}
}

@inreference{wikipediaHelpWikitext2024,
  title = {Help:{{Wikitext}}},
  shorttitle = {Help},
  booktitle = {Wikipedia},
  author = {Wikipedia},
  date = {2024-03-08T02:07:04Z},
  url = {https://en.wikipedia.org/w/index.php?title=Help:Wikitext&oldid=1212475524},
  urldate = {2024-03-14},
  abstract = {The markup language called wikitext, also known as wiki markup or wikicode, consists of the syntax and keywords used by the MediaWiki software to format a page. (Note the lowercase spelling of these terms.) To learn how to see this hypertext markup, and to save an edit, see Help:Editing. Generally, coding can be copied and pasted, without writing new code. There is a short list of markup and tips at Help:Cheatsheet. In addition to wikitext, some HTML elements are also allowed for presentation formatting. See Help:HTML in wikitext for information on this.},
  langid = {english},
  annotation = {Page Version ID: 1212475524},
  file = {/Users/marcel/Zotero/storage/5MASY7V5/HelpWikitext.html}
}

@inreference{WikipediaSizeWikipedia2024,
  title = {Wikipedia:{{Size}} of {{Wikipedia}}},
  shorttitle = {Wikipedia},
  booktitle = {Wikipedia},
  date = {2024-02-07T14:39:08Z},
  url = {https://en.wikipedia.org/w/index.php?title=Wikipedia:Size_of_Wikipedia&oldid=1204637456},
  urldate = {2024-02-13},
  abstract = {The size of the English Wikipedia can be measured in terms of the number of articles, number of words, number of pages, and the size of the database, among other ways. As of 13 February 2024, there are 6,783,300 articles in the English Wikipedia containing over 4.5 billion words (giving an average of about 668 words per article). The total number of pages is 59,999,779. Articles make up 11.31 percent of all pages on Wikipedia. As of 2 July 2023, the size of the current version of all articles compressed is about 22.14 GB without media.Wikipedia continues to grow, and the number of articles on Wikipedia is increasing by about 14,000 a month (as of January 2024). The number of articles added to Wikipedia every month reached its peak in 2006, at over 50,000 new articles a month, and has been slowly but steadily declining since then. While this might seem to show that Wikipedia's growth is slowing or stopping, it should be noted that the amount of text added to Wikipedia articles every year has been constant since 2006, at roughly 1 gigabyte of (compressed) text added per year. This implies that as time progresses, proportionally more content is added to existing articles rather than new articles, and that Wikipedia has maintained the same persistent rate of growth throughout since the 2010s. In other words, over time, the average article size is growing faster than the number of articles. Most of the earlier entries were extracted from Wikipedia:Milestones. Later entries are taken from observations of the new software's built-in article count features. For information on what Wikipedia's software counts as an article, see Wikipedia:What is an article\#Lists of articles and statistics. The article count of bot-generated Wikipedias such as the Cebuano-language edition of Wikipedia, as well as the Swedish-, Dutch- and the Waray-language editions, grow much faster than those that are primarily written by humans such as the English Wikipedia. Swedish Wikipedian Sverker Johansson's Lsjbot is the primary author of those four primarily bot-generated Wikipedias. Cebuano and Waray are Filipino languages. However, individual articles in bot-generated Wikipedias are on average much shorter than those in primarily human-written Wikipedias. Thus, article count alone is a very poor indicator of the scale and scope of all Wikipedia editions.},
  langid = {english},
  annotation = {Page Version ID: 1204637456},
  file = {/Users/marcel/Zotero/storage/FK7KZYMC/WikipediaSize_of_Wikipedia.html}
}

@inreference{wikipediaWikipediaDatabaseDownload2023,
  title = {Wikipedia:{{Database}} Download},
  shorttitle = {Wikipedia},
  booktitle = {Wikipedia},
  author = {Wikipedia},
  date = {2023-11-25T16:39:41Z},
  url = {https://en.wikipedia.org/w/index.php?title=Wikipedia:Database_download&oldid=1186807991},
  urldate = {2024-02-29},
  abstract = {Wikipedia offers free copies of all available content to interested users. These databases can be used for mirroring, personal use, informal backups, offline use or database queries (such as for Wikipedia:Maintenance). All text content is licensed under the Creative Commons Attribution-ShareAlike 3.0 License (CC-BY-SA), and most is additionally licensed under the GNU Free Documentation License (GFDL). Images and other files are available under different terms, as detailed on their description pages. For our advice about complying with these licenses, see Wikipedia:Copyrights.},
  langid = {english},
  annotation = {Page Version ID: 1186807991},
  file = {/Users/marcel/Zotero/storage/8CPCQJHK/WikipediaDatabase_download.html}
}

@inreference{wikipediaWikipediaSixDegrees2024,
  title = {Wikipedia:{{Six}} Degrees of {{Wikipedia}}},
  shorttitle = {Wikipedia},
  booktitle = {Wikipedia},
  author = {Wikipedia},
  date = {2024-02-05T23:14:15Z},
  url = {https://en.wikipedia.org/w/index.php?title=Wikipedia:Six_degrees_of_Wikipedia&oldid=1203914048},
  urldate = {2024-03-15},
  abstract = {There is a popular hypothesis, known as six degrees of separation, holding that any two people are separated by a chain of no more than six acquaintances. Studying the characters of Wikipedia to see whether something similar obtains among its articles, Six Degrees of Wikipedia aims to be a compendium of the following things: The items separated by the longest minimal chains in the encyclopedia (especially where these are more than four links long). The shortest known chain between the two items should be specified. Generalisation over time, where possible, seems to produce the shortest chains. Failing this, try generalisation over space to reduce chain length. The most intuitively remote items separated by short chains—chains of fewer than six articles, anyway.  That is, these should be items that have no obvious connection but which, nonetheless, can be linked between very quickly in Wikipedia. This is a much more subjective category, but should still be interesting; it may be enough to describe these as "interestingly" or "oddly" short chains. Chains between two articles selected at random (using Special:Randompage). Since these can often be uninteresting, think twice about actually adding these to this page. Articles that can be proven to have no chain between one another. This is the search for the potential outlier that could prove the hypothesis at least capable of being in a state of "incorrect". Intuition suggests that there shouldn't be any, but that is in fact why we need to search for it/them.},
  langid = {english},
  annotation = {Page Version ID: 1203914048}
}

@inreference{wikipediaWikipediaWikiGame2024,
  title = {Wikipedia:{{Wiki Game}}},
  shorttitle = {Wikipedia},
  booktitle = {Wikipedia},
  author = {Wikipedia},
  date = {2024-01-26T19:02:32Z},
  url = {https://en.wikipedia.org/w/index.php?title=Wikipedia:Wiki_Game&oldid=1199308715},
  urldate = {2024-03-15},
  abstract = {The Wiki Game, also known as the Wikipedia race, Wikirace, Wikispeedia, WikiLadders, WikiClick, or WikiWhack, is a race between any number of participants, using wikilinks to travel from one Wikipedia page to another. The first person to reach the destination page, or the person that reaches the destination using the fewest links, wins the race.},
  langid = {english},
  annotation = {Page Version ID: 1199308715},
  file = {/Users/marcel/Zotero/storage/WCZRUNZN/WikipediaWiki_Game.html}
}

@online{wolfHuggingFaceTransformersStateoftheart2020,
  title = {{{HuggingFace}}'s {{Transformers}}: {{State-of-the-art Natural Language Processing}}},
  shorttitle = {{{HuggingFace}}'s {{Transformers}}},
  author = {Wolf, Thomas and Debut, Lysandre and Sanh, Victor and Chaumond, Julien and Delangue, Clement and Moi, Anthony and Cistac, Pierric and Rault, Tim and Louf, Rémi and Funtowicz, Morgan and Davison, Joe and Shleifer, Sam and family=Platen, given=Patrick, prefix=von, useprefix=true and Ma, Clara and Jernite, Yacine and Plu, Julien and Xu, Canwen and Scao, Teven Le and Gugger, Sylvain and Drame, Mariama and Lhoest, Quentin and Rush, Alexander M.},
  date = {2020-07-13},
  eprint = {1910.03771},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.1910.03771},
  url = {http://arxiv.org/abs/1910.03771},
  urldate = {2024-03-14},
  abstract = {Recent progress in natural language processing has been driven by advances in both model architecture and model pretraining. Transformer architectures have facilitated building higher-capacity models and pretraining has made it possible to effectively utilize this capacity for a wide variety of tasks. \textbackslash textit\{Transformers\} is an open-source library with the goal of opening up these advances to the wider machine learning community. The library consists of carefully engineered state-of-the art Transformer architectures under a unified API. Backing this library is a curated collection of pretrained models made by and available for the community. \textbackslash textit\{Transformers\} is designed to be extensible by researchers, simple for practitioners, and fast and robust in industrial deployments. The library is available at \textbackslash url\{https://github.com/huggingface/transformers\}.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computation and Language},
  file = {/Users/marcel/Zotero/storage/FMTATZUD/Wolf et al. - 2020 - HuggingFace's Transformers State-of-the-art Natural Language Processing.pdf;/Users/marcel/Zotero/storage/U2CJEUN6/1910.html}
}

@article{wrightDeepPhysicalNeural2022,
  title = {Deep Physical Neural Networks Trained with Backpropagation},
  author = {Wright, Logan G. and Onodera, Tatsuhiro and Stein, Martin M. and Wang, Tianyu and Schachter, Darren T. and Hu, Zoey and McMahon, Peter L.},
  date = {2022-01},
  journaltitle = {Nature},
  volume = {601},
  number = {7894},
  pages = {549--555},
  publisher = {Nature Publishing Group},
  issn = {1476-4687},
  doi = {10.1038/s41586-021-04223-6},
  url = {https://www.nature.com/articles/s41586-021-04223-6},
  urldate = {2023-10-21},
  abstract = {Deep-learning models have become pervasive tools in science and engineering. However, their energy requirements now increasingly limit their scalability1. Deep-learning accelerators2–9 aim to perform deep learning energy-efficiently, usually targeting the inference phase and often by exploiting physical substrates beyond conventional electronics. Approaches so far10–22 have been unable to apply the backpropagation algorithm to train unconventional novel hardware in situ. The advantages of backpropagation have made it the~de facto~training method for large-scale neural networks, so this deficiency constitutes a major impediment. Here we introduce a hybrid in situ–in silico algorithm,~called physics-aware training, that applies backpropagation to train controllable physical systems. Just as deep learning realizes computations with deep neural networks made from layers of mathematical functions, our approach allows us to train deep~physical neural networks~made from layers of controllable physical systems, even when the physical layers lack any mathematical isomorphism to conventional artificial neural network layers. To demonstrate the universality of our approach, we train diverse physical neural networks based on optics, mechanics and electronics to experimentally perform audio and image classification tasks. Physics-aware training combines the scalability of backpropagation with the automatic mitigation of imperfections and noise achievable with~in situ~algorithms.~Physical neural networks have the potential to perform machine learning faster and more energy-efficiently than conventional electronic processors and, more broadly, can endow physical systems with automatically designed physical functionalities, for example, for robotics23–26, materials27–29 and smart sensors30–32.},
  issue = {7894},
  langid = {english},
  keywords = {Computational science,Nonlinear optics},
  file = {/Users/marcel/Zotero/storage/2FQ4L8BE/Wright et al. - 2022 - Deep physical neural networks trained with backpropagation.pdf}
}

@inproceedings{wuAccelergyArchitectureLevelEnergy2019,
  title = {Accelergy: {{An Architecture-Level Energy Estimation Methodology}} for {{Accelerator Designs}}},
  shorttitle = {Accelergy},
  booktitle = {2019 {{IEEE}}/{{ACM International Conference}} on {{Computer-Aided Design}} ({{ICCAD}})},
  author = {Wu, Yannan Nellie and Emer, Joel S. and Sze, Vivienne},
  date = {2019-11},
  pages = {1--8},
  publisher = {IEEE},
  location = {Westminster, CO, USA},
  doi = {10.1109/ICCAD45719.2019.8942149},
  url = {https://ieeexplore.ieee.org/document/8942149/},
  urldate = {2023-05-09},
  abstract = {With Moore’s law slowing down and Dennard scaling ended, energyefficient domain-specific accelerators, such as deep neural network (DNN) processors for machine learning and programmable network switches for cloud applications, have become a promising way for hardware designers to continue bringing energy efficiency improvements to data and computation-intensive applications. To ensure the fast exploration of the accelerator design space, architecturelevel energy estimators, which perform energy estimations without requiring complete hardware description of the designs, are critical to designers. However, it is difficult to use existing architecturelevel energy estimators to obtain accurate estimates for accelerator designs, as accelerator designs are diverse and sensitive to data patterns. This paper presents Accelergy, a generally applicable energy estimation methodology for accelerators that allows design specifications comprised of user-defined high-level compound components and user-defined low-level primitive components, which can be characterized by third-party energy estimation plug-ins. An example with primitive and compound components for DNN accelerator designs is also provided as an application of the proposed methodology. Overall, Accelergy achieves 95\% accuracy on Eyeriss, a well-known DNN accelerator design, and can correctly capture the energy breakdown of components at different granularities. The Accelergy code is available at http://accelergy.mit.edu.},
  eventtitle = {2019 {{IEEE}}/{{ACM International Conference}} on {{Computer-Aided Design}} ({{ICCAD}})},
  isbn = {978-1-7281-2350-9},
  langid = {english},
  file = {/Users/marcel/Zotero/storage/ZRMYPYX7/Wu et al. - 2019 - Accelergy An Architecture-Level Energy Estimation.pdf}
}

@article{wuAIPhysicistUnsupervised2019,
  title = {Toward an {{AI Physicist}} for {{Unsupervised Learning}}},
  author = {Wu, Tailin and Tegmark, Max},
  date = {2019-09-19},
  journaltitle = {Physical Review E},
  shortjournal = {Phys. Rev. E},
  volume = {100},
  number = {3},
  eprint = {1810.10525},
  eprinttype = {arXiv},
  eprintclass = {cond-mat, physics:physics},
  pages = {033311},
  issn = {2470-0045, 2470-0053},
  doi = {10.1103/PhysRevE.100.033311},
  url = {http://arxiv.org/abs/1810.10525},
  urldate = {2022-08-15},
  abstract = {We investigate opportunities and challenges for improving unsupervised machine learning using four common strategies with a long history in physics: divide-and-conquer, Occam's razor, unification and lifelong learning. Instead of using one model to learn everything, we propose a novel paradigm centered around the learning and manipulation of *theories*, which parsimoniously predict both aspects of the future (from past observations) and the domain in which these predictions are accurate. Specifically, we propose a novel generalized-mean-loss to encourage each theory to specialize in its comparatively advantageous domain, and a differentiable description length objective to downweight bad data and "snap" learned theories into simple symbolic formulas. Theories are stored in a "theory hub", which continuously unifies learned theories and can propose theories when encountering new environments. We test our implementation, the toy "AI Physicist" learning agent, on a suite of increasingly complex physics environments. From unsupervised observation of trajectories through worlds involving random combinations of gravity, electromagnetism, harmonic motion and elastic bounces, our agent typically learns faster and produces mean-squared prediction errors about a billion times smaller than a standard feedforward neural net of comparable complexity, typically recovering integer and rational theory parameters exactly. Our agent successfully identifies domains with different laws of motion also for a nonlinear chaotic double pendulum in a piecewise constant force field.},
  keywords = {Computer Science - Machine Learning,Condensed Matter - Disordered Systems and Neural Networks,Physics - Computational Physics},
  file = {/Users/marcel/Zotero/storage/QEAZDLZE/Wu and Tegmark - 2019 - Toward an AI Physicist for Unsupervised Learning.pdf;/Users/marcel/Zotero/storage/IRER7CAQ/1810.html}
}

@article{wuAnalogOpticalComputing2022,
  title = {Analog {{Optical Computing}} for {{Artificial Intelligence}}},
  author = {Wu, Jiamin and Lin, Xing and Guo, Yuchen and Liu, Junwei and Fang, Lu and Jiao, Shuming and Dai, Qionghai},
  date = {2022-03-01},
  journaltitle = {Engineering},
  shortjournal = {Engineering},
  volume = {10},
  pages = {133--145},
  issn = {2095-8099},
  doi = {10.1016/j.eng.2021.06.021},
  url = {https://www.sciencedirect.com/science/article/pii/S2095809921003349},
  urldate = {2023-10-17},
  abstract = {The rapid development of artificial intelligence (AI) facilitates various applications from all areas but also poses great challenges in its hardware implementation in terms of speed and energy because of the explosive growth of data. Optical computing provides a distinctive perspective to address this bottleneck by harnessing the unique properties of photons including broad bandwidth, low latency, and high energy efficiency. In this review, we introduce the latest developments of optical computing for different AI models, including feedforward neural networks, reservoir computing, and spiking neural networks (SNNs). Recent progress in integrated photonic devices, combined with the rise of AI, provides a great opportunity for the renaissance of optical computing in practical applications. This effort requires multidisciplinary efforts from a broad community. This review provides an overview of the state-of-the-art accomplishments in recent years, discusses the availability of current technologies, and points out various remaining challenges in different aspects to push the frontier. We anticipate that the era of large-scale integrated photonics processors will soon arrive for practical AI applications in the form of hybrid optoelectronic frameworks.},
  keywords = {Artificial intelligence,Neural network,Neuromorphic computing,Optical computing,Opto-electronic framework,Photonics processor,Reservoir computing},
  file = {/Users/marcel/Zotero/storage/PRKCRZ6C/Wu et al. - 2022 - Analog Optical Computing for Artificial Intelligence.pdf}
}

@online{wuHighresolutionNovoStructure2022,
  title = {High-Resolution de Novo Structure Prediction from Primary Sequence},
  author = {Wu, Ruidong and Ding, Fan and Wang, Rui and Shen, Rui and Zhang, Xiwen and Luo, Shitong and Su, Chenpeng and Wu, Zuofan and Xie, Qi and Berger, Bonnie and Ma, Jianzhu and Peng, Jian},
  date = {2022-07-22},
  eprinttype = {bioRxiv},
  eprintclass = {New Results},
  pages = {2022.07.21.500999},
  doi = {10.1101/2022.07.21.500999},
  url = {https://www.biorxiv.org/content/10.1101/2022.07.21.500999v1},
  urldate = {2022-08-01},
  abstract = {Recent breakthroughs have used deep learning to exploit evolutionary information in multiple sequence alignments (MSAs) to accurately predict protein structures. However, MSAs of homologous proteins are not always available, such as with orphan proteins or fast-evolving proteins like antibodies, and a protein typically folds in a natural setting from its primary amino acid sequence into its three-dimensional structure, suggesting that evolutionary information and MSAs should not be necessary to predict a protein’s folded form. Here, we introduce OmegaFold, the first computational method to successfully predict high-resolution protein structure from a single primary sequence alone. Using a new combination of a protein language model that allows us to make predictions from single sequences and a geometry-inspired transformer model trained on protein structures, OmegaFold outperforms RoseTTAFold and achieves similar prediction accuracy to AlphaFold2 on recently released structures. OmegaFold enables accurate predictions on orphan proteins that do not belong to any functionally characterized protein family and antibodies that tend to have noisy MSAs due to fast evolution. Our study fills a much-encountered gap in structure prediction and brings us a step closer to understanding protein folding in nature.},
  langid = {english},
  pubstate = {prepublished},
  file = {/Users/marcel/Zotero/storage/UY43NL36/Wu et al. - 2022 - High-resolution de novo structure prediction from .pdf;/Users/marcel/Zotero/storage/UFE4KIYV/2022.07.21.html}
}

@article{wuPatchbasedMeshInpainting2022,
  title = {Patch-Based Mesh Inpainting via Low Rank Recovery},
  author = {Wu, Xiaoqun and Lin, Xiaoyun and Li, Nan and Li, Haisheng},
  date = {2022-07-01},
  journaltitle = {Graphical Models},
  shortjournal = {Graphical Models},
  volume = {122},
  pages = {101139},
  issn = {1524-0703},
  doi = {10.1016/j.gmod.2022.101139},
  url = {https://www.sciencedirect.com/science/article/pii/S1524070322000169},
  urldate = {2022-11-03},
  abstract = {Mesh inpainting aims to fill the holes or missing regions from observed incomplete meshes and keep consistent with prior knowledge. Inspired by the success of low rank in describing similarity, we formulate the mesh inpainting problem as the low rank matrix recovery problem and present a patch-based mesh inpainting algorithm. Normal patch covariance is adapted to describe the similarity between surface patches. By analyzing the similarity of patches, the most similar patches are packed into a matrix with low rank structure. An iterative diffusion strategy is first designed to recover the patch vertex normals gradually. Then, the normals are refined by low rank approximation to keep the overall consistency and vertex positions are finally updated. We conduct several experiments in different 3D models to verify the proposed approach. Compared with existing algorithms, our experimental results demonstrate the superiority of our approach both visually and quantitatively in recovering the mesh with self-similarity patterns.},
  langid = {english},
  keywords = {Low-rank,Mesh inpainting},
  file = {/Users/marcel/Zotero/storage/KBKIYIM2/Wu et al. - 2022 - Patch-based mesh inpainting via low rank recovery.pdf;/Users/marcel/Zotero/storage/49BQ4MF5/S1524070322000169.html}
}

@unpublished{wuPointConvDeepConvolutional2020,
  title = {{{PointConv}}: {{Deep Convolutional Networks}} on {{3D Point Clouds}}},
  shorttitle = {{{PointConv}}},
  author = {Wu, Wenxuan and Qi, Zhongang and Fuxin, Li},
  date = {2020-11-09},
  eprint = {1811.07246},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/1811.07246},
  urldate = {2021-07-27},
  abstract = {Unlike images which are represented in regular dense grids, 3D point clouds are irregular and unordered, hence applying convolution on them can be difficult. In this paper, we extend the dynamic filter to a new convolution operation, named PointConv. PointConv can be applied on point clouds to build deep convolutional networks. We treat convolution kernels as nonlinear functions of the local coordinates of 3D points comprised of weight and density functions. With respect to a given point, the weight functions are learned with multi-layer perceptron networks and density functions through kernel density estimation. The most important contribution of this work is a novel reformulation proposed for efficiently computing the weight functions, which allowed us to dramatically scale up the network and significantly improve its performance. The learned convolution kernel can be used to compute translation-invariant and permutation-invariant convolution on any point set in the 3D space. Besides, PointConv can also be used as deconvolution operators to propagate features from a subsampled point cloud back to its original resolution. Experiments on ModelNet40, ShapeNet, and ScanNet show that deep convolutional neural networks built on PointConv are able to achieve state-of-the-art on challenging semantic segmentation benchmarks on 3D point clouds. Besides, our experiments converting CIFAR-10 into a point cloud showed that networks built on PointConv can match the performance of convolutional networks in 2D images of a similar structure.},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {/Users/marcel/Zotero/storage/BBFGKKLW/Wu et al_2020_PointConv.pdf;/Users/marcel/Zotero/storage/UNBSHQUK/1811.html}
}

@online{wuSurveyGraphPrompting2023,
  title = {A {{Survey}} of {{Graph Prompting Methods}}: {{Techniques}}, {{Applications}}, and {{Challenges}}},
  shorttitle = {A {{Survey}} of {{Graph Prompting Methods}}},
  author = {Wu, Xuansheng and Zhou, Kaixiong and Sun, Mingchen and Wang, Xin and Liu, Ninghao},
  date = {2023-05-30},
  eprint = {2303.07275},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2303.07275},
  url = {http://arxiv.org/abs/2303.07275},
  urldate = {2024-03-15},
  abstract = {The recent "pre-train, prompt, predict training" paradigm has gained popularity as a way to learn generalizable models with limited labeled data. The approach involves using a pre-trained model and a prompting function that applies a template to input samples, adding indicative context and reformulating target tasks as the pre-training task. However, the design of prompts could be a challenging and time-consuming process in complex tasks. The limitation can be addressed by using graph data, as graphs serve as structured knowledge repositories by explicitly modeling the interaction between entities. In this survey, we review prompting methods from the graph perspective, where prompting functions are augmented with graph knowledge. In particular, we introduce the basic concepts of graph prompt learning, organize the existing work of designing graph prompting functions, and describe their applications and future challenges. This survey will bridge the gap between graphs and prompt design to facilitate future methodology development.},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Computer Science - Social and Information Networks},
  file = {/Users/marcel/Zotero/storage/BY33QES6/Wu et al. - 2023 - A Survey of Graph Prompting Methods Techniques, Applications, and Challenges.pdf;/Users/marcel/Zotero/storage/XER5MYKU/2303.html}
}

@online{xiaoEfficientStreamingLanguage2023,
  title = {Efficient {{Streaming Language Models}} with {{Attention Sinks}}},
  author = {Xiao, Guangxuan and Tian, Yuandong and Chen, Beidi and Han, Song and Lewis, Mike},
  date = {2023-12-11},
  eprint = {2309.17453},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2309.17453},
  url = {http://arxiv.org/abs/2309.17453},
  urldate = {2024-03-16},
  abstract = {Deploying Large Language Models (LLMs) in streaming applications such as multi-round dialogue, where long interactions are expected, is urgently needed but poses two major challenges. Firstly, during the decoding stage, caching previous tokens' Key and Value states (KV) consumes extensive memory. Secondly, popular LLMs cannot generalize to longer texts than the training sequence length. Window attention, where only the most recent KVs are cached, is a natural approach -- but we show that it fails when the text length surpasses the cache size. We observe an interesting phenomenon, namely attention sink, that keeping the KV of initial tokens will largely recover the performance of window attention. In this paper, we first demonstrate that the emergence of attention sink is due to the strong attention scores towards initial tokens as a ``sink'' even if they are not semantically important. Based on the above analysis, we introduce StreamingLLM, an efficient framework that enables LLMs trained with a finite length attention window to generalize to infinite sequence lengths without any fine-tuning. We show that StreamingLLM can enable Llama-2, MPT, Falcon, and Pythia to perform stable and efficient language modeling with up to 4 million tokens and more. In addition, we discover that adding a placeholder token as a dedicated attention sink during pre-training can further improve streaming deployment. In streaming settings, StreamingLLM outperforms the sliding window recomputation baseline by up to 22.2x speedup. Code and datasets are provided at https://github.com/mit-han-lab/streaming-llm.},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
  file = {/Users/marcel/Zotero/storage/GPSW5ZTP/Xiao et al. - 2023 - Efficient Streaming Language Models with Attention Sinks.pdf;/Users/marcel/Zotero/storage/GT4PR5CT/2309.html}
}

@article{xuIntegratedPhotonicComputing2023,
  title = {Integrated {{Photonic Computing}} beyond the von {{Neumann Architecture}}},
  author = {Xu, Xiao-Yun and Jin, Xian-Min},
  date = {2023-04-19},
  journaltitle = {ACS Photonics},
  volume = {10},
  number = {4},
  pages = {1027--1036},
  publisher = {American Chemical Society},
  doi = {10.1021/acsphotonics.2c01543},
  url = {https://doi.org/10.1021/acsphotonics.2c01543},
  urldate = {2023-10-17},
  abstract = {In the context of a doomed end of the Moore’s law, various new types of computing architectures have been emerging, aiming to meet the demands of intractable computation and artificial intelligence. Photonic computing is a competitive candidate, in light of the inherent properties of photons, including high propagation speed, strong robustness, and multiple degrees of freedom to encode information. Also, the progress of integrated photonics continues to provide novel possibilities, apart from boosting the scalability and stability of photonic computing architectures. Moreover, an introduction of quantum technology might open a new chapter for photonic computing, from the view of single photons. In this Perspective, we highlight the unique features and advances of integrated photonic platforms, whose roles in constructing a non-von Neumann computing architecture are also outlined. We show their potential in solving problems beyond the reach of traditional computers and in machine learning and further discuss the conceivable challenges and opportunities.},
  file = {/Users/marcel/Zotero/storage/RH6HNTWK/Xu and Jin - 2023 - Integrated Photonic Computing beyond the von Neumann Architecture.pdf}
}

@article{xuMultichannelOpticalComputing2022,
  title = {A Multichannel Optical Computing Architecture for Advanced Machine Vision},
  author = {Xu, Zhihao and Yuan, Xiaoyun and Zhou, Tiankuang and Fang, Lu},
  date = {2022-08-18},
  journaltitle = {Light: Science \& Applications},
  shortjournal = {Light Sci Appl},
  volume = {11},
  number = {1},
  pages = {255},
  publisher = {Nature Publishing Group},
  issn = {2047-7538},
  doi = {10.1038/s41377-022-00945-y},
  url = {https://www.nature.com/articles/s41377-022-00945-y},
  urldate = {2023-10-17},
  abstract = {Endowed with the superior computing speed and energy efficiency, optical neural networks (ONNs) have attracted ever-growing attention in recent years. Existing optical computing architectures are mainly single-channel due to the lack of advanced optical connection and interaction operators, solving simple tasks such as hand-written digit classification, saliency detection, etc. The limited computing capacity and scalability of single-channel ONNs restrict the optical implementation of advanced machine vision. Herein, we develop Monet: a multichannel optical neural network architecture for a universal multiple-input multiple-channel optical computing based on a novel projection-interference-prediction framework where the inter- and intra- channel connections are mapped to optical interference and diffraction. In our Monet, optical interference patterns are generated by projecting and interfering the multichannel inputs in a shared domain. These patterns encoding the correspondences together with feature embeddings are iteratively produced through the projection-interference process to predict the final output optically. For the first time, Monet validates that multichannel processing properties can be optically implemented with high-efficiency, enabling real-world intelligent multichannel-processing tasks solved via optical computing, including 3D/motion detections. Extensive experiments on different scenarios demonstrate the effectiveness of Monet in handling advanced machine vision tasks with comparative accuracy as the electronic counterparts yet achieving a ten-fold improvement in computing efficiency. For intelligent computing, the trends of dealing with real-world advanced tasks are irreversible. Breaking the capacity and scalability limitations of single-channel ONN and further exploring the multichannel processing potential of wave optics, we anticipate that the proposed technique will accelerate the development of more powerful optical AI as critical support for modern advanced machine vision.},
  issue = {1},
  langid = {english},
  keywords = {Applied optics,Optical techniques,Transformation optics},
  file = {/Users/marcel/Zotero/storage/FWE3JMG4/Xu et al. - 2022 - A multichannel optical computing architecture for advanced machine vision.pdf}
}

@online{xuPointNeRFPointbasedNeural2022,
  title = {Point-{{NeRF}}: {{Point-based Neural Radiance Fields}}},
  shorttitle = {Point-{{NeRF}}},
  author = {Xu, Qiangeng and Xu, Zexiang and Philip, Julien and Bi, Sai and Shu, Zhixin and Sunkavalli, Kalyan and Neumann, Ulrich},
  date = {2022-03-18},
  eprint = {2201.08845},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2201.08845},
  url = {http://arxiv.org/abs/2201.08845},
  urldate = {2022-09-30},
  abstract = {Volumetric neural rendering methods like NeRF generate high-quality view synthesis results but are optimized per-scene leading to prohibitive reconstruction time. On the other hand, deep multi-view stereo methods can quickly reconstruct scene geometry via direct network inference. Point-NeRF combines the advantages of these two approaches by using neural 3D point clouds, with associated neural features, to model a radiance field. Point-NeRF can be rendered efficiently by aggregating neural point features near scene surfaces, in a ray marching-based rendering pipeline. Moreover, Point-NeRF can be initialized via direct inference of a pre-trained deep network to produce a neural point cloud; this point cloud can be finetuned to surpass the visual quality of NeRF with 30X faster training time. Point-NeRF can be combined with other 3D reconstruction methods and handles the errors and outliers in such methods via a novel pruning and growing mechanism. The experiments on the DTU, the NeRF Synthetics , the ScanNet and the Tanks and Temples datasets demonstrate Point-NeRF can surpass the existing methods and achieve the state-of-the-art results.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {/Users/marcel/Zotero/storage/3TJ99HXF/Xu et al. - 2022 - Point-NeRF Point-based Neural Radiance Fields.pdf;/Users/marcel/Zotero/storage/3FRLTUZ6/2201.html}
}

@online{xuWhatCanNeural2020,
  title = {What {{Can Neural Networks Reason About}}?},
  author = {Xu, Keyulu and Li, Jingling and Zhang, Mozhi and Du, Simon S. and Kawarabayashi, Ken-ichi and Jegelka, Stefanie},
  date = {2020-02-15},
  eprint = {1905.13211},
  eprinttype = {arXiv},
  eprintclass = {cs, stat},
  doi = {10.48550/arXiv.1905.13211},
  url = {http://arxiv.org/abs/1905.13211},
  urldate = {2024-02-13},
  abstract = {Neural networks have succeeded in many reasoning tasks. Empirically, these tasks require specialized network structures, e.g., Graph Neural Networks (GNNs) perform well on many such tasks, but less structured networks fail. Theoretically, there is limited understanding of why and when a network structure generalizes better than others, although they have equal expressive power. In this paper, we develop a framework to characterize which reasoning tasks a network can learn well, by studying how well its computation structure aligns with the algorithmic structure of the relevant reasoning process. We formally define this algorithmic alignment and derive a sample complexity bound that decreases with better alignment. This framework offers an explanation for the empirical success of popular reasoning models, and suggests their limitations. As an example, we unify seemingly different reasoning tasks, such as intuitive physics, visual question answering, and shortest paths, via the lens of a powerful algorithmic paradigm, dynamic programming (DP). We show that GNNs align with DP and thus are expected to solve these tasks. On several reasoning tasks, our theory is supported by empirical results.},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing,Statistics - Machine Learning},
  file = {/Users/marcel/Zotero/storage/JGB8CQ3I/Xu et al. - 2020 - What Can Neural Networks Reason About.pdf;/Users/marcel/Zotero/storage/V2GCYPXV/1905.html}
}

@online{yangDiffusionModelsComprehensive2022a,
  title = {Diffusion {{Models}}: {{A Comprehensive Survey}} of {{Methods}} and {{Applications}}},
  shorttitle = {Diffusion {{Models}}},
  author = {Yang, Ling and Zhang, Zhilong and Song, Yang and Hong, Shenda and Xu, Runsheng and Zhao, Yue and Shao, Yingxia and Zhang, Wentao and Cui, Bin and Yang, Ming-Hsuan},
  date = {2022-10-23},
  eprint = {2209.00796},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2209.00796},
  url = {http://arxiv.org/abs/2209.00796},
  urldate = {2022-12-01},
  abstract = {Diffusion models have emerged as a powerful new family of deep generative models with record-breaking performance in many applications, including image synthesis, video generation, and molecule design. In this survey, we provide an overview of the rapidly expanding body of work on diffusion models, categorizing the research into three key areas: efficient sampling, improved likelihood estimation, and handling data with special structures. We also discuss the potential for combining diffusion models with other generative models for enhanced results. We further review the wide-ranging applications of diffusion models in fields spanning from computer vision, natural language processing, temporal data modeling, to interdisciplinary applications in other scientific disciplines. This survey aims to provide a contextualized, in-depth look at the state of diffusion models, identifying the key areas of focus and pointing to potential areas for further exploration. Github: https://github.com/YangLing0818/Diffusion-Models-Papers-Survey-Taxonomy.},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning},
  file = {/Users/marcel/Zotero/storage/NKQYADXS/Yang et al. - 2022 - Diffusion Models A Comprehensive Survey of Method.pdf;/Users/marcel/Zotero/storage/EZZ79Z5V/2209.html}
}

@unpublished{yangPointFlow3DPoint2019,
  title = {{{PointFlow}}: {{3D Point Cloud Generation}} with {{Continuous Normalizing Flows}}},
  shorttitle = {{{PointFlow}}},
  author = {Yang, Guandao and Huang, Xun and Hao, Zekun and Liu, Ming-Yu and Belongie, Serge and Hariharan, Bharath},
  date = {2019-09-02},
  eprint = {1906.12320},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/1906.12320},
  urldate = {2021-07-27},
  abstract = {As 3D point clouds become the representation of choice for multiple vision and graphics applications, the ability to synthesize or reconstruct high-resolution, high-fidelity point clouds becomes crucial. Despite the recent success of deep learning models in discriminative tasks of point clouds, generating point clouds remains challenging. This paper proposes a principled probabilistic framework to generate 3D point clouds by modeling them as a distribution of distributions. Specifically, we learn a two-level hierarchy of distributions where the first level is the distribution of shapes and the second level is the distribution of points given a shape. This formulation allows us to both sample shapes and sample an arbitrary number of points from a shape. Our generative model, named PointFlow, learns each level of the distribution with a continuous normalizing flow. The invertibility of normalizing flows enables the computation of the likelihood during training and allows us to train our model in the variational inference framework. Empirically, we demonstrate that PointFlow achieves state-of-the-art performance in point cloud generation. We additionally show that our model can faithfully reconstruct point clouds and learn useful representations in an unsupervised manner. The code will be available at https://github.com/stevenygd/PointFlow.},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning},
  file = {/Users/marcel/Zotero/storage/3AQELNM5/Yang et al_2019_PointFlow.pdf;/Users/marcel/Zotero/storage/HIRHDBD9/1906.html}
}

@online{yangTensorProgramsTuning2022,
  title = {Tensor {{Programs V}}: {{Tuning Large Neural Networks}} via {{Zero-Shot Hyperparameter Transfer}}},
  shorttitle = {Tensor {{Programs V}}},
  author = {Yang, Greg and Hu, Edward J. and Babuschkin, Igor and Sidor, Szymon and Liu, Xiaodong and Farhi, David and Ryder, Nick and Pachocki, Jakub and Chen, Weizhu and Gao, Jianfeng},
  date = {2022-03-28},
  eprint = {2203.03466},
  eprinttype = {arXiv},
  eprintclass = {cond-mat},
  doi = {10.48550/arXiv.2203.03466},
  url = {http://arxiv.org/abs/2203.03466},
  urldate = {2024-05-10},
  abstract = {Hyperparameter (HP) tuning in deep learning is an expensive process, prohibitively so for neural networks (NNs) with billions of parameters. We show that, in the recently discovered Maximal Update Parametrization (muP), many optimal HPs remain stable even as model size changes. This leads to a new HP tuning paradigm we call muTransfer: parametrize the target model in muP, tune the HP indirectly on a smaller model, and zero-shot transfer them to the full-sized model, i.e., without directly tuning the latter at all. We verify muTransfer on Transformer and ResNet. For example, 1) by transferring pretraining HPs from a model of 13M parameters, we outperform published numbers of BERT-large (350M parameters), with a total tuning cost equivalent to pretraining BERT-large once; 2) by transferring from 40M parameters, we outperform published numbers of the 6.7B GPT-3 model, with tuning cost only 7\% of total pretraining cost. A Pytorch implementation of our technique can be found at github.com/microsoft/mup and installable via `pip install mup`.},
  pubstate = {prepublished},
  keywords = {Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing,Condensed Matter - Disordered Systems and Neural Networks},
  file = {/Users/marcel/Zotero/storage/ZVZQUJVA/Yang et al. - 2022 - Tensor Programs V Tuning Large Neural Networks via Zero-Shot Hyperparameter Transfer.pdf;/Users/marcel/Zotero/storage/63ZWZYHB/2203.html}
}

@video{yannickilcherBackpropagationBrain2020,
  entrysubtype = {video},
  title = {Backpropagation and the Brain},
  editor = {{Yannic Kilcher}},
  editortype = {director},
  date = {2020-04-20},
  url = {https://www.youtube.com/watch?v=a0f07M2uj_A},
  urldate = {2022-04-19},
  abstract = {Geoffrey Hinton and his co-authors describe a biologically plausible variant of backpropagation and report evidence that such an algorithm might be responsible for learning in the brain. https://www.nature.com/articles/s4158... Abstract: During learning, the brain modifies synapses to improve behaviour. In the cortex, synapses are embedded within multilayered networks, making it difficult to determine the effect of an individual synaptic modification on the behaviour of the system. The backpropagation algorithm solves this problem in deep artificial neural networks, but historically it has been viewed as biologically problematic. Nonetheless, recent developments in neuroscience and the successes of artificial neural networks have reinvigorated interest in whether backpropagation offers insights for understanding learning in the cortex. The backpropagation algorithm learns quickly by computing synaptic updates using feedback connections to deliver error signals. Although feedback connections are ubiquitous in the cortex, it is difficult to see how they could deliver the error signals required by strict formulations of backpropagation. Here we build on past and recent developments to argue that feedback connections may instead induce neural activities whose differences can be used to locally approximate these signals and hence drive effective learning in deep networks in the brain. Authors: Timothy P. Lillicrap, Adam Santoro, Luke Marris, Colin J. Akerman \& Geoffrey Hinton Links: YouTube: https://www.youtube.com/c/yannickilcher Twitter: https://twitter.com/ykilcher BitChute: https://www.bitchute.com/channel/yann... Minds: https://www.minds.com/ykilcher}
}

@video{yannickilcherNeurallyPlausibleModel2019,
  entrysubtype = {video},
  title = {A Neurally Plausible Model Learns Successor Representations in Partially Observable Environments},
  editor = {{Yannic Kilcher}},
  editortype = {director},
  date = {2019-11-07},
  url = {https://www.youtube.com/watch?v=KXEEqcwXn8w},
  urldate = {2022-04-19},
  abstract = {Successor representations are a mid-point between model-based and model-free reinforcement learning. This paper learns successor representation in environments where only incomplete information is available. Abstract: Animals need to devise strategies to maximize returns while interacting with their environment based on incoming noisy sensory observations. Task-relevant states, such as the agent's location within an environment or the presence of a predator, are often not directly observable but must be inferred using available sensory information. Successor representations (SR) have been proposed as a middle-ground between model-based and model-free reinforcement learning strategies, allowing for fast value computation and rapid adaptation to changes in the reward function or goal locations. Indeed, recent studies suggest that features of neural responses are consistent with the SR framework. However, it is not clear how such representations might be learned and computed in partially observed, noisy environments. Here, we introduce a neurally plausible model using distributional successor features, which builds on the distributed distributional code for the representation and computation of uncertainty, and which allows for efficient value function computation in partially observed environments via the successor representation. We show that distributional successor features can support reinforcement learning in noisy environments in which direct learning of successful policies is infeasible. Authors: Eszter Vertes, Maneesh Sahani Links: YouTube: https://www.youtube.com/c/yannickilcher Twitter: https://twitter.com/ykilcher BitChute: https://www.bitchute.com/channel/yann... Minds: https://www.minds.com/ykilcher}
}

@online{yasunagaQAGNNReasoningLanguage2021,
  title = {{{QA-GNN}}: {{Reasoning}} with {{Language Models}} and {{Knowledge Graphs}} for {{Question Answering}}},
  shorttitle = {{{QA-GNN}}},
  author = {Yasunaga, Michihiro and Ren, Hongyu and Bosselut, Antoine and Liang, Percy and Leskovec, Jure},
  date = {2021-04-13},
  url = {https://arxiv.org/abs/2104.06378v5},
  urldate = {2024-03-15},
  abstract = {The problem of answering questions using knowledge from pre-trained language models (LMs) and knowledge graphs (KGs) presents two challenges: given a QA context (question and answer choice), methods need to (i) identify relevant knowledge from large KGs, and (ii) perform joint reasoning over the QA context and KG. In this work, we propose a new model, QA-GNN, which addresses the above challenges through two key innovations: (i) relevance scoring, where we use LMs to estimate the importance of KG nodes relative to the given QA context, and (ii) joint reasoning, where we connect the QA context and KG to form a joint graph, and mutually update their representations through graph neural networks. We evaluate our model on QA benchmarks in the commonsense (CommonsenseQA, OpenBookQA) and biomedical (MedQA-USMLE) domains. QA-GNN outperforms existing LM and LM+KG models, and exhibits capabilities to perform interpretable and structured reasoning, e.g., correctly handling negation in questions.},
  langid = {english},
  organization = {arXiv.org},
  file = {/Users/marcel/Zotero/storage/U6M99PH8/Yasunaga et al. - 2021 - QA-GNN Reasoning with Language Models and Knowledge Graphs for Question Answering.pdf}
}

@online{yasunagaQAGNNReasoningLanguage2022,
  title = {{{QA-GNN}}: {{Reasoning}} with {{Language Models}} and {{Knowledge Graphs}} for {{Question Answering}}},
  shorttitle = {{{QA-GNN}}},
  author = {Yasunaga, Michihiro and Ren, Hongyu and Bosselut, Antoine and Liang, Percy and Leskovec, Jure},
  date = {2022-12-12},
  eprint = {2104.06378},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2104.06378},
  url = {http://arxiv.org/abs/2104.06378},
  urldate = {2024-02-13},
  abstract = {The problem of answering questions using knowledge from pre-trained language models (LMs) and knowledge graphs (KGs) presents two challenges: given a QA context (question and answer choice), methods need to (i) identify relevant knowledge from large KGs, and (ii) perform joint reasoning over the QA context and KG. In this work, we propose a new model, QA-GNN, which addresses the above challenges through two key innovations: (i) relevance scoring, where we use LMs to estimate the importance of KG nodes relative to the given QA context, and (ii) joint reasoning, where we connect the QA context and KG to form a joint graph, and mutually update their representations through graph neural networks. We evaluate our model on QA benchmarks in the commonsense (CommonsenseQA, OpenBookQA) and biomedical (MedQA-USMLE) domains. QA-GNN outperforms existing LM and LM+KG models, and exhibits capabilities to perform interpretable and structured reasoning, e.g., correctly handling negation in questions.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computation and Language,Computer Science - Machine Learning},
  file = {/Users/marcel/Zotero/storage/WH28KTJK/Yasunaga et al. - 2022 - QA-GNN Reasoning with Language Models and Knowledge Graphs for Question Answering.pdf;/Users/marcel/Zotero/storage/YNCKBYWN/2104.html}
}

@online{yiHardwareAwareStaticOptimization2023,
  title = {Hardware-{{Aware Static Optimization}} of {{Hyperdimensional Computations}}},
  author = {Yi, Pu and Achour, Sara},
  date = {2023-04-06},
  eprint = {2304.03335},
  eprinttype = {arXiv},
  eprintclass = {cs, math},
  url = {http://arxiv.org/abs/2304.03335},
  urldate = {2023-05-23},
  abstract = {Hyperdimensional (HD) computing is an highly error-resilient computational paradigm that can be used to efficiently perform language classification, data retrieval, and analogical reasoning tasks on error-prone emerging hardware technologies. HD computation is storage-inefficient and often requires computing over 10,000-dimensional bit vectors. Prior work either leaves hypervectors unoptimized or dynamically tunes HD computation parameters (e.g., hypervector dimension) to deliver the desired accuracy. These approaches are time-consuming, lack accuracy guarantees, and do not generalize well. We present Heim, a framework for statically optimizing HD computation parameters to minimize resource usage in the presence of hardware error. Heim guarantees the optimized computation satisfies a user-provided target accuracy. Heim deploys a novel analysis procedure that unifies theoretical results in HD computing to systematically optimize HD computation. We develop four analysis-amenable data structures that leverage Heim to perform aggressive space-saving optimizations, and optimize these data structures to attain 99\% query accuracy on both binary memory and multiple-bit-per-cell resistive memory. Heim-optimized data structures deliver 1.31x-14.51x reductions in hypervector size and 2.191x-27.27x reductions in memory usage while attaining 98.96-99.75\% accuracy. Heim-optimized data structures deliver up to 41.40\% accuracy improvements over dynamically tuned parameters. Heim computes parameters significantly faster than dynamic approaches.},
  pubstate = {prepublished},
  file = {/Users/marcel/Zotero/storage/78N2XFBW/Yi and Achour - 2023 - Hardware-Aware Static Optimization of Hyperdimensional Computations.pdf}
}

@article{yinXNORSRAMInMemoryComputing2020,
  title = {{{XNOR-SRAM}}: {{In-Memory Computing SRAM Macro}} for {{Binary}}/{{Ternary Deep Neural Networks}}},
  shorttitle = {{{XNOR-SRAM}}},
  author = {Yin, Shihui and Jiang, Zhewei and Seo, Jae-Sun and Seok, Mingoo},
  date = {2020},
  journaltitle = {IEEE Journal of Solid-State Circuits},
  shortjournal = {IEEE J. Solid-State Circuits},
  pages = {1--11},
  issn = {0018-9200, 1558-173X},
  doi = {10.1109/JSSC.2019.2963616},
  url = {https://ieeexplore.ieee.org/document/8959407/},
  urldate = {2023-10-21},
  abstract = {We present XNOR-SRAM, a mixed-signal inmemory computing (IMC) SRAM macro that computes ternaryXNOR-and-accumulate (XAC) operations in binary/ternary deep neural networks (DNNs) without row-by-row data access. The XNOR-SRAM bitcell embeds circuits for ternary XNOR operations, which are accumulated on the read bitline (RBL) by simultaneously turning on all 256 rows, essentially forming a resistive voltage divider. The analog RBL voltage is digitized with a column-multiplexed 11-level flash analog-to-digital converter (ADC) at the XNOR-SRAM periphery. XNOR-SRAM is prototyped in a 65-nm CMOS and achieves the energy efficiency of 403 TOPS/W for ternary-XAC operations with 88.8\% test accuracy for the CIFAR-10 data set at 0.6-V supply. This marks 33× better energy efficiency and 300× better energy–delay product than conventional digital hardware and also represents among the best tradeoff in energy efficiency and DNN accuracy.},
  langid = {english},
  file = {/Users/marcel/Zotero/storage/B7HREJY8/Yin et al. - 2020 - XNOR-SRAM In-Memory Computing SRAM Macro for BinaryTernary Deep Neural Networks.pdf}
}

@article{yuDomainKnowledgeGraph2021,
  title = {A Domain Knowledge Graph Construction Method Based on {{Wikipedia}}},
  author = {Yu, Haoze and Li, Haisheng and Mao, Dianhui and Cai, Qiang},
  date = {2021-12-01},
  journaltitle = {Journal of Information Science},
  volume = {47},
  number = {6},
  pages = {783--793},
  publisher = {SAGE Publications Ltd},
  issn = {0165-5515},
  doi = {10.1177/0165551520932510},
  url = {https://doi.org/10.1177/0165551520932510},
  urldate = {2024-03-15},
  abstract = {In order to achieve real-time updating of the domain knowledge graph and improve the relationship extraction ability in the construction process, a domain knowledge graph construction method is proposed. Based on the structured knowledge in Wikipedia’s classification system, we acquire concepts and instances contained in subject areas. A relationship extraction algorithm based on co-word analysis is intended to extract the classification relationships in semi-structured open labels. A Bi-GRU remote supervised relationship extraction model based on a multiple-scale attention mechanism and an improved cross-entropy loss function is proposed to obtain the non-classification relationships of concepts in unstructured texts. Experiments show that the proposed model performs better than the existing methods. Based on the obtained concepts, instances and relationships, a domain knowledge graph is constructed and the domain-independent nodes and relationships contained in them are removed through a vector variance algorithm. The effectiveness of the proposed method is verified by constructing a food domain knowledge graph based on Wikipedia.},
  langid = {english},
  file = {/Users/marcel/Zotero/storage/J9XWQ4HX/Yu et al. - 2021 - A domain knowledge graph construction method based on Wikipedia.pdf}
}

@book{yuReRAMbasedMachineLearning2021,
  title = {{{ReRAM-based Machine Learning}}},
  author = {Yu, Hao and Ni, Leibin and Dinakarrao, Sai Manoj Pudukotai},
  date = {2021-04-01},
  publisher = {IET Digital Library},
  doi = {10.1049/PBPC039E},
  url = {https://digital-library.theiet.org/content/books/pc/pbpc039e},
  urldate = {2023-11-11},
  abstract = {The transition towards exascale computing has resulted in major transformations in computing paradigms. The need to analyze and respond to such large amounts of data sets has led to the adoption of machine learning (ML) and deep learning (DL) methods in a wide range of applications. One of the major challenges is the fetching of data from computing memory and writing it back without experiencing a memory-wall bottleneck. To address such concerns, in-memory computing (IMC) and supporting frameworks have been introduced. In-memory computing methods have ultra-low power and high-density embedded storage. Resistive Random-Access Memory (ReRAM) technology seems the most promising IMC solution due to its minimized leakage power, reduced power consumption and smaller hardware footprint, as well as its compatibility with CMOS technology, which is widely used in industry. In this book, the authors introduce ReRAM techniques for performing distributed computing using IMC accelerators, present ReRAM-based IMC architectures that can perform computations of ML and data-intensive applications, as well as strategies to map ML designs onto hardware accelerators. The book serves as a bridge between researchers in the computing domain (algorithm designers for ML and DL) and computing hardware designers.},
  isbn = {978-1-83953-082-1},
  langid = {english},
  file = {/Users/marcel/Zotero/storage/8JITTBL7/Yu et al. - 2021 - ReRAM-based Machine Learning.pdf;/Users/marcel/Zotero/storage/WXIUAYR2/pbpc039e.html}
}

@unpublished{zahnPruningDeepNeural2022,
  title = {Pruning Deep Neural Networks Generates a Sparse, Bio-Inspired Nonlinear Controller for Insect Flight},
  author = {Zahn, Olivia and Bustamante Jr., Jorge and Switzer, Callin and Daniel, Thomas and Kutz, J. Nathan},
  date = {2022-01-05},
  eprint = {2201.01852},
  eprinttype = {arXiv},
  eprintclass = {q-bio},
  url = {http://arxiv.org/abs/2201.01852},
  urldate = {2022-05-02},
  abstract = {Insect flight is a strongly nonlinear and actuated dynamical system. As such, strategies for understanding its control have typically relied on either model-based methods or linearizations thereof. Here we develop a framework that combines model predictive control on an established flight dynamics model and deep neural networks (DNN) to create an efficient method for solving the inverse problem of flight control. We turn to natural systems for inspiration since they inherently demonstrate network pruning with the consequence of yielding more efficient networks for a specific set of tasks. This bio-inspired approach allows us to leverage network pruning to optimally sparsify a DNN architecture in order to perform flight tasks with as few neural connections as possible, however, there are limits to sparsification. Specifically, as the number of connections falls below a critical threshold, flight performance drops considerably. We develop sparsification paradigms and explore their limits for control tasks. Monte Carlo simulations also quantify the statistical distribution of network weights during pruning given initial random weights of the DNNs. We demonstrate that on average, the network can be pruned to retain approximately 7\% of the original network weights, with statistical distributions quantified at each layer of the network. Overall, this work shows that sparsely connected DNNs are capable of predicting the forces required to follow flight trajectories. Additionally, sparsification has sharp performance limits.},
  keywords = {Quantitative Biology - Quantitative Methods},
  file = {/Users/marcel/Zotero/storage/UIJWBB6Q/Zahn et al. - 2022 - Pruning deep neural networks generates a sparse, b.pdf;/Users/marcel/Zotero/storage/S9WVR8ZR/2201.html}
}

@article{zhangHWADAMFPGABasedAccelerator2023,
  title = {{{HW-ADAM}}: {{FPGA-Based Accelerator}} for {{Adaptive Moment Estimation}}},
  shorttitle = {{{HW-ADAM}}},
  author = {Zhang, Weiyi and Niu, Liting and Zhang, Debing and Wang, Guangqi and Farrukh, Fasih Ud Din and Zhang, Chun},
  date = {2023-01},
  journaltitle = {Electronics},
  volume = {12},
  number = {2},
  pages = {263},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {2079-9292},
  doi = {10.3390/electronics12020263},
  url = {https://www.mdpi.com/2079-9292/12/2/263},
  urldate = {2023-11-10},
  abstract = {The selection of the optimizer is critical for convergence in the field of on-chip training. As one second moment optimizer, adaptive moment estimation (ADAM) shows a significant advantage compared with non-moment optimizers such as stochastic gradient descent (SGD) and first-moment optimizers such as Momentum. However, ADAM is hard to implement on hardware due to the computationally intensive operations, including square, root extraction, and division. This work proposed Hardware-ADAM (HW-ADAM), an efficient fixed-point accelerator for ADAM highlighting hardware-oriented mathematical optimizations. HW-ADAM has two designs: Efficient-ADAM (E-ADAM) unit reduced the hardware resource consumption by around 90\% compared with the related work. E-ADAM achieved a throughput of 2.89 MUOP/s (Million Updating Operation per Second), which is 2.8× of the original ADAM. Fast-ADAM (F-ADAM) unit reduced 91.5\% flip-flops, 65.7\% look-up tables, and 50\% DSPs compared with the related work. The F-ADAM unit achieved a throughput of 16.7 MUOP/s, which is 16.4× of the original ADAM.},
  issue = {2},
  langid = {english},
  keywords = {accelerator,adaptive moment estimation,FPGA,on-chip training},
  file = {/Users/marcel/Zotero/storage/QQFD8K5E/Zhang et al. - 2023 - HW-ADAM FPGA-Based Accelerator for Adaptive Moment Estimation.pdf}
}

@inproceedings{zhangPUFDualstateAnalog2022,
  title = {{{DA PUF}}: Dual-State Analog {{PUF}}},
  shorttitle = {{{DA PUF}}},
  booktitle = {Proceedings of the 59th {{ACM}}/{{IEEE Design Automation Conference}}},
  author = {Zhang, Jiliang and Ding, Lin and Chen, Zhuojun and Li, Wenshang and Qu, Gang},
  date = {2022-08-23},
  series = {{{DAC}} '22},
  pages = {73--78},
  publisher = {Association for Computing Machinery},
  location = {New York, NY, USA},
  doi = {10.1145/3489517.3530412},
  url = {https://dl.acm.org/doi/10.1145/3489517.3530412},
  urldate = {2023-12-15},
  abstract = {Physical unclonable function (PUF) is a promising lightweight hardware security primitive that exploits process variations during chip fabrication for applications such as key generation and device authentication. Reliability of the PUF information plays a vital role and poses a major challenge for PUF design. In this paper, we propose a novel dual-state analog PUF (DA PUF) which has been successfully fabricated in 55nm process. The 40,960 bits generated by the fabricated DA PUF pass the NIST randomness test with reliability over 99.99\% for working environment of -40 \textasciitilde{} 125 C (temperature) and 0.96 \textasciitilde{} 1.44V (voltage), outperforming the two state-of-the-art analog PUFs reported in JSSC 2016 and 2021.},
  isbn = {978-1-4503-9142-9},
  keywords = {analog PUF,device authentication,hardware securiy,key generation,physical unclonable function},
  file = {/Users/marcel/Zotero/storage/VMQJN7H6/Zhang et al. - 2022 - DA PUF dual-state analog PUF.pdf}
}

@online{zhangRootMeanSquare2019,
  title = {Root {{Mean Square Layer Normalization}}},
  author = {Zhang, Biao and Sennrich, Rico},
  date = {2019-10-16},
  eprint = {1910.07467},
  eprinttype = {arXiv},
  eprintclass = {cs, stat},
  doi = {10.48550/arXiv.1910.07467},
  url = {http://arxiv.org/abs/1910.07467},
  urldate = {2024-03-16},
  abstract = {Layer normalization (LayerNorm) has been successfully applied to various deep neural networks to help stabilize training and boost model convergence because of its capability in handling re-centering and re-scaling of both inputs and weight matrix. However, the computational overhead introduced by LayerNorm makes these improvements expensive and significantly slows the underlying network, e.g. RNN in particular. In this paper, we hypothesize that re-centering invariance in LayerNorm is dispensable and propose root mean square layer normalization, or RMSNorm. RMSNorm regularizes the summed inputs to a neuron in one layer according to root mean square (RMS), giving the model re-scaling invariance property and implicit learning rate adaptation ability. RMSNorm is computationally simpler and thus more efficient than LayerNorm. We also present partial RMSNorm, or pRMSNorm where the RMS is estimated from p\% of the summed inputs without breaking the above properties. Extensive experiments on several tasks using diverse network architectures show that RMSNorm achieves comparable performance against LayerNorm but reduces the running time by 7\%\textasciitilde 64\% on different models. Source code is available at https://github.com/bzhangGo/rmsnorm.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computation and Language,Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/marcel/Zotero/storage/R7Q5T949/Zhang and Sennrich - 2019 - Root Mean Square Layer Normalization.pdf;/Users/marcel/Zotero/storage/S44HUECJ/1910.html}
}

@online{zhangSim2RealSoftRobotic2022,
  title = {{{Sim2Real}} for {{Soft Robotic Fish}} via {{Differentiable Simulation}}},
  author = {Zhang, John Z. and Zhang, Yu and Ma, Pingchuan and Nava, Elvis and Du, Tao and Arm, Philip and Matusik, Wojciech and Katzschmann, Robert K.},
  date = {2022-11-08},
  eprint = {2109.14855},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2109.14855},
  url = {http://arxiv.org/abs/2109.14855},
  urldate = {2023-06-29},
  abstract = {Accurate simulation of soft mechanisms under dynamic actuation is critical for the design of soft robots. We address this gap with our differentiable simulation tool by learning the material parameters of our soft robotic fish. On the example of a soft robotic fish, we demonstrate an experimentally-verified, fast optimization pipeline for learning the material parameters from quasi-static data via differentiable simulation and apply it to the prediction of dynamic performance. Our method identifies physically plausible Young's moduli for various soft silicone elastomers and stiff acetal copolymers used in creation of our three different robotic fish tail designs. We show that our method is compatible with varying internal geometry of the actuators, such as the number of hollow cavities. Our framework allows high fidelity prediction of dynamic behavior for composite bi-morph bending structures in real hardware to millimeter-accuracy and within 3 percent error normalized to actuator length. We provide a differentiable and robust estimate of the thrust force using a neural network thrust predictor; this estimate allows for accurate modeling of our experimental setup measuring bollard pull. This work presents a prototypical hardware and simulation problem solved using our differentiable framework; the framework can be applied to higher dimensional parameter inference, learning control policies, and computational design due to its differentiable character.},
  pubstate = {prepublished},
  keywords = {Computer Science - Machine Learning,Computer Science - Robotics},
  file = {/Users/marcel/Zotero/storage/HPHUKCEW/Zhang et al. - 2022 - Sim2Real for Soft Robotic Fish via Differentiable .pdf;/Users/marcel/Zotero/storage/N47LQEQV/2109.html}
}

@online{zhangWassersplinesNeuralVector2022,
  title = {Wassersplines for {{Neural Vector Field--Controlled Animation}}},
  author = {Zhang, Paul and Smirnov, Dmitriy and Solomon, Justin},
  date = {2022-09-19},
  eprint = {2201.11940},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2201.11940},
  url = {http://arxiv.org/abs/2201.11940},
  urldate = {2022-11-03},
  abstract = {Much of computer-generated animation is created by manipulating meshes with rigs. While this approach works well for animating articulated objects like animals, it has limited flexibility for animating less structured free-form objects. We introduce Wassersplines, a novel trajectory inference method for animating unstructured densities based on recent advances in continuous normalizing flows and optimal transport. The key idea is to train a neurally-parameterized velocity field that represents the motion between keyframes. Trajectories are then computed by advecting keyframes through the velocity field. We solve an additional Wasserstein barycenter interpolation problem to guarantee strict adherence to keyframes. Our tool can stylize trajectories through a variety of PDE-based regularizers to create different visual effects. We demonstrate our tool on various keyframe interpolation problems to produce temporally-coherent animations without meshing or rigging.},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Graphics},
  file = {/Users/marcel/Zotero/storage/AVQ95PZT/Zhang et al. - 2022 - Wassersplines for Neural Vector Field--Controlled .pdf;/Users/marcel/Zotero/storage/JDYNHM6Q/2201.html}
}

@inproceedings{zhaoEnergyEfficientComputinginMemoryNeuromorphic2019,
  title = {An {{Energy-Efficient Computing-in-Memory Neuromorphic System}} with {{On-Chip Training}}},
  booktitle = {2019 {{IEEE Biomedical Circuits}} and {{Systems Conference}} ({{BioCAS}})},
  author = {Zhao, Zhao and Wang, Yuan and Zhang, Xinyue and Cui, Xiaoxin and Huang, Ru},
  date = {2019-10},
  pages = {1--4},
  issn = {2163-4025},
  doi = {10.1109/BIOCAS.2019.8918995},
  abstract = {The aim of neuromorphic computing system is to implement the computational power and efficiency of the human brain. Computing-in-memory (CIM) is a promising and energy-efficient way to perform intensive computations, whose structure is similar to human brain synapse. A 8.78TOPS/W biologically-inspired neuromorphic computing system for pattern recognition based on CIM architecture is presented in this work. The proposed system supports on-chip training with energy-efficient bio-plausible spike-timing-dependent plasticity (STDP) rule and performs multiply-and-accumulate (MAC) computations inside SRAM array during inference, which greatly reduces the energy consumption. Simulated in 65-nm technology, the proposed system achieves good performance and energy efficiency for pattern recognition. The total energy consumption of training and classifying per image of the proposed system is 0.20 nJ. And the proposed spiking neural network (SNN) just consumes 0.074mW at 1.0V with the throughput of 2.5M images/s in inference phase.},
  eventtitle = {2019 {{IEEE Biomedical Circuits}} and {{Systems Conference}} ({{BioCAS}})},
  keywords = {analog computation,bio-plasticity synapses,computing-in-memory (CIM),multiply-and-accumulate (MAC),neuromorphic computing system,Neuromorphics,Neurons,on-chip training,Random access memory,Static VAr compensators,Synapses,Testing,Training},
  file = {/Users/marcel/Zotero/storage/KCMDLCR9/Zhao et al. - 2019 - An Energy-Efficient Computing-in-Memory Neuromorph.pdf;/Users/marcel/Zotero/storage/S63JWXIW/8918995.html}
}

@unpublished{zhaoQuaternionEquivariantCapsule2020,
  title = {Quaternion {{Equivariant Capsule Networks}} for {{3D Point Clouds}}},
  author = {Zhao, Yongheng and Birdal, Tolga and Lenssen, Jan Eric and Menegatti, Emanuele and Guibas, Leonidas and Tombari, Federico},
  date = {2020-08-23},
  eprint = {1912.12098},
  eprinttype = {arXiv},
  eprintclass = {cs, stat},
  url = {http://arxiv.org/abs/1912.12098},
  urldate = {2021-07-27},
  abstract = {We present a 3D capsule module for processing point clouds that is equivariant to 3D rotations and translations, as well as invariant to permutations of the input points. The operator receives a sparse set of local reference frames, computed from an input point cloud and establishes end-to-end transformation equivariance through a novel dynamic routing procedure on quaternions. Further, we theoretically connect dynamic routing between capsules to the well-known Weiszfeld algorithm, a scheme for solving \textbackslash emph\{iterative re-weighted least squares\} (IRLS) problems with provable convergence properties. It is shown that such group dynamic routing can be interpreted as robust IRLS rotation averaging on capsule votes, where information is routed based on the final inlier scores. Based on our operator, we build a capsule network that disentangles geometry from pose, paving the way for more informative descriptors and a structured latent space. Our architecture allows joint object classification and orientation estimation without explicit supervision of rotations. We validate our algorithm empirically on common benchmark datasets.},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Graphics,Computer Science - Machine Learning,Computer Science - Robotics,Statistics - Machine Learning},
  file = {/Users/marcel/Zotero/storage/A2ANEAHN/Zhao et al_2020_Quaternion Equivariant Capsule Networks for 3D Point Clouds.pdf;/Users/marcel/Zotero/storage/ICTM8GKP/1912.html}
}

@online{zhengGraphNeuralNetworks2022,
  title = {Graph {{Neural Networks}} for {{Graphs}} with {{Heterophily}}: {{A Survey}}},
  shorttitle = {Graph {{Neural Networks}} for {{Graphs}} with {{Heterophily}}},
  author = {Zheng, Xin and Liu, Yixin and Pan, Shirui and Zhang, Miao and Jin, Di and Yu, Philip S.},
  date = {2022-02-14},
  eprint = {2202.07082},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2202.07082},
  url = {http://arxiv.org/abs/2202.07082},
  urldate = {2023-02-26},
  abstract = {Recent years have witnessed fast developments of graph neural networks (GNNs) that have benefited myriads of graph analytic tasks and applications. In general, most GNNs depend on the homophily assumption that nodes belonging to the same class are more likely to be connected. However, as a ubiquitous graph property in numerous real-world scenarios, heterophily, i.e., nodes with different labels tend to be linked, significantly limits the performance of tailor-made homophilic GNNs. Hence, \textbackslash textit\{GNNs for heterophilic graphs\} are gaining increasing attention in this community. To the best of our knowledge, in this paper, we provide a comprehensive review of GNNs for heterophilic graphs for the first time. Specifically, we propose a systematic taxonomy that essentially governs existing heterophilic GNN models, along with a general summary and detailed analysis. Furthermore, we summarize the mainstream heterophilic graph benchmarks to facilitate robust and fair evaluations. In the end, we point out the potential directions to advance and stimulate future research and applications on heterophilic graphs.},
  pubstate = {prepublished},
  keywords = {Computer Science - Machine Learning},
  file = {/Users/marcel/Zotero/storage/62XJNI94/Zheng et al. - 2022 - Graph Neural Networks for Graphs with Heterophily.pdf;/Users/marcel/Zotero/storage/66XXMLDD/2202.html}
}

@online{zhouTeachingAlgorithmicReasoning2022,
  title = {Teaching {{Algorithmic Reasoning}} via {{In-context Learning}}},
  author = {Zhou, Hattie and Nova, Azade and Larochelle, Hugo and Courville, Aaron and Neyshabur, Behnam and Sedghi, Hanie},
  date = {2022-11-15},
  eprint = {2211.09066},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2211.09066},
  url = {http://arxiv.org/abs/2211.09066},
  urldate = {2024-03-14},
  abstract = {Large language models (LLMs) have shown increasing in-context learning capabilities through scaling up model and data size. Despite this progress, LLMs are still unable to solve algorithmic reasoning problems. While providing a rationale with the final answer has led to further improvements in multi-step reasoning problems, Anil et al. 2022 showed that even simple algorithmic reasoning tasks such as parity are far from solved. In this work, we identify and study four key stages for successfully teaching algorithmic reasoning to LLMs: (1) formulating algorithms as skills, (2) teaching multiple skills simultaneously (skill accumulation), (3) teaching how to combine skills (skill composition) and (4) teaching how to use skills as tools. We show that it is possible to teach algorithmic reasoning to LLMs via in-context learning, which we refer to as algorithmic prompting. We evaluate our approach on a variety of arithmetic and quantitative reasoning tasks, and demonstrate significant boosts in performance over existing prompting techniques. In particular, for long parity, addition, multiplication and subtraction, we achieve an error reduction of approximately 10x, 9x, 5x and 2x respectively compared to the best available baselines.},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Machine Learning},
  file = {/Users/marcel/Zotero/storage/W5UJD6H7/Zhou et al. - 2022 - Teaching Algorithmic Reasoning via In-context Learning.pdf;/Users/marcel/Zotero/storage/V2X2HRFF/2211.html}
}

@unpublished{zhuCorrespondenceFreePointCloud2021,
  title = {Correspondence-{{Free Point Cloud Registration}} with {{SO}}(3)-{{Equivariant Implicit Shape Representations}}},
  author = {Zhu, Minghan and Ghaffari, Maani and Peng, Huei},
  date = {2021-07-21},
  eprint = {2107.10296},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2107.10296},
  urldate = {2021-07-30},
  abstract = {This paper proposes a correspondence-free method for point cloud rotational registration. We learn an embedding for each point cloud in a feature space that preserves the SO(3)-equivariance property, enabled by recent developments in equivariant neural networks. The proposed shape registration method achieves three major advantages through combining equivariant feature learning with implicit shape models. First, the necessity of data association is removed because of the permutation-invariant property in network architectures similar to PointNet. Second, the registration in feature space can be solved in closed-form using Horn's method due to the SO(3)-equivariance property. Third, the registration is robust to noise in the point cloud because of implicit shape learning. The experimental results show superior performance compared with existing correspondence-free deep registration methods.},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning},
  file = {/Users/marcel/Zotero/storage/6C52UFGZ/Zhu et al_2021_Correspondence-Free Point Cloud Registration with SO(3)-Equivariant Implicit.pdf;/Users/marcel/Zotero/storage/H2HMIDZP/2107.html}
}

@article{zhuSpaceefficientOpticalComputing2022,
  title = {Space-Efficient Optical Computing with an Integrated Chip Diffractive Neural Network},
  author = {Zhu, H. H. and Zou, J. and Zhang, H. and Shi, Y. Z. and Luo, S. B. and Wang, N. and Cai, H. and Wan, L. X. and Wang, B. and Jiang, X. D. and Thompson, J. and Luo, X. S. and Zhou, X. H. and Xiao, L. M. and Huang, W. and Patrick, L. and Gu, M. and Kwek, L. C. and Liu, A. Q.},
  date = {2022-02-24},
  journaltitle = {Nature Communications},
  shortjournal = {Nat Commun},
  volume = {13},
  number = {1},
  pages = {1044},
  publisher = {Nature Publishing Group},
  issn = {2041-1723},
  doi = {10.1038/s41467-022-28702-0},
  url = {https://www.nature.com/articles/s41467-022-28702-0},
  urldate = {2023-10-17},
  abstract = {Large-scale, highly integrated and low-power-consuming hardware is becoming progressively more important for realizing optical neural networks (ONNs) capable of advanced optical computing. Traditional experimental implementations need N2 units such as Mach-Zehnder interferometers (MZIs) for an input dimension N to realize typical computing operations (convolutions and matrix multiplication), resulting in limited scalability and consuming excessive power. Here, we propose the integrated diffractive optical network for implementing parallel Fourier transforms, convolution operations and application-specific optical computing using two ultracompact diffractive cells (Fourier transform operation) and only N MZIs. The footprint and energy consumption scales linearly with the input data dimension, instead of the quadratic scaling in the traditional ONN framework. A \textasciitilde 10-fold reduction in both footprint and energy consumption, as well as equal high accuracy with previous MZI-based ONNs was experimentally achieved for computations performed on the MNIST and Fashion-MNIST datasets. The integrated diffractive optical network (IDNN) chip demonstrates a promising avenue towards scalable and low-power-consumption optical computational chips for optical-artificial-intelligence.},
  issue = {1},
  langid = {english},
  keywords = {Electronic devices,Integrated optics,Silicon photonics},
  file = {/Users/marcel/Zotero/storage/9YHUFLI6/Zhu et al. - 2022 - Space-efficient optical computing with an integrated chip diffractive neural network.pdf}
}

@online{ZoteroYourPersonal,
  title = {Zotero | {{Your}} Personal Research Assistant},
  url = {https://www.zotero.org/start},
  urldate = {2022-03-17},
  file = {/Users/marcel/Zotero/storage/MM2CFYVV/start.html}
}
